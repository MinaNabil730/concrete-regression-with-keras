{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete Strength Prediction using Neural Networks\n",
    "\n",
    "In this notebook, we will build and evaluate several neural network models to predict concrete strength. We will follow these steps:\n",
    "\n",
    "1. **Build a baseline model**: Use a neural network with one hidden layer.\n",
    "2. **Normalize the data**: Use the same model but with normalized data.\n",
    "3. **Increase the number of epochs**: Train the model for more epochs.\n",
    "4. **Increase the number of hidden layers**: Use a deeper neural network with three hidden layers.\n",
    "\n",
    "---\n",
    "\n",
    "## Step A: Build a baseline model\n",
    "\n",
    "We will use the Keras library to build a neural network with:\n",
    "- One hidden layer of 10 nodes with a ReLU activation function.\n",
    "- The adam optimizer and mean squared error as the loss function.\n",
    "\n",
    "1. Randomly split the data into training and test sets, holding 30% of the data for testing.\n",
    "2. Train the model on the training data using 50 epochs.\n",
    "3. Evaluate the model on the test data and compute the mean squared error.\n",
    "4. Repeat the process 50 times to create a list of 50 mean squared errors.\n",
    "5. Report the mean and standard deviation of the mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('concrete_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data looks clean and is ready to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "features = df.drop([\"Strength\"], axis = 1)\n",
    "target = df[\"Strength\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features\n",
    "n_cols = features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the baseline model\n",
    "def regression_model(n_cols):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 2s - 75ms/step - loss: 331881.7812 - val_loss: 273516.7500\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 232556.7656 - val_loss: 191135.9062\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 163230.2188 - val_loss: 134598.6875\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 115828.2812 - val_loss: 96412.6797\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 83521.7812 - val_loss: 70163.6875\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 61191.3555 - val_loss: 51726.6562\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 3ms/step - loss: 45465.4766 - val_loss: 38886.4297\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 34586.4453 - val_loss: 30060.3633\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 26965.9277 - val_loss: 23870.0527\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 21512.3145 - val_loss: 19432.0391\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 17648.4531 - val_loss: 16203.5859\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 3ms/step - loss: 14770.9297 - val_loss: 13763.6084\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 12546.4170 - val_loss: 11773.7100\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 10746.9541 - val_loss: 10152.5391\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 9272.2910 - val_loss: 8824.3193\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 8065.7085 - val_loss: 7707.2314\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 7050.4375 - val_loss: 6771.6396\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 6198.4922 - val_loss: 5984.4761\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 8ms/step - loss: 5482.5112 - val_loss: 5312.7910\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 4872.8516 - val_loss: 4745.5210\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 4358.6523 - val_loss: 4267.1782\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 3935.4233 - val_loss: 3873.4785\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 3587.9631 - val_loss: 3550.6565\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 3ms/step - loss: 3298.4280 - val_loss: 3276.9370\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 3053.7400 - val_loss: 3056.6072\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 2857.7869 - val_loss: 2870.1699\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 2690.5547 - val_loss: 2716.5386\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 2548.0088 - val_loss: 2585.3892\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 2427.8677 - val_loss: 2470.8252\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 2323.5464 - val_loss: 2375.5325\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 2234.7820 - val_loss: 2291.1433\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 2157.3215 - val_loss: 2215.3049\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 2089.8594 - val_loss: 2149.0713\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 7ms/step - loss: 2030.1711 - val_loss: 2092.2000\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 1978.9637 - val_loss: 2041.6727\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 1933.5739 - val_loss: 1998.5603\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 1894.7046 - val_loss: 1960.5404\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 1861.3718 - val_loss: 1925.7023\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 1831.2743 - val_loss: 1896.5409\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 3ms/step - loss: 1805.5710 - val_loss: 1870.3754\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 1783.7660 - val_loss: 1847.1967\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 1764.8258 - val_loss: 1827.4668\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 1748.6189 - val_loss: 1809.3313\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 3ms/step - loss: 1733.7750 - val_loss: 1792.9335\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 1720.6510 - val_loss: 1777.7312\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 1708.4409 - val_loss: 1764.4615\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 1697.1366 - val_loss: 1751.8948\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 1686.6010 - val_loss: 1739.8159\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 1676.6503 - val_loss: 1728.4893\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 3ms/step - loss: 1667.3671 - val_loss: 1717.8435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 58ms/step - loss: 17695.5449 - val_loss: 7342.0063\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 7366.9604 - val_loss: 6256.7300\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 6560.4404 - val_loss: 5773.5811\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 5858.5513 - val_loss: 5165.8281\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 5254.7100 - val_loss: 4648.3833\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 3ms/step - loss: 4652.4355 - val_loss: 4160.2261\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 4149.2793 - val_loss: 3767.2605\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 3684.0876 - val_loss: 3335.2749\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 3288.1758 - val_loss: 3041.5701\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - loss: 2937.0381 - val_loss: 2740.7197\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 8ms/step - loss: 2636.4336 - val_loss: 2502.3000\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 2365.7146 - val_loss: 2231.2542\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2130.7217 - val_loss: 2054.3345\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1930.1682 - val_loss: 1862.1671\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1767.7888 - val_loss: 1705.3491\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1606.1354 - val_loss: 1567.0969\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1470.5392 - val_loss: 1449.8264\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 1345.7773 - val_loss: 1333.6494\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1236.6178 - val_loss: 1244.8386\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 3ms/step - loss: 1139.3390 - val_loss: 1125.0037\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1049.4664 - val_loss: 1054.3196\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 968.6629 - val_loss: 993.3274\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 898.8680 - val_loss: 922.0488\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 3ms/step - loss: 825.5968 - val_loss: 828.9042\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 758.8595 - val_loss: 762.4431\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 701.7151 - val_loss: 696.2888\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 647.5626 - val_loss: 654.3391\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 595.9868 - val_loss: 618.5060\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 549.1938 - val_loss: 550.2926\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 512.3467 - val_loss: 516.7958\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 471.1549 - val_loss: 475.0456\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 434.7742 - val_loss: 439.0409\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 404.6570 - val_loss: 410.0771\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 373.8167 - val_loss: 376.1094\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 7ms/step - loss: 349.2127 - val_loss: 356.4773\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 325.3435 - val_loss: 332.9359\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 301.0428 - val_loss: 304.1635\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 282.2841 - val_loss: 284.0792\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 267.3602 - val_loss: 265.5311\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 252.0831 - val_loss: 257.8404\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 232.4456 - val_loss: 235.6911\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 15ms/step - loss: 219.2786 - val_loss: 228.3075\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 12ms/step - loss: 210.0221 - val_loss: 222.6395\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 8ms/step - loss: 198.9050 - val_loss: 202.9053\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 186.9257 - val_loss: 189.8134\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 179.1380 - val_loss: 183.1006\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 16ms/step - loss: 170.9170 - val_loss: 178.6248\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 164.6771 - val_loss: 166.9924\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 158.0340 - val_loss: 160.3918\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 153.0746 - val_loss: 159.4006\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 76ms/step - loss: 731228.2500 - val_loss: 596142.6250\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 485391.8750 - val_loss: 384913.4062\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 306527.1250 - val_loss: 232846.3750\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 6ms/step - loss: 176421.2344 - val_loss: 120923.5234\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 80652.2656 - val_loss: 46472.7539\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 29042.2715 - val_loss: 18392.4844\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 3ms/step - loss: 13777.8486 - val_loss: 13119.8711\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 11703.3311 - val_loss: 12523.3291\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 11287.7285 - val_loss: 12171.9580\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 10996.1875 - val_loss: 11821.9346\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 10712.8525 - val_loss: 11480.9551\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 10424.9531 - val_loss: 11177.4707\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 10147.0430 - val_loss: 10845.2695\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 9878.4531 - val_loss: 10535.9697\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 9625.5605 - val_loss: 10244.8389\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 9381.5732 - val_loss: 9954.5605\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 6ms/step - loss: 9144.1846 - val_loss: 9673.1309\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 7ms/step - loss: 8910.4736 - val_loss: 9420.3623\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 8700.0146 - val_loss: 9165.6504\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 8476.2070 - val_loss: 8913.1826\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 8275.2471 - val_loss: 8679.1748\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 8057.4619 - val_loss: 8449.3145\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 7865.8560 - val_loss: 8217.8906\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 6ms/step - loss: 7663.7642 - val_loss: 8002.7915\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 7506.6816 - val_loss: 7799.9346\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 7320.4189 - val_loss: 7589.1021\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 10ms/step - loss: 7131.4707 - val_loss: 7397.8076\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 6966.4390 - val_loss: 7216.6479\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 6800.0908 - val_loss: 7023.8906\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 6639.5366 - val_loss: 6853.1035\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 6485.7461 - val_loss: 6681.9883\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 6343.0210 - val_loss: 6507.1567\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 6179.0845 - val_loss: 6341.8804\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 6034.5479 - val_loss: 6182.3999\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 3ms/step - loss: 5893.5215 - val_loss: 6024.3032\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 5747.4224 - val_loss: 5878.3491\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 5620.9580 - val_loss: 5720.0225\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 5480.0356 - val_loss: 5575.0498\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 5344.7856 - val_loss: 5440.0693\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 5225.3760 - val_loss: 5297.9683\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 5105.6235 - val_loss: 5166.2324\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 4988.0137 - val_loss: 5053.9683\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 4876.1587 - val_loss: 4924.6719\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 4760.6753 - val_loss: 4804.6670\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 4658.5088 - val_loss: 4693.8296\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 4550.0679 - val_loss: 4583.0347\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 4463.5151 - val_loss: 4479.8496\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 4350.4238 - val_loss: 4368.5913\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 4253.9985 - val_loss: 4271.6240\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 4163.9849 - val_loss: 4172.8242\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 64ms/step - loss: 87476.2188 - val_loss: 62946.9062\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 42646.7500 - val_loss: 27266.6465\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 18304.3652 - val_loss: 11494.5059\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 10731.3281 - val_loss: 9052.3818\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 9400.8916 - val_loss: 8113.7573\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 8467.7480 - val_loss: 7370.4902\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 3ms/step - loss: 7614.6548 - val_loss: 6582.6533\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 6853.6587 - val_loss: 5978.0034\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 6207.0132 - val_loss: 5404.1782\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 5591.1509 - val_loss: 4859.8784\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 5052.2241 - val_loss: 4384.7964\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 4559.0151 - val_loss: 3979.6331\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 4115.4639 - val_loss: 3599.1553\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 3703.3718 - val_loss: 3237.8052\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 3334.4851 - val_loss: 2912.0208\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 2995.7815 - val_loss: 2627.4512\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 2691.7021 - val_loss: 2363.5901\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 3ms/step - loss: 2426.4709 - val_loss: 2130.1504\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 2185.1797 - val_loss: 1932.1927\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1980.4352 - val_loss: 1762.6234\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 3ms/step - loss: 1793.5641 - val_loss: 1600.3882\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 1629.6736 - val_loss: 1461.7683\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1490.4293 - val_loss: 1324.7410\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1357.9513 - val_loss: 1213.1129\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 3ms/step - loss: 1248.9081 - val_loss: 1115.6296\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1146.7721 - val_loss: 1024.3674\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1063.6022 - val_loss: 941.5350\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 984.5665 - val_loss: 879.9791\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 920.6690 - val_loss: 821.6864\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 861.5054 - val_loss: 770.5289\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 807.9767 - val_loss: 722.8223\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 760.2172 - val_loss: 675.5512\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 714.1864 - val_loss: 637.2114\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 675.1532 - val_loss: 601.0243\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 636.9019 - val_loss: 569.7439\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 602.3702 - val_loss: 544.6707\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 570.1101 - val_loss: 514.2996\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 540.9686 - val_loss: 490.9015\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 514.3877 - val_loss: 467.6362\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 489.3885 - val_loss: 446.9031\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 465.5116 - val_loss: 426.3141\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 444.0457 - val_loss: 408.3483\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 424.7234 - val_loss: 391.7547\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 406.7194 - val_loss: 376.4632\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 11ms/step - loss: 390.3178 - val_loss: 362.6810\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 374.6531 - val_loss: 348.6026\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 3ms/step - loss: 360.5798 - val_loss: 336.8741\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 347.1286 - val_loss: 325.9592\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 335.2808 - val_loss: 315.9912\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 324.2148 - val_loss: 305.7751\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 62ms/step - loss: 8470.6338 - val_loss: 5169.6499\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 4300.4873 - val_loss: 3734.6023\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 2937.5823 - val_loss: 2635.3086\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 2147.3945 - val_loss: 1947.5231\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1617.8282 - val_loss: 1534.8306\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1266.9613 - val_loss: 1232.8976\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 982.9703 - val_loss: 957.9044\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 785.3158 - val_loss: 756.6899\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 613.6934 - val_loss: 601.3264\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 504.9763 - val_loss: 517.9084\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 442.6364 - val_loss: 463.0103\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 391.3455 - val_loss: 404.3326\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 341.0465 - val_loss: 370.0974\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 308.3100 - val_loss: 342.7344\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 286.2867 - val_loss: 321.5831\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 268.3852 - val_loss: 305.7439\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 247.5134 - val_loss: 294.8228\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 3ms/step - loss: 234.1670 - val_loss: 273.1404\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 220.1528 - val_loss: 268.2623\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 212.0964 - val_loss: 253.4156\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 207.1772 - val_loss: 241.9550\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 9ms/step - loss: 199.6627 - val_loss: 233.2032\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 3ms/step - loss: 191.2609 - val_loss: 233.9415\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 182.1840 - val_loss: 217.6954\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 176.6114 - val_loss: 214.5578\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 180.5842 - val_loss: 207.8222\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 170.5097 - val_loss: 198.6785\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.0689 - val_loss: 198.5392\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 9ms/step - loss: 160.1242 - val_loss: 191.3607\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.0438 - val_loss: 184.0487\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.2989 - val_loss: 180.6403\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.6898 - val_loss: 176.9976\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.0650 - val_loss: 175.7808\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 146.4151 - val_loss: 169.8628\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.7276 - val_loss: 167.1839\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.3402 - val_loss: 164.8946\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.6766 - val_loss: 160.5441\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.5919 - val_loss: 157.4525\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 143.3467 - val_loss: 155.6877\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.1702 - val_loss: 153.9994\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.8642 - val_loss: 150.1644\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.4180 - val_loss: 152.6805\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 135.6120 - val_loss: 146.5979\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.7514 - val_loss: 144.0115\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 137.7920 - val_loss: 143.1917\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 129.5473 - val_loss: 143.1581\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.7166 - val_loss: 139.5934\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 126.5661 - val_loss: 143.6441\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.4181 - val_loss: 137.5869\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 124.3636 - val_loss: 135.7456\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 66ms/step - loss: 28085.2871 - val_loss: 14697.9902\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 3ms/step - loss: 7910.5508 - val_loss: 3876.0264\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 2817.7268 - val_loss: 2706.7625\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 2385.1475 - val_loss: 2440.5081\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 2128.3838 - val_loss: 2215.3977\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1919.3177 - val_loss: 2006.6802\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1734.8190 - val_loss: 1819.9702\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1561.6086 - val_loss: 1653.2031\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1409.1423 - val_loss: 1502.5991\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1272.6736 - val_loss: 1365.7589\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1148.7614 - val_loss: 1242.2256\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1037.6189 - val_loss: 1129.5859\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 937.8176 - val_loss: 1022.3781\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 847.5952 - val_loss: 931.1837\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 766.6572 - val_loss: 847.4859\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 693.8784 - val_loss: 769.8073\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 628.4871 - val_loss: 703.7224\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 3ms/step - loss: 571.5997 - val_loss: 643.9556\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 521.6221 - val_loss: 591.9376\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 475.9711 - val_loss: 542.2758\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 438.3840 - val_loss: 499.7817\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 401.6934 - val_loss: 462.0695\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 7ms/step - loss: 369.8018 - val_loss: 428.2750\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 341.5466 - val_loss: 398.4402\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 317.6237 - val_loss: 371.1926\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 295.5131 - val_loss: 348.1283\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 276.2443 - val_loss: 327.0607\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 259.8086 - val_loss: 307.9196\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 244.7959 - val_loss: 291.3453\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 231.9410 - val_loss: 276.8878\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 220.5725 - val_loss: 262.8726\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 211.3476 - val_loss: 251.0189\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 202.0435 - val_loss: 241.4405\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 3ms/step - loss: 195.3739 - val_loss: 232.3501\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 187.9726 - val_loss: 224.3361\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 182.2175 - val_loss: 217.6833\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 177.1476 - val_loss: 211.9523\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 172.4305 - val_loss: 206.2622\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.1054 - val_loss: 201.4736\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 165.5353 - val_loss: 196.9541\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.7177 - val_loss: 193.6265\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.6435 - val_loss: 189.6917\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.6315 - val_loss: 186.6024\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 17ms/step - loss: 155.0157 - val_loss: 183.9003\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.3517 - val_loss: 181.2412\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 152.0491 - val_loss: 179.5411\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 149.3157 - val_loss: 176.9635\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 148.4873 - val_loss: 175.6442\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.7151 - val_loss: 172.9603\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.7010 - val_loss: 171.1121\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 132ms/step - loss: 88652.8828 - val_loss: 51419.8594\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 34435.8672 - val_loss: 16716.7773\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 11006.2451 - val_loss: 6364.8354\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 5440.9678 - val_loss: 5338.8740\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 4781.5557 - val_loss: 4874.0039\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 4370.6938 - val_loss: 4376.8950\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 4010.3870 - val_loss: 3989.7661\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 3682.4331 - val_loss: 3671.5630\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 3405.7915 - val_loss: 3366.7056\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 3150.4851 - val_loss: 3126.8042\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 2924.6953 - val_loss: 2899.8457\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 2732.2371 - val_loss: 2685.2258\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2558.1941 - val_loss: 2515.6514\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 2403.4358 - val_loss: 2350.3154\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 2264.3401 - val_loss: 2216.6545\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 2136.3613 - val_loss: 2085.9363\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 2019.6741 - val_loss: 1958.8698\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1914.6010 - val_loss: 1847.9122\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1817.4662 - val_loss: 1752.7457\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1721.0426 - val_loss: 1656.7577\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1639.2008 - val_loss: 1570.4078\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1559.1703 - val_loss: 1487.1471\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 12ms/step - loss: 1485.9908 - val_loss: 1416.3712\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1413.4012 - val_loss: 1343.3872\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1349.1249 - val_loss: 1280.9673\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1283.6938 - val_loss: 1216.5291\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1222.4843 - val_loss: 1158.8324\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 1165.7152 - val_loss: 1102.5256\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1113.4460 - val_loss: 1049.0587\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 1062.2123 - val_loss: 1001.7424\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 1012.8950 - val_loss: 953.3799\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 966.5468 - val_loss: 910.1332\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 923.8868 - val_loss: 863.1439\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 879.9724 - val_loss: 827.1743\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 840.8527 - val_loss: 787.1275\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 802.5323 - val_loss: 750.8623\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 766.6159 - val_loss: 717.0229\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 732.8228 - val_loss: 685.6290\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 698.8875 - val_loss: 652.8021\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 667.8983 - val_loss: 623.0040\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 639.0934 - val_loss: 596.5144\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 611.8288 - val_loss: 572.2020\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 587.4633 - val_loss: 546.8920\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 558.4630 - val_loss: 523.3342\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 534.5283 - val_loss: 501.1130\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 511.0519 - val_loss: 479.6681\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 490.1528 - val_loss: 459.6503\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 468.3256 - val_loss: 442.0474\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 448.7820 - val_loss: 424.9069\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 431.2388 - val_loss: 406.8942\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 67ms/step - loss: 102483.2422 - val_loss: 67313.1875\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 52452.4609 - val_loss: 31612.5762\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 24578.3438 - val_loss: 13539.7236\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 3ms/step - loss: 10667.7627 - val_loss: 5286.8379\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 4398.2388 - val_loss: 2258.2373\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 2169.0217 - val_loss: 1424.0475\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1533.2382 - val_loss: 1283.4080\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1357.8098 - val_loss: 1223.9608\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1265.8710 - val_loss: 1154.5021\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1178.4861 - val_loss: 1079.9673\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1095.8008 - val_loss: 1003.9112\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1021.5798 - val_loss: 935.5989\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 3ms/step - loss: 951.1401 - val_loss: 881.9863\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 886.6671 - val_loss: 826.1402\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 827.2188 - val_loss: 777.2083\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 774.1030 - val_loss: 721.8030\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 721.2100 - val_loss: 684.0111\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 675.3195 - val_loss: 639.4836\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 631.9844 - val_loss: 604.3890\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 591.6799 - val_loss: 564.8882\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 554.4977 - val_loss: 529.1799\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 520.2072 - val_loss: 498.2207\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 489.7093 - val_loss: 472.4210\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 459.9770 - val_loss: 444.3950\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 432.9418 - val_loss: 419.9474\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 409.5869 - val_loss: 397.9615\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 7ms/step - loss: 385.1872 - val_loss: 374.1993\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 363.4389 - val_loss: 358.2749\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 3ms/step - loss: 343.3407 - val_loss: 339.3507\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 324.8570 - val_loss: 322.7074\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 308.2458 - val_loss: 307.6181\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 292.8843 - val_loss: 292.8989\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 277.9492 - val_loss: 282.4928\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 264.7759 - val_loss: 270.2328\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 252.7590 - val_loss: 259.2788\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 241.2189 - val_loss: 248.5331\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 231.4227 - val_loss: 240.2529\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 221.8284 - val_loss: 232.5928\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 212.9395 - val_loss: 224.9965\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 204.6634 - val_loss: 217.7874\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 197.3426 - val_loss: 211.2523\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.2397 - val_loss: 205.0831\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 184.4917 - val_loss: 200.3094\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 178.6954 - val_loss: 195.1373\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.8286 - val_loss: 191.1553\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.3451 - val_loss: 187.5603\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.4161 - val_loss: 183.4793\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 9ms/step - loss: 161.2515 - val_loss: 180.4999\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 158.1539 - val_loss: 177.8519\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 155.1144 - val_loss: 175.0997\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 58ms/step - loss: 11996.1816 - val_loss: 4072.7209\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 2691.9399 - val_loss: 1815.6887\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1803.1052 - val_loss: 1483.0824\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1409.9056 - val_loss: 1177.9606\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1104.3427 - val_loss: 922.6170\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 849.1995 - val_loss: 721.6957\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 665.8671 - val_loss: 572.1466\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 535.8174 - val_loss: 473.0001\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 448.6801 - val_loss: 406.0153\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 392.7689 - val_loss: 355.1038\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 346.0346 - val_loss: 317.1964\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 311.3451 - val_loss: 287.5113\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 285.9402 - val_loss: 269.2100\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 267.4349 - val_loss: 249.7466\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 249.1714 - val_loss: 232.7814\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 236.3421 - val_loss: 221.3186\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 222.7571 - val_loss: 208.3100\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 210.9081 - val_loss: 198.3038\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 200.6731 - val_loss: 188.7056\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.9976 - val_loss: 184.4877\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 182.4188 - val_loss: 172.6664\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 174.0376 - val_loss: 166.5241\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 166.8285 - val_loss: 160.6515\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 160.3769 - val_loss: 152.1291\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.5313 - val_loss: 146.1270\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.6975 - val_loss: 143.5243\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.8604 - val_loss: 148.0299\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.4165 - val_loss: 132.8718\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 11ms/step - loss: 135.4402 - val_loss: 128.7467\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 3ms/step - loss: 132.5792 - val_loss: 125.7537\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.1373 - val_loss: 125.0840\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.9227 - val_loss: 122.6340\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.2577 - val_loss: 119.3066\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 121.7673 - val_loss: 117.7504\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.1470 - val_loss: 116.2293\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 122.6358 - val_loss: 116.2624\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 118.4948 - val_loss: 121.0352\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.0847 - val_loss: 113.3728\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 115.5054 - val_loss: 113.6261\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.4656 - val_loss: 112.3356\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 113.7732 - val_loss: 110.4955\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.9915 - val_loss: 109.9516\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.0291 - val_loss: 111.7989\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.4941 - val_loss: 110.6438\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.6495 - val_loss: 109.7214\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - loss: 113.8263 - val_loss: 114.9661\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.4371 - val_loss: 108.5369\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.0969 - val_loss: 109.3572\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 111.0972 - val_loss: 109.8794\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.9755 - val_loss: 107.6093\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 3601.8621 - val_loss: 3279.9302\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 2394.1677 - val_loss: 2316.8921\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1705.9984 - val_loss: 1552.8784\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1184.4957 - val_loss: 1103.9739\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 871.9272 - val_loss: 834.6147\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 686.2315 - val_loss: 659.3469\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 563.6662 - val_loss: 526.2520\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 472.8519 - val_loss: 441.1847\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 421.5428 - val_loss: 378.4172\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 366.9753 - val_loss: 330.6207\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 324.8996 - val_loss: 286.2279\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 288.9783 - val_loss: 250.7600\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 258.2079 - val_loss: 221.6687\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 232.2377 - val_loss: 204.9272\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 215.7529 - val_loss: 181.3361\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 194.6754 - val_loss: 162.6895\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 180.3836 - val_loss: 156.4285\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 172.7964 - val_loss: 147.8484\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.4251 - val_loss: 132.5688\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 3ms/step - loss: 161.1532 - val_loss: 126.7320\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.5811 - val_loss: 123.2462\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.9449 - val_loss: 120.0782\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.7265 - val_loss: 115.7412\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.3040 - val_loss: 121.7051\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 140.0645 - val_loss: 112.4293\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 138.3957 - val_loss: 111.3168\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 3ms/step - loss: 136.7532 - val_loss: 110.0865\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.6668 - val_loss: 107.9596\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.4367 - val_loss: 107.0344\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.5827 - val_loss: 107.3138\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.4724 - val_loss: 113.8883\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 132.2777 - val_loss: 107.6025\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 131.0092 - val_loss: 104.6272\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 132.9652 - val_loss: 104.7204\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.3609 - val_loss: 102.5149\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 3ms/step - loss: 131.5741 - val_loss: 103.8068\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.9203 - val_loss: 104.6478\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.5877 - val_loss: 108.7906\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.1605 - val_loss: 101.3995\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.8493 - val_loss: 101.9361\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 129.2457 - val_loss: 100.5439\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 130.4955 - val_loss: 100.7890\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 127.5101 - val_loss: 101.9794\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.9544 - val_loss: 107.5156\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.3852 - val_loss: 99.6661\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 126.5925 - val_loss: 100.3650\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.8557 - val_loss: 99.7921\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 10ms/step - loss: 123.2741 - val_loss: 99.9352\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 127.8364 - val_loss: 98.1746\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.5804 - val_loss: 105.7816\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 61ms/step - loss: 17493.6523 - val_loss: 4727.8857\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 7ms/step - loss: 1712.6278 - val_loss: 798.4950\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 945.5060 - val_loss: 684.4692\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 751.5475 - val_loss: 622.1019\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 687.5454 - val_loss: 562.7155\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 643.5172 - val_loss: 530.2919\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 612.9346 - val_loss: 501.7107\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 586.8601 - val_loss: 481.3366\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 559.3668 - val_loss: 461.6562\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 535.3414 - val_loss: 439.8095\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 3ms/step - loss: 509.0872 - val_loss: 420.5164\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 488.8731 - val_loss: 403.7061\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 467.4175 - val_loss: 386.1608\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 449.0127 - val_loss: 370.2819\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 424.8950 - val_loss: 355.1749\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 406.2442 - val_loss: 339.7259\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 388.4014 - val_loss: 325.4121\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 372.2917 - val_loss: 312.2457\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 3ms/step - loss: 355.1228 - val_loss: 300.1273\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 338.7589 - val_loss: 292.3094\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 325.4481 - val_loss: 279.9539\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 6ms/step - loss: 310.9020 - val_loss: 264.6802\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 294.3634 - val_loss: 259.1252\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 282.9271 - val_loss: 247.3158\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 272.6426 - val_loss: 248.2095\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 3ms/step - loss: 263.1691 - val_loss: 235.3291\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 10ms/step - loss: 254.1765 - val_loss: 228.4274\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 246.5617 - val_loss: 224.7969\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 240.7390 - val_loss: 220.0786\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 235.3092 - val_loss: 217.8338\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 230.0664 - val_loss: 211.6354\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 225.8466 - val_loss: 213.2124\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 221.9423 - val_loss: 204.1226\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 218.3680 - val_loss: 202.4523\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 215.8829 - val_loss: 200.7925\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 212.2085 - val_loss: 198.7391\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 208.9224 - val_loss: 195.2782\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 206.1379 - val_loss: 193.4280\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 204.9241 - val_loss: 192.8820\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 204.6104 - val_loss: 187.1878\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 199.1279 - val_loss: 189.1881\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 194.6455 - val_loss: 182.7031\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 3ms/step - loss: 193.1105 - val_loss: 180.9926\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.6050 - val_loss: 177.7939\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 187.0735 - val_loss: 178.1142\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 186.3610 - val_loss: 173.8199\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 184.0198 - val_loss: 171.6326\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 3ms/step - loss: 183.1876 - val_loss: 170.7219\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 179.9261 - val_loss: 168.4810\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 177.7507 - val_loss: 167.6886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 63ms/step - loss: 195220.3750 - val_loss: 150848.4062\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 124402.4844 - val_loss: 93862.2344\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 76155.2344 - val_loss: 55421.6953\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 41469.0586 - val_loss: 23553.1895\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 13707.4512 - val_loss: 6145.3057\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 4319.9839 - val_loss: 3775.2217\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 3441.1550 - val_loss: 3554.8689\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 3237.7109 - val_loss: 3289.7161\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 3019.7507 - val_loss: 3056.9509\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 2829.6084 - val_loss: 2844.6316\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 2649.6379 - val_loss: 2659.1213\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 2484.6431 - val_loss: 2479.4998\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2329.3525 - val_loss: 2312.3267\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 2186.8174 - val_loss: 2167.8203\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 2054.7288 - val_loss: 2022.8254\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1931.8466 - val_loss: 1894.0338\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1820.9230 - val_loss: 1767.2937\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1708.6139 - val_loss: 1661.1357\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 1611.9673 - val_loss: 1555.9302\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1521.6855 - val_loss: 1457.3701\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1439.4958 - val_loss: 1370.9532\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1360.6381 - val_loss: 1291.2382\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1293.9712 - val_loss: 1218.1388\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1226.2538 - val_loss: 1149.8936\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1164.2233 - val_loss: 1094.2882\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1109.5912 - val_loss: 1033.5222\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1058.4441 - val_loss: 981.6150\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 1011.8351 - val_loss: 936.0145\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 971.5373 - val_loss: 897.9481\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 3ms/step - loss: 930.1307 - val_loss: 854.8309\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 894.5380 - val_loss: 824.1169\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 861.5089 - val_loss: 792.0392\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 830.6750 - val_loss: 760.5720\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 803.5850 - val_loss: 733.2761\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 779.4014 - val_loss: 710.2307\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 754.1596 - val_loss: 687.5142\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 738.5881 - val_loss: 671.2001\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 717.6155 - val_loss: 650.5065\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 693.4323 - val_loss: 632.4694\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 675.8604 - val_loss: 618.0099\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 662.6116 - val_loss: 604.4783\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 646.3628 - val_loss: 589.1293\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 627.7036 - val_loss: 577.9166\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 613.9039 - val_loss: 564.9790\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 9ms/step - loss: 600.4896 - val_loss: 550.0626\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - loss: 587.0920 - val_loss: 539.1151\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 573.6804 - val_loss: 530.4235\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 563.7069 - val_loss: 518.0464\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 549.9553 - val_loss: 509.8825\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 541.8223 - val_loss: 498.7578\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 64ms/step - loss: 4134.8091 - val_loss: 2786.0186\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 3251.9275 - val_loss: 2348.0068\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 3ms/step - loss: 2608.6362 - val_loss: 1858.6407\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 2182.8674 - val_loss: 1626.4028\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1844.0676 - val_loss: 1338.4436\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 1574.8928 - val_loss: 1228.3369\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1365.0214 - val_loss: 1000.1984\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1185.7427 - val_loss: 912.7205\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1039.6652 - val_loss: 790.5434\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 920.4761 - val_loss: 700.3786\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 828.4064 - val_loss: 657.5851\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 745.6606 - val_loss: 577.3268\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 682.2070 - val_loss: 533.4968\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 7ms/step - loss: 616.5554 - val_loss: 493.0646\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 563.6241 - val_loss: 449.8925\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 527.3156 - val_loss: 419.0679\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 489.0558 - val_loss: 391.6907\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 449.1846 - val_loss: 369.0438\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 421.5627 - val_loss: 357.2187\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 391.3950 - val_loss: 334.4109\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 368.2270 - val_loss: 312.6407\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 342.9048 - val_loss: 289.4779\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 322.8000 - val_loss: 279.2568\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 11ms/step - loss: 304.7718 - val_loss: 275.9010\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 293.1762 - val_loss: 243.5030\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 271.8636 - val_loss: 248.7287\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 262.2773 - val_loss: 221.8697\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 245.0438 - val_loss: 212.6785\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 235.4795 - val_loss: 203.9303\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 222.5467 - val_loss: 193.9258\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 218.2566 - val_loss: 186.8604\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 208.7981 - val_loss: 187.6547\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 197.6686 - val_loss: 175.9645\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 192.7515 - val_loss: 171.6380\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 182.0890 - val_loss: 160.6983\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 176.4893 - val_loss: 156.2625\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 3ms/step - loss: 171.6396 - val_loss: 151.1894\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 166.6236 - val_loss: 162.0993\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 170.1109 - val_loss: 156.6348\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.3054 - val_loss: 145.1417\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.4663 - val_loss: 136.7406\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 149.1667 - val_loss: 134.2196\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 7ms/step - loss: 146.1327 - val_loss: 130.6834\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 7ms/step - loss: 142.9664 - val_loss: 130.3131\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 142.4253 - val_loss: 126.2286\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 7ms/step - loss: 137.8042 - val_loss: 123.9985\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 7ms/step - loss: 135.1249 - val_loss: 125.7539\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 136.4924 - val_loss: 125.6319\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 7ms/step - loss: 131.5601 - val_loss: 122.4552\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 131.5275 - val_loss: 118.9316\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 67ms/step - loss: 191502.6406 - val_loss: 113863.3906\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 75630.2969 - val_loss: 39992.9766\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 7ms/step - loss: 24951.7383 - val_loss: 11438.8398\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 6718.4624 - val_loss: 2600.9038\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 1590.3062 - val_loss: 677.8901\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 597.9588 - val_loss: 448.6942\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 3ms/step - loss: 485.2253 - val_loss: 436.9931\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 463.7190 - val_loss: 421.7624\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 447.5770 - val_loss: 406.3300\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 431.6623 - val_loss: 390.6570\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 415.4876 - val_loss: 377.9077\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 400.9307 - val_loss: 364.4425\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 386.0708 - val_loss: 349.5718\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 3ms/step - loss: 371.2560 - val_loss: 337.1656\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 357.7939 - val_loss: 323.5808\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 343.6093 - val_loss: 313.1169\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 331.1882 - val_loss: 300.2950\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 319.2258 - val_loss: 290.6145\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 307.3782 - val_loss: 279.4178\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 296.2441 - val_loss: 270.0671\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 286.1575 - val_loss: 260.1536\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 277.2433 - val_loss: 253.0896\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 267.1990 - val_loss: 242.5688\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 257.7008 - val_loss: 236.1698\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 249.7915 - val_loss: 229.1961\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 241.5057 - val_loss: 222.3302\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 234.3727 - val_loss: 215.7571\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 227.4667 - val_loss: 210.0111\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 220.5840 - val_loss: 205.0287\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 214.9377 - val_loss: 199.8893\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 208.8572 - val_loss: 195.8598\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 203.6950 - val_loss: 191.8636\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 7ms/step - loss: 198.6606 - val_loss: 187.8459\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 193.9911 - val_loss: 183.7688\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.0270 - val_loss: 180.8020\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 185.6528 - val_loss: 177.2295\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 181.8330 - val_loss: 174.1881\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 9ms/step - loss: 178.3656 - val_loss: 172.0880\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 175.0640 - val_loss: 169.2585\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 171.9893 - val_loss: 167.0950\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.5678 - val_loss: 164.7938\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 166.4323 - val_loss: 162.4089\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 164.3564 - val_loss: 161.2191\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 161.6806 - val_loss: 158.4030\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.0485 - val_loss: 156.8869\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.2423 - val_loss: 155.2520\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 155.0181 - val_loss: 154.6806\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.0012 - val_loss: 152.6283\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 150.8714 - val_loss: 151.1277\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.9228 - val_loss: 149.6025\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 72ms/step - loss: 112772.6484 - val_loss: 70456.3672\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 19ms/step - loss: 45213.9844 - val_loss: 22970.9922\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 13689.4727 - val_loss: 7604.9756\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 6021.3667 - val_loss: 5751.4346\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 10ms/step - loss: 5189.5342 - val_loss: 5422.4521\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 4856.0957 - val_loss: 5061.9019\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 4528.7402 - val_loss: 4720.2041\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 4216.5464 - val_loss: 4407.6562\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 3921.4202 - val_loss: 4103.0742\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 3644.9434 - val_loss: 3821.2517\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 3385.1182 - val_loss: 3553.2949\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 3137.3076 - val_loss: 3303.9768\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2916.6863 - val_loss: 3073.4849\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 2706.1970 - val_loss: 2868.5654\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 3ms/step - loss: 2522.7964 - val_loss: 2666.8916\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 2340.2727 - val_loss: 2488.6121\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 2180.8499 - val_loss: 2325.2144\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 2033.9005 - val_loss: 2173.1750\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 3ms/step - loss: 1900.9797 - val_loss: 2027.0050\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1775.5663 - val_loss: 1902.1589\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1667.6610 - val_loss: 1780.5627\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1563.7422 - val_loss: 1679.3945\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1463.1791 - val_loss: 1567.4512\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 3ms/step - loss: 1372.0063 - val_loss: 1475.9072\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1289.8964 - val_loss: 1388.6781\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1211.7974 - val_loss: 1301.9600\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1137.2933 - val_loss: 1231.9360\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1070.7350 - val_loss: 1158.8341\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1006.8777 - val_loss: 1099.2802\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 951.4513 - val_loss: 1037.2279\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 898.8663 - val_loss: 983.6170\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 850.0082 - val_loss: 931.0068\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 804.8501 - val_loss: 879.3688\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 763.2861 - val_loss: 839.2390\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 725.1906 - val_loss: 791.1534\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 3ms/step - loss: 691.0109 - val_loss: 752.7979\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 655.0132 - val_loss: 716.4350\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 625.2878 - val_loss: 679.6484\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 596.2595 - val_loss: 645.1276\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 570.1212 - val_loss: 615.2041\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 542.1060 - val_loss: 586.6445\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 11ms/step - loss: 518.4693 - val_loss: 559.8216\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 495.7853 - val_loss: 533.9178\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 473.6812 - val_loss: 508.7783\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 3ms/step - loss: 454.1851 - val_loss: 487.0456\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 436.4573 - val_loss: 463.6626\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 419.6755 - val_loss: 448.2324\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 399.8205 - val_loss: 423.1684\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 3ms/step - loss: 384.2405 - val_loss: 405.8098\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 369.6606 - val_loss: 389.6499\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 72ms/step - loss: 89764.4062 - val_loss: 44244.3594\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 24629.0039 - val_loss: 9502.6846\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 5620.1655 - val_loss: 3837.6145\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 3377.5547 - val_loss: 3634.9724\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 3255.8921 - val_loss: 3500.9766\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 3ms/step - loss: 3132.9521 - val_loss: 3351.4221\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 3010.7004 - val_loss: 3218.7434\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 2894.5415 - val_loss: 3076.0403\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 2780.6516 - val_loss: 2955.4958\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - loss: 2648.1011 - val_loss: 2803.2446\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 2532.9255 - val_loss: 2676.6882\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 2424.7542 - val_loss: 2547.5408\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2303.0574 - val_loss: 2431.6836\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 2204.9224 - val_loss: 2308.6123\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 2087.3342 - val_loss: 2187.7034\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1994.0017 - val_loss: 2084.4404\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1894.6790 - val_loss: 1973.7587\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1801.9607 - val_loss: 1869.9213\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1716.7311 - val_loss: 1782.6348\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1632.2817 - val_loss: 1690.8595\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1560.8644 - val_loss: 1600.9512\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1485.5952 - val_loss: 1520.1958\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 9ms/step - loss: 1411.8931 - val_loss: 1455.2423\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 3ms/step - loss: 1347.3732 - val_loss: 1378.8674\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 1286.4314 - val_loss: 1309.7368\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1226.1036 - val_loss: 1246.6311\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 1170.9728 - val_loss: 1187.5647\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1118.5612 - val_loss: 1131.9547\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1070.0337 - val_loss: 1077.6155\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 1023.7723 - val_loss: 1030.4354\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 6ms/step - loss: 980.4761 - val_loss: 984.8262\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 940.2880 - val_loss: 938.2628\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 902.1522 - val_loss: 897.1113\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 863.2073 - val_loss: 851.0674\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 831.4751 - val_loss: 816.0371\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 799.3859 - val_loss: 782.9957\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 761.1663 - val_loss: 749.7352\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 3ms/step - loss: 730.9084 - val_loss: 716.9152\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 701.7704 - val_loss: 685.0611\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 674.9030 - val_loss: 656.0684\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 649.0626 - val_loss: 630.8209\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 622.9702 - val_loss: 602.7142\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 599.7054 - val_loss: 578.3065\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 577.3831 - val_loss: 553.2721\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 555.5786 - val_loss: 534.3224\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 533.7148 - val_loss: 513.6291\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 514.7048 - val_loss: 489.8351\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 495.2467 - val_loss: 470.9851\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 476.5978 - val_loss: 453.9333\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 460.7031 - val_loss: 435.0381\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 63ms/step - loss: 8870.0322 - val_loss: 3051.8462\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 3294.7920 - val_loss: 2461.7354\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 2544.0010 - val_loss: 2111.3975\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 2218.3760 - val_loss: 1827.7611\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1979.3898 - val_loss: 1620.9775\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1772.7549 - val_loss: 1497.7938\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1643.3329 - val_loss: 1391.2704\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1507.4662 - val_loss: 1255.9105\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1403.1849 - val_loss: 1165.3295\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1332.0636 - val_loss: 1115.7025\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1255.5555 - val_loss: 1070.9036\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1203.1870 - val_loss: 1062.9938\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1144.3534 - val_loss: 974.5996\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1091.2822 - val_loss: 926.1395\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1043.6613 - val_loss: 882.9080\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 999.2310 - val_loss: 913.1122\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 954.6275 - val_loss: 807.4131\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 925.2587 - val_loss: 774.4370\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 869.8386 - val_loss: 739.5603\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 821.0563 - val_loss: 710.9338\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 773.5511 - val_loss: 652.1763\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 720.2079 - val_loss: 587.6257\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 655.5722 - val_loss: 534.0663\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 599.5170 - val_loss: 508.6624\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 550.4655 - val_loss: 456.5807\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 505.7148 - val_loss: 421.5720\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 3ms/step - loss: 468.3558 - val_loss: 396.8320\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 433.4579 - val_loss: 375.8145\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 413.1224 - val_loss: 353.1811\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 388.6383 - val_loss: 337.1494\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 369.6325 - val_loss: 316.4844\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 356.1935 - val_loss: 299.9895\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 325.8488 - val_loss: 285.3951\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 308.4436 - val_loss: 272.4935\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 293.9422 - val_loss: 260.0620\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 285.3524 - val_loss: 251.7840\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 277.3756 - val_loss: 237.0776\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 251.5807 - val_loss: 226.5713\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 239.8389 - val_loss: 218.4782\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 3ms/step - loss: 229.3791 - val_loss: 213.2501\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 226.3899 - val_loss: 217.5743\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 211.1656 - val_loss: 194.4213\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 199.4443 - val_loss: 187.9006\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 12ms/step - loss: 192.0021 - val_loss: 186.9639\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 185.6377 - val_loss: 174.5984\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - loss: 177.4962 - val_loss: 167.9016\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 3ms/step - loss: 171.5617 - val_loss: 163.1281\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 164.0986 - val_loss: 171.0049\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.9014 - val_loss: 163.1527\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.3191 - val_loss: 152.3718\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 61ms/step - loss: 11965.1748 - val_loss: 7282.6611\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 6279.9814 - val_loss: 6041.6948\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 3ms/step - loss: 5137.9097 - val_loss: 4911.5015\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 4151.4268 - val_loss: 3987.0369\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 3332.5117 - val_loss: 3197.6257\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 2625.1941 - val_loss: 2527.1692\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 2035.3052 - val_loss: 1941.2878\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1530.8794 - val_loss: 1450.3185\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 3ms/step - loss: 1122.0275 - val_loss: 1080.6952\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 818.4707 - val_loss: 805.6780\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 605.1750 - val_loss: 608.0034\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 461.1098 - val_loss: 478.7481\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 364.9043 - val_loss: 385.2765\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 3ms/step - loss: 299.7073 - val_loss: 318.9561\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 253.4790 - val_loss: 272.3723\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 221.4662 - val_loss: 243.4520\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 3ms/step - loss: 199.9455 - val_loss: 224.1991\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 184.1854 - val_loss: 206.8153\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.6534 - val_loss: 198.7824\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.4936 - val_loss: 183.3487\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 155.0166 - val_loss: 174.1369\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 10ms/step - loss: 149.1593 - val_loss: 168.5408\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.6127 - val_loss: 163.9616\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.0422 - val_loss: 157.4317\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.9377 - val_loss: 153.7938\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 3ms/step - loss: 134.0665 - val_loss: 151.7801\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.0358 - val_loss: 147.3477\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.6266 - val_loss: 145.7741\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.3427 - val_loss: 142.8704\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 128.1306 - val_loss: 140.7810\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.7508 - val_loss: 138.8950\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 122.9461 - val_loss: 138.8460\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.9683 - val_loss: 136.7264\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.5880 - val_loss: 134.7375\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 3ms/step - loss: 123.1500 - val_loss: 134.9072\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 118.6114 - val_loss: 133.4135\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 116.9202 - val_loss: 132.3273\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.7274 - val_loss: 131.1775\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 115.4958 - val_loss: 130.3528\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.5222 - val_loss: 132.8790\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.3749 - val_loss: 129.0817\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.6684 - val_loss: 128.3312\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.2838 - val_loss: 130.9437\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.6692 - val_loss: 130.1199\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.9309 - val_loss: 129.5170\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 110.5167 - val_loss: 130.5222\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.2466 - val_loss: 125.7749\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 110.0816 - val_loss: 125.5487\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 110.3008 - val_loss: 126.7027\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.3997 - val_loss: 124.8338\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 65ms/step - loss: 555875.4375 - val_loss: 435133.0000\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 356931.5625 - val_loss: 278994.2812\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 224312.5156 - val_loss: 169803.7344\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 131320.6719 - val_loss: 94269.6016\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 69961.7734 - val_loss: 47826.0273\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 33903.5547 - val_loss: 21973.6289\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 7ms/step - loss: 14995.5547 - val_loss: 9603.8926\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 6614.8906 - val_loss: 4525.4780\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 3433.4771 - val_loss: 2802.7136\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - loss: 2459.0183 - val_loss: 2285.4429\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 2186.2856 - val_loss: 2132.3428\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 2090.3384 - val_loss: 2074.7341\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2042.5330 - val_loss: 2027.7494\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 2002.6951 - val_loss: 1984.5392\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1961.1312 - val_loss: 1942.9249\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1921.3892 - val_loss: 1904.1860\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1880.7798 - val_loss: 1860.7522\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1840.1051 - val_loss: 1818.9901\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1800.3804 - val_loss: 1781.7451\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1761.7573 - val_loss: 1737.4359\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1721.3782 - val_loss: 1700.9510\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1684.2347 - val_loss: 1662.3168\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1647.0796 - val_loss: 1624.6375\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1609.8284 - val_loss: 1588.0254\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 3ms/step - loss: 1571.7307 - val_loss: 1550.2025\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1534.4674 - val_loss: 1513.2341\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1496.0985 - val_loss: 1472.4523\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1456.5969 - val_loss: 1432.6722\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1418.2605 - val_loss: 1395.6393\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 1382.6866 - val_loss: 1357.5450\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 1344.9553 - val_loss: 1321.4417\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 1312.0383 - val_loss: 1289.1200\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 3ms/step - loss: 1276.8275 - val_loss: 1256.7296\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 1243.8341 - val_loss: 1222.4391\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 1212.8082 - val_loss: 1194.3835\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 1183.6914 - val_loss: 1165.6689\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 3ms/step - loss: 1155.3875 - val_loss: 1136.6035\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 1128.8260 - val_loss: 1112.3877\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 1098.9304 - val_loss: 1079.6589\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 1070.0957 - val_loss: 1052.6902\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 3ms/step - loss: 1041.4482 - val_loss: 1027.1683\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 1015.7715 - val_loss: 1000.6567\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 989.1329 - val_loss: 976.3759\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 11ms/step - loss: 962.9116 - val_loss: 950.4798\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 940.0828 - val_loss: 926.2747\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 914.7026 - val_loss: 900.8019\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 3ms/step - loss: 889.0142 - val_loss: 877.1381\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 862.0731 - val_loss: 852.3308\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 835.8566 - val_loss: 828.1585\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 3ms/step - loss: 811.0009 - val_loss: 802.3253\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 59ms/step - loss: 311194.7500 - val_loss: 225880.7031\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 3ms/step - loss: 157481.9688 - val_loss: 107361.5391\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 70159.3125 - val_loss: 44535.6875\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 27021.0938 - val_loss: 15988.7705\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 10459.1553 - val_loss: 7175.2510\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 6808.0693 - val_loss: 6080.4663\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 6337.5215 - val_loss: 5878.4165\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 6071.9390 - val_loss: 5704.2529\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 5832.3999 - val_loss: 5529.3496\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - loss: 5627.4302 - val_loss: 5374.2852\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 5436.1416 - val_loss: 5239.9346\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 5257.6338 - val_loss: 5093.4512\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 5098.1689 - val_loss: 4960.3940\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 8ms/step - loss: 4943.9912 - val_loss: 4859.7480\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 4804.0234 - val_loss: 4740.2559\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 4674.6602 - val_loss: 4629.7251\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 4552.5542 - val_loss: 4505.1899\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 4426.6255 - val_loss: 4425.8315\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 4321.2778 - val_loss: 4305.0005\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 4208.8799 - val_loss: 4220.7510\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 3ms/step - loss: 4100.2451 - val_loss: 4120.1602\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 10ms/step - loss: 4004.4158 - val_loss: 4024.0110\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 3901.0566 - val_loss: 3934.4539\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 3809.4375 - val_loss: 3856.8770\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 3714.2393 - val_loss: 3753.6108\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 3625.9500 - val_loss: 3676.8140\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 3537.3013 - val_loss: 3606.2007\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 3461.9546 - val_loss: 3499.4150\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 3369.9668 - val_loss: 3432.0171\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 3ms/step - loss: 3296.1199 - val_loss: 3361.5386\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 3222.5398 - val_loss: 3260.3979\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 3136.2590 - val_loss: 3202.8735\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 3066.3364 - val_loss: 3127.8850\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 3ms/step - loss: 2988.2725 - val_loss: 3039.2812\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 2915.8984 - val_loss: 2971.8347\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 2846.9392 - val_loss: 2902.3491\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 2777.6384 - val_loss: 2821.7451\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 2720.4343 - val_loss: 2758.1301\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 2647.4126 - val_loss: 2690.6118\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 2588.0952 - val_loss: 2628.5232\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 2524.4082 - val_loss: 2551.4495\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 2463.0686 - val_loss: 2485.3474\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 2407.1375 - val_loss: 2433.8108\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 2349.6675 - val_loss: 2369.2117\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 2295.5195 - val_loss: 2312.1143\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 2240.4446 - val_loss: 2258.9998\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 2187.4614 - val_loss: 2202.3989\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 2139.7598 - val_loss: 2149.7820\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 2085.6277 - val_loss: 2081.9150\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 2031.1328 - val_loss: 2038.8926\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 66ms/step - loss: 2417.6467 - val_loss: 2345.7471\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1698.7402 - val_loss: 1775.6564\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1241.0350 - val_loss: 1352.2264\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 910.5501 - val_loss: 1008.8693\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 630.9886 - val_loss: 650.6239\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 448.4110 - val_loss: 465.3025\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 340.2526 - val_loss: 356.1175\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 266.3435 - val_loss: 282.8892\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 217.8471 - val_loss: 238.6903\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 187.3923 - val_loss: 204.8359\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.2059 - val_loss: 179.7631\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.2503 - val_loss: 167.9872\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.5859 - val_loss: 153.7574\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 8ms/step - loss: 135.8720 - val_loss: 145.8752\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 128.0893 - val_loss: 140.6978\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.7452 - val_loss: 137.9173\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 122.1011 - val_loss: 131.9545\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.6256 - val_loss: 129.9939\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.3259 - val_loss: 126.9373\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 112.8053 - val_loss: 124.0229\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.4484 - val_loss: 123.0984\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 9ms/step - loss: 111.0573 - val_loss: 122.2817\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 113.0944 - val_loss: 120.3914\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.2031 - val_loss: 121.1268\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 114.3641 - val_loss: 118.9400\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.8326 - val_loss: 117.0731\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 107.1844 - val_loss: 124.7065\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 107.1939 - val_loss: 115.7647\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 104.5726 - val_loss: 114.8604\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 104.4527 - val_loss: 112.4581\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 104.7379 - val_loss: 118.3156\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 102.2181 - val_loss: 115.0975\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 100.6506 - val_loss: 110.2223\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 99.7943 - val_loss: 110.0175\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 99.7995 - val_loss: 108.6827\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 98.5598 - val_loss: 108.3081\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 97.3211 - val_loss: 106.7731\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 97.1703 - val_loss: 107.5706\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 100.8794 - val_loss: 106.2358\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 95.6007 - val_loss: 106.3524\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 95.0853 - val_loss: 107.5498\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 7ms/step - loss: 96.8938 - val_loss: 107.6456\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 98.8394 - val_loss: 103.2682\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 95.2665 - val_loss: 103.1796\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 97.1005 - val_loss: 106.2554\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 10ms/step - loss: 91.6515 - val_loss: 102.1614\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 8ms/step - loss: 95.7337 - val_loss: 107.2118\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 93.6401 - val_loss: 101.2934\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 91.2782 - val_loss: 101.6946\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 90.4413 - val_loss: 99.6794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 63ms/step - loss: 575952.6250 - val_loss: 470318.5000\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 396703.8750 - val_loss: 318770.8750\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 3ms/step - loss: 266737.5625 - val_loss: 210943.5625\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 175221.9688 - val_loss: 136158.1719\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 112161.1641 - val_loss: 85357.5547\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 69731.7734 - val_loss: 51876.1367\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 42131.1562 - val_loss: 30507.5566\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 24721.8633 - val_loss: 17396.3066\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 14119.9639 - val_loss: 9809.8281\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 7998.5830 - val_loss: 5480.2241\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 4553.3516 - val_loss: 3158.8862\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 9ms/step - loss: 2708.0039 - val_loss: 1981.7498\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1782.9801 - val_loss: 1412.8396\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1325.9524 - val_loss: 1166.6388\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 1119.2614 - val_loss: 1060.9956\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1026.9612 - val_loss: 1021.0417\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 985.7605 - val_loss: 1004.7809\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 963.1357 - val_loss: 997.9661\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 950.0190 - val_loss: 991.1932\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 939.8783 - val_loss: 985.3467\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 3ms/step - loss: 930.1747 - val_loss: 979.0740\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 921.3124 - val_loss: 971.8100\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 912.1342 - val_loss: 964.6118\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 903.4051 - val_loss: 956.2646\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 894.2871 - val_loss: 948.9966\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 885.7267 - val_loss: 940.8829\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 876.4358 - val_loss: 932.6741\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 11ms/step - loss: 867.4265 - val_loss: 923.9476\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 7ms/step - loss: 858.1000 - val_loss: 915.5095\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 849.4918 - val_loss: 908.1910\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 8ms/step - loss: 839.4092 - val_loss: 899.8690\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 830.0458 - val_loss: 890.7581\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 820.7564 - val_loss: 881.3710\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 811.5272 - val_loss: 872.4631\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 804.1160 - val_loss: 862.4350\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 8ms/step - loss: 792.9903 - val_loss: 856.6198\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 784.1613 - val_loss: 848.5694\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 775.3705 - val_loss: 839.5653\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 766.6246 - val_loss: 831.6042\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 757.9728 - val_loss: 822.8893\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 749.5396 - val_loss: 814.2456\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 740.8282 - val_loss: 805.2552\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 732.8152 - val_loss: 797.3298\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 8ms/step - loss: 723.7557 - val_loss: 789.9427\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 715.6628 - val_loss: 780.9116\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 707.5342 - val_loss: 774.7290\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 699.0502 - val_loss: 765.1962\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 3ms/step - loss: 691.3508 - val_loss: 757.4647\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 683.6398 - val_loss: 749.6008\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 675.5352 - val_loss: 742.0936\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 65ms/step - loss: 169900.3125 - val_loss: 121711.5234\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 90065.7422 - val_loss: 57415.3906\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 36845.9805 - val_loss: 18766.6328\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 11473.0898 - val_loss: 8968.4043\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 7261.6729 - val_loss: 8250.0488\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 6432.4590 - val_loss: 7351.5767\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 5808.9263 - val_loss: 6623.8618\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 3ms/step - loss: 5282.1675 - val_loss: 6049.1143\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 4807.4434 - val_loss: 5547.3530\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 4405.4995 - val_loss: 5097.4146\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 4043.5603 - val_loss: 4661.4448\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 3709.8887 - val_loss: 4308.2261\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 3418.1707 - val_loss: 3953.7979\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 3ms/step - loss: 3158.7593 - val_loss: 3658.7039\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 2925.7632 - val_loss: 3403.6189\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 2719.6614 - val_loss: 3139.2473\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 2533.3860 - val_loss: 2905.6311\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 3ms/step - loss: 2353.0137 - val_loss: 2715.3384\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 2203.8679 - val_loss: 2522.0430\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 2064.1636 - val_loss: 2357.5620\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1934.7047 - val_loss: 2200.6396\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 1814.9847 - val_loss: 2064.4138\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1710.7489 - val_loss: 1932.4086\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1610.6560 - val_loss: 1812.0129\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 7ms/step - loss: 1518.2958 - val_loss: 1703.3214\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 1436.2426 - val_loss: 1605.5984\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1358.0688 - val_loss: 1512.0436\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 3ms/step - loss: 1283.3081 - val_loss: 1423.8507\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1217.2065 - val_loss: 1345.7146\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 1155.7208 - val_loss: 1272.5940\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 1098.2043 - val_loss: 1200.9113\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 1044.5608 - val_loss: 1139.6027\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 992.8296 - val_loss: 1081.9423\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 946.5839 - val_loss: 1027.6979\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 903.4199 - val_loss: 975.8658\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 862.6871 - val_loss: 929.2434\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 823.3574 - val_loss: 886.0020\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 789.2795 - val_loss: 845.1014\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 754.3312 - val_loss: 806.4775\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 723.7384 - val_loss: 770.3544\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 692.9365 - val_loss: 738.1552\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 665.2252 - val_loss: 705.9365\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 638.6254 - val_loss: 676.6429\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 3ms/step - loss: 613.2554 - val_loss: 647.7820\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 590.7335 - val_loss: 622.3897\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 569.8192 - val_loss: 596.6166\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 9ms/step - loss: 545.3706 - val_loss: 574.8676\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 526.5181 - val_loss: 549.8687\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 506.5306 - val_loss: 529.8932\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 487.4739 - val_loss: 507.3994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 62ms/step - loss: 7816.2744 - val_loss: 5715.0601\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 5092.5747 - val_loss: 4029.7463\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 3773.5933 - val_loss: 3057.3357\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 3006.2698 - val_loss: 2531.8953\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 2533.3250 - val_loss: 2192.4172\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 2162.1155 - val_loss: 1895.4982\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1869.6837 - val_loss: 1665.5892\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1654.6362 - val_loss: 1447.1342\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1426.3079 - val_loss: 1267.4817\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1232.2278 - val_loss: 1071.2728\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1051.9464 - val_loss: 938.6385\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 927.7847 - val_loss: 833.7916\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 835.2605 - val_loss: 753.8625\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 3ms/step - loss: 735.4474 - val_loss: 682.5910\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 670.7623 - val_loss: 627.0615\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 610.9043 - val_loss: 580.8486\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 559.4674 - val_loss: 539.9731\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 520.0582 - val_loss: 531.4771\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 482.5750 - val_loss: 453.5423\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 438.3658 - val_loss: 422.2487\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 407.2928 - val_loss: 401.5616\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 386.2805 - val_loss: 373.4129\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 362.2722 - val_loss: 370.0115\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 343.6369 - val_loss: 336.4409\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 320.8533 - val_loss: 335.3461\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 10ms/step - loss: 303.3167 - val_loss: 298.7824\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 279.7699 - val_loss: 290.3392\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 271.8106 - val_loss: 280.5808\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 249.3780 - val_loss: 259.2385\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 239.9975 - val_loss: 249.6613\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 228.6089 - val_loss: 237.3627\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 216.4762 - val_loss: 230.0694\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 206.3283 - val_loss: 219.3518\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 200.4123 - val_loss: 211.9030\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 192.6296 - val_loss: 205.3349\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 184.5529 - val_loss: 204.1833\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 177.1048 - val_loss: 195.4834\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 172.1739 - val_loss: 186.0981\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.3533 - val_loss: 183.5514\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.6668 - val_loss: 177.6253\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.9681 - val_loss: 182.8740\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.2847 - val_loss: 178.2926\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 155.5793 - val_loss: 169.0767\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.2871 - val_loss: 165.6158\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 145.3205 - val_loss: 159.1046\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.9482 - val_loss: 155.9283\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.3092 - val_loss: 154.3809\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.0729 - val_loss: 153.0854\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.8001 - val_loss: 149.0588\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.3264 - val_loss: 147.4475\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 65ms/step - loss: 72996.1250 - val_loss: 41167.7422\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 26550.5723 - val_loss: 11017.4980\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 6649.4121 - val_loss: 2381.9622\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1914.0265 - val_loss: 1471.4226\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 1473.0231 - val_loss: 1482.6249\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1400.4275 - val_loss: 1384.7369\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1322.3864 - val_loss: 1309.2845\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1248.0261 - val_loss: 1236.7532\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1175.5017 - val_loss: 1167.3129\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1102.8776 - val_loss: 1098.5488\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1035.6401 - val_loss: 1027.0961\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 964.1336 - val_loss: 971.2763\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 898.3841 - val_loss: 912.1984\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 836.6716 - val_loss: 850.5925\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 778.3001 - val_loss: 800.3381\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 724.8347 - val_loss: 749.1417\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 673.6868 - val_loss: 708.8550\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 626.6243 - val_loss: 661.2502\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 585.0966 - val_loss: 620.4117\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 546.1891 - val_loss: 587.5067\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 512.0526 - val_loss: 556.4662\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 482.8004 - val_loss: 525.4335\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 453.9564 - val_loss: 503.1972\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 430.4589 - val_loss: 481.0482\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 408.8481 - val_loss: 462.0046\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 390.8271 - val_loss: 449.4715\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 374.2103 - val_loss: 425.4328\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 360.6405 - val_loss: 412.9090\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 347.9185 - val_loss: 407.0851\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 335.7805 - val_loss: 392.0446\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 328.2224 - val_loss: 383.3675\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 318.0148 - val_loss: 371.1106\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 312.0713 - val_loss: 369.5719\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 305.1779 - val_loss: 360.2026\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 298.3898 - val_loss: 349.5928\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 293.4093 - val_loss: 352.2356\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 288.9250 - val_loss: 343.5757\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 283.3863 - val_loss: 337.2137\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 279.0454 - val_loss: 332.0018\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 275.0514 - val_loss: 324.5760\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 270.9184 - val_loss: 321.3031\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 267.7829 - val_loss: 313.1586\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 264.4575 - val_loss: 311.6345\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 3ms/step - loss: 259.7830 - val_loss: 306.3526\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 9ms/step - loss: 256.7090 - val_loss: 305.6762\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 254.2488 - val_loss: 295.8867\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 250.1995 - val_loss: 296.3748\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 3ms/step - loss: 247.0046 - val_loss: 290.9184\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 244.5274 - val_loss: 287.3260\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 241.2742 - val_loss: 281.9801\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 62ms/step - loss: 2101.1018 - val_loss: 1365.2529\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1310.7100 - val_loss: 1052.1879\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1081.3701 - val_loss: 901.2021\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 938.0900 - val_loss: 784.8766\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 817.2541 - val_loss: 679.6205\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 715.1584 - val_loss: 594.3281\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 622.7546 - val_loss: 522.5355\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 542.4522 - val_loss: 454.7134\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 477.1481 - val_loss: 395.9798\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 417.1801 - val_loss: 346.9668\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 358.9533 - val_loss: 307.0542\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 309.4919 - val_loss: 278.6627\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 275.1566 - val_loss: 251.3431\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 248.4300 - val_loss: 231.1392\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 225.6932 - val_loss: 217.4366\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 210.6377 - val_loss: 205.0644\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 195.9604 - val_loss: 197.3018\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 185.3223 - val_loss: 190.6998\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 176.0383 - val_loss: 187.6070\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 168.4609 - val_loss: 180.8173\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.0855 - val_loss: 177.2169\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 158.9603 - val_loss: 177.5227\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 154.8226 - val_loss: 169.9921\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.3009 - val_loss: 168.2921\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.6736 - val_loss: 166.1366\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 14ms/step - loss: 143.4775 - val_loss: 164.7353\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.7252 - val_loss: 163.9146\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 3ms/step - loss: 139.2527 - val_loss: 159.6453\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.4816 - val_loss: 156.4754\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.9142 - val_loss: 157.3276\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.2341 - val_loss: 153.8767\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.1876 - val_loss: 155.9031\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 130.1338 - val_loss: 151.2280\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.2919 - val_loss: 149.6796\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.9110 - val_loss: 149.2668\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.7458 - val_loss: 148.3672\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 124.3952 - val_loss: 149.7316\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 122.0958 - val_loss: 150.7582\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 121.2326 - val_loss: 145.9918\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 119.3716 - val_loss: 143.5368\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 3ms/step - loss: 117.8475 - val_loss: 144.0386\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 118.7432 - val_loss: 143.0922\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.8135 - val_loss: 142.1689\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 3ms/step - loss: 115.8109 - val_loss: 141.5317\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.6634 - val_loss: 143.1983\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.8471 - val_loss: 140.3036\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 113.6663 - val_loss: 139.5193\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.1496 - val_loss: 144.6366\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.9341 - val_loss: 138.2522\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.5338 - val_loss: 149.2166\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 134ms/step - loss: 201525.2188 - val_loss: 144666.8125\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 108695.7109 - val_loss: 71603.5859\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 51991.0859 - val_loss: 32278.2305\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 23858.8770 - val_loss: 15252.1973\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 12702.6641 - val_loss: 9457.5410\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 9193.9092 - val_loss: 7928.4658\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 8292.3936 - val_loss: 7493.9395\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 7908.4458 - val_loss: 7235.6924\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 7623.2920 - val_loss: 6963.7979\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 7259.9258 - val_loss: 6460.8574\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 6523.5615 - val_loss: 5683.9312\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 8ms/step - loss: 5754.0835 - val_loss: 4971.1968\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 4993.4336 - val_loss: 4283.0747\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 4297.4531 - val_loss: 3654.8022\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 3634.8335 - val_loss: 3092.7542\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 3057.8069 - val_loss: 2601.0464\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 2551.1621 - val_loss: 2172.2212\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 2120.9277 - val_loss: 1829.0376\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1766.6476 - val_loss: 1519.0465\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 3ms/step - loss: 1473.2932 - val_loss: 1284.8345\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1223.6041 - val_loss: 1100.9603\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1033.9568 - val_loss: 943.2062\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 884.5156 - val_loss: 830.9957\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 6ms/step - loss: 768.1597 - val_loss: 737.0332\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 675.7983 - val_loss: 667.0488\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 608.9425 - val_loss: 607.1921\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 549.4135 - val_loss: 563.0476\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 506.1412 - val_loss: 523.3815\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 467.4897 - val_loss: 495.9585\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 437.6013 - val_loss: 475.6672\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 411.9105 - val_loss: 446.6520\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 388.8223 - val_loss: 431.5222\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 371.1763 - val_loss: 409.1516\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 353.1768 - val_loss: 388.3953\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 336.2630 - val_loss: 395.9333\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 324.0116 - val_loss: 371.0710\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 3ms/step - loss: 308.5766 - val_loss: 348.9632\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 297.3332 - val_loss: 345.2382\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 285.1975 - val_loss: 335.7613\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 274.8893 - val_loss: 314.4647\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 269.1893 - val_loss: 307.0977\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 9ms/step - loss: 254.1808 - val_loss: 300.0808\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 246.5359 - val_loss: 297.0775\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 238.6914 - val_loss: 289.1998\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 229.8518 - val_loss: 276.0981\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 221.9472 - val_loss: 265.0472\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 215.3400 - val_loss: 265.3110\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 208.0640 - val_loss: 252.1673\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 202.2694 - val_loss: 249.3918\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 196.7256 - val_loss: 244.3112\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 59ms/step - loss: 308568.2812 - val_loss: 258694.6562\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 213350.8281 - val_loss: 176723.6719\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 143684.3750 - val_loss: 118005.3828\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 94663.2109 - val_loss: 77152.3594\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 6ms/step - loss: 60951.2383 - val_loss: 49537.5547\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 38651.6914 - val_loss: 31377.6738\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 24311.9824 - val_loss: 20046.6562\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 15621.6445 - val_loss: 13398.7676\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 10651.5596 - val_loss: 9637.8467\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 7979.2471 - val_loss: 7608.7744\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 6601.6367 - val_loss: 6552.9038\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 5899.7261 - val_loss: 5999.6284\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 5532.4917 - val_loss: 5690.5527\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 5315.8125 - val_loss: 5482.1216\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 5160.4868 - val_loss: 5305.5024\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 5004.1885 - val_loss: 5141.0767\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 4851.2012 - val_loss: 4988.4565\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 4701.5874 - val_loss: 4847.0840\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 4549.7925 - val_loss: 4712.0566\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 4397.0029 - val_loss: 4561.3730\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 4220.6436 - val_loss: 4398.2476\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 11ms/step - loss: 4023.0142 - val_loss: 4201.5034\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 3838.6990 - val_loss: 4032.6016\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 3693.3252 - val_loss: 3900.1035\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 3576.7905 - val_loss: 3784.2703\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 3461.9456 - val_loss: 3673.8621\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 3324.9207 - val_loss: 3550.1174\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 3178.5859 - val_loss: 3415.8806\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 3023.4578 - val_loss: 3227.4475\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 2804.1665 - val_loss: 2939.9736\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 2515.8447 - val_loss: 2601.9800\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 2220.6624 - val_loss: 2265.7336\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 1931.8845 - val_loss: 1989.1558\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 1702.1272 - val_loss: 1748.2496\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 1493.6177 - val_loss: 1548.4443\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 1322.0703 - val_loss: 1370.4506\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 1181.6790 - val_loss: 1210.8052\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 1054.1237 - val_loss: 1074.3175\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 944.8377 - val_loss: 952.7440\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 841.4077 - val_loss: 850.6031\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 758.9551 - val_loss: 758.8734\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 685.2084 - val_loss: 681.2771\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 625.8531 - val_loss: 623.6550\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 564.8803 - val_loss: 563.9008\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 517.7367 - val_loss: 515.0274\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 8ms/step - loss: 474.6522 - val_loss: 468.0818\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 437.8554 - val_loss: 433.5236\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 405.3341 - val_loss: 397.7628\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 376.0085 - val_loss: 368.9579\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 347.9029 - val_loss: 343.7423\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 72ms/step - loss: 27055.3223 - val_loss: 16782.1016\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 9364.8203 - val_loss: 6353.2773\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 4519.2603 - val_loss: 4133.8506\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 3861.0776 - val_loss: 3769.2642\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 3695.9719 - val_loss: 3640.0393\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 3535.5786 - val_loss: 3489.9016\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 3381.4917 - val_loss: 3337.0676\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 3224.4783 - val_loss: 3138.7117\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 2939.6887 - val_loss: 2884.8579\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 2635.1667 - val_loss: 2561.2407\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 2359.9104 - val_loss: 2270.4875\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 3ms/step - loss: 2097.6724 - val_loss: 1988.1058\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1862.4126 - val_loss: 1752.9701\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1645.0082 - val_loss: 1557.3400\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1452.0543 - val_loss: 1356.2239\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1276.8823 - val_loss: 1207.5947\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1121.7675 - val_loss: 1044.0353\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 989.5023 - val_loss: 923.2962\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 861.0032 - val_loss: 809.7875\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 754.1626 - val_loss: 709.5352\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 661.6778 - val_loss: 624.4330\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 582.1575 - val_loss: 542.9560\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 515.4429 - val_loss: 467.0326\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 460.4774 - val_loss: 422.2021\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 407.2751 - val_loss: 385.6618\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 3ms/step - loss: 364.6104 - val_loss: 339.6165\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 331.8639 - val_loss: 321.1904\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 302.2671 - val_loss: 290.0598\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 277.8036 - val_loss: 264.8649\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 9ms/step - loss: 257.1048 - val_loss: 257.3422\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 3ms/step - loss: 239.6056 - val_loss: 240.2608\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 224.6577 - val_loss: 222.5933\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 213.1425 - val_loss: 210.1615\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 202.1236 - val_loss: 201.2247\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 192.2157 - val_loss: 195.9489\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 3ms/step - loss: 184.5051 - val_loss: 187.0875\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 178.1005 - val_loss: 180.1634\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 170.7918 - val_loss: 179.2240\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 164.6418 - val_loss: 169.3051\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 3ms/step - loss: 162.3839 - val_loss: 166.1120\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 155.5296 - val_loss: 160.8223\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.4005 - val_loss: 165.7567\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.9179 - val_loss: 154.0176\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 9ms/step - loss: 147.5565 - val_loss: 153.5493\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.0428 - val_loss: 148.3988\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.7524 - val_loss: 145.3501\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 137.2199 - val_loss: 143.8762\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.2945 - val_loss: 150.5086\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 9ms/step - loss: 135.8311 - val_loss: 137.8826\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.4848 - val_loss: 139.0558\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 62ms/step - loss: 19773.4805 - val_loss: 3583.8474\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 3247.9058 - val_loss: 3059.9805\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 2261.4116 - val_loss: 2477.6028\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1914.8555 - val_loss: 2081.1750\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 1632.3652 - val_loss: 1784.8162\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1394.7704 - val_loss: 1518.2063\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1194.2380 - val_loss: 1301.0983\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1029.0120 - val_loss: 1102.4708\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 876.5314 - val_loss: 937.8220\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 755.2338 - val_loss: 804.7203\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 658.9805 - val_loss: 696.1377\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 9ms/step - loss: 580.3381 - val_loss: 610.3811\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 517.9055 - val_loss: 539.1307\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 463.8238 - val_loss: 475.3129\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 420.2735 - val_loss: 425.4572\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 384.2654 - val_loss: 385.2395\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 353.7634 - val_loss: 352.9248\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 329.8731 - val_loss: 321.9987\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 304.4462 - val_loss: 295.1338\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 283.3343 - val_loss: 273.0908\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 266.8224 - val_loss: 254.1704\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 250.3837 - val_loss: 238.5142\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 235.8176 - val_loss: 237.8565\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 220.3130 - val_loss: 210.0695\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 210.2418 - val_loss: 200.6081\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 8ms/step - loss: 198.7288 - val_loss: 186.2262\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 3ms/step - loss: 187.6612 - val_loss: 176.5409\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 179.0609 - val_loss: 169.0877\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 8ms/step - loss: 172.6150 - val_loss: 160.2945\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 3ms/step - loss: 163.7432 - val_loss: 153.6041\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.8363 - val_loss: 148.4340\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.7276 - val_loss: 143.8235\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 147.1230 - val_loss: 141.3919\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 142.6559 - val_loss: 139.3373\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 3ms/step - loss: 137.5401 - val_loss: 131.0224\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.4787 - val_loss: 127.5589\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.0735 - val_loss: 126.0019\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.7481 - val_loss: 120.8147\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 123.7411 - val_loss: 118.4498\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.7635 - val_loss: 118.8805\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 3ms/step - loss: 120.8864 - val_loss: 118.7123\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 118.6410 - val_loss: 113.1799\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.9391 - val_loss: 111.1617\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.2479 - val_loss: 119.3211\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 3ms/step - loss: 114.0266 - val_loss: 110.2159\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 11ms/step - loss: 114.7060 - val_loss: 109.1179\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 108.7897 - val_loss: 124.1278\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.3578 - val_loss: 111.3598\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.1461 - val_loss: 107.6144\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 108.0660 - val_loss: 106.4127\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 58ms/step - loss: 193302.5469 - val_loss: 121589.8516\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 86871.7969 - val_loss: 46775.0000\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 30826.5801 - val_loss: 14302.0693\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 7ms/step - loss: 10705.2549 - val_loss: 7270.2202\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 7423.4526 - val_loss: 6748.3120\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 6925.3149 - val_loss: 6295.2124\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 6503.0869 - val_loss: 5871.0894\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 6ms/step - loss: 6075.0811 - val_loss: 5491.8550\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 5690.5342 - val_loss: 5100.8291\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 5313.9097 - val_loss: 4751.1758\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 4960.7075 - val_loss: 4431.6064\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 4618.7661 - val_loss: 4087.6226\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 4297.0278 - val_loss: 3795.5549\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 4006.0625 - val_loss: 3506.3423\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 3713.9612 - val_loss: 3234.7354\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 3437.0864 - val_loss: 3002.7588\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 3195.3706 - val_loss: 2767.4927\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 2952.3572 - val_loss: 2555.4385\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 2730.5310 - val_loss: 2351.4644\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 2524.9285 - val_loss: 2162.1423\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 2330.7083 - val_loss: 2002.2762\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 2161.3694 - val_loss: 1849.8362\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 2000.0970 - val_loss: 1715.6072\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 1854.9060 - val_loss: 1585.1176\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1721.9688 - val_loss: 1480.3824\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1603.4983 - val_loss: 1371.1708\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1497.6185 - val_loss: 1278.0154\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 10ms/step - loss: 1394.2365 - val_loss: 1197.1665\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 1303.6503 - val_loss: 1130.3883\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 1223.1326 - val_loss: 1057.1063\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 1152.3638 - val_loss: 997.0513\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 1081.9062 - val_loss: 942.3961\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 1019.4812 - val_loss: 894.9333\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 963.6113 - val_loss: 847.2145\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 909.1281 - val_loss: 809.1536\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 868.2568 - val_loss: 767.1454\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 818.3051 - val_loss: 732.4891\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 779.7390 - val_loss: 698.1866\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 740.7733 - val_loss: 669.7281\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 705.8441 - val_loss: 641.0201\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 674.0472 - val_loss: 614.4763\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 646.1168 - val_loss: 590.5765\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 620.3983 - val_loss: 565.7172\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 590.5141 - val_loss: 545.3743\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 567.4919 - val_loss: 526.5034\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 546.4056 - val_loss: 509.1867\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 528.6410 - val_loss: 492.0827\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 506.2360 - val_loss: 476.8607\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 490.0192 - val_loss: 460.9989\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 472.2307 - val_loss: 447.6665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 316198.7500 - val_loss: 232932.2656\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 172641.6094 - val_loss: 119483.9453\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 83183.5859 - val_loss: 53373.1719\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 34077.0547 - val_loss: 19925.2891\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 11378.9902 - val_loss: 6262.8394\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 3339.2349 - val_loss: 2040.3723\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1248.4250 - val_loss: 1170.5068\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 902.6002 - val_loss: 1021.6733\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 857.5965 - val_loss: 991.8950\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 843.2706 - val_loss: 981.4650\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 831.4862 - val_loss: 972.6567\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 819.0572 - val_loss: 958.2816\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 807.1101 - val_loss: 948.2390\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 795.6204 - val_loss: 933.7639\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 783.5684 - val_loss: 923.7968\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 772.1083 - val_loss: 915.8281\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 761.0091 - val_loss: 903.3813\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 3ms/step - loss: 749.6652 - val_loss: 891.1275\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 738.8550 - val_loss: 881.8271\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 728.3920 - val_loss: 871.5773\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 718.1021 - val_loss: 863.3188\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 709.2037 - val_loss: 850.1051\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 699.1348 - val_loss: 844.8041\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 689.8243 - val_loss: 831.5856\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 680.5671 - val_loss: 828.0941\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 671.6143 - val_loss: 814.9592\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 664.3921 - val_loss: 804.7242\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 656.5499 - val_loss: 799.4112\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 646.9899 - val_loss: 786.8477\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 638.6929 - val_loss: 782.3016\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 3ms/step - loss: 631.3087 - val_loss: 772.3477\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 624.1033 - val_loss: 762.9786\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 616.2656 - val_loss: 759.0574\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 609.2949 - val_loss: 747.0527\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 603.6503 - val_loss: 741.0917\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 595.7411 - val_loss: 731.5958\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 589.8498 - val_loss: 724.1312\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 583.7618 - val_loss: 717.4721\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 576.7377 - val_loss: 710.1165\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 571.7488 - val_loss: 704.4119\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 568.3222 - val_loss: 703.4069\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 10ms/step - loss: 557.0344 - val_loss: 684.1353\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 553.4942 - val_loss: 682.1418\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 546.3489 - val_loss: 677.0455\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 540.2251 - val_loss: 667.9882\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - loss: 535.2135 - val_loss: 658.2478\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 529.1886 - val_loss: 655.1555\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 523.8426 - val_loss: 648.1801\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 518.6270 - val_loss: 639.7371\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 512.5632 - val_loss: 633.6768\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 59ms/step - loss: 114877.3125 - val_loss: 65987.5547\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 6ms/step - loss: 40490.3359 - val_loss: 18221.4199\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 11143.0293 - val_loss: 7641.4375\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 6900.2280 - val_loss: 6930.8999\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 6183.1665 - val_loss: 6100.5483\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 3ms/step - loss: 5498.2373 - val_loss: 5407.3457\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 4878.8633 - val_loss: 4774.9443\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 3ms/step - loss: 4314.5581 - val_loss: 4185.0728\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 3779.6458 - val_loss: 3677.1780\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 3304.4258 - val_loss: 3204.7913\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 3ms/step - loss: 2871.1619 - val_loss: 2753.0515\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 2462.8203 - val_loss: 2346.3462\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2093.4578 - val_loss: 2006.2010\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 3ms/step - loss: 1787.3695 - val_loss: 1703.5646\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1524.0211 - val_loss: 1442.0256\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1281.6141 - val_loss: 1194.5571\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1078.6772 - val_loss: 1014.6464\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 924.9144 - val_loss: 863.7010\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 796.4432 - val_loss: 739.1454\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 688.4742 - val_loss: 641.4851\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 11ms/step - loss: 601.5629 - val_loss: 558.6921\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 529.6338 - val_loss: 493.1831\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 7ms/step - loss: 471.9261 - val_loss: 439.3717\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 422.7271 - val_loss: 399.0536\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 381.4880 - val_loss: 360.2199\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 349.3737 - val_loss: 325.5962\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 318.3266 - val_loss: 300.7455\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 294.2174 - val_loss: 279.6512\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 274.6130 - val_loss: 260.5713\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 255.9659 - val_loss: 243.6477\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 239.8701 - val_loss: 229.6558\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 225.2149 - val_loss: 217.1343\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 212.8053 - val_loss: 206.3552\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 202.1770 - val_loss: 197.8687\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 8ms/step - loss: 192.7617 - val_loss: 188.5513\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 182.9520 - val_loss: 181.7749\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 175.9086 - val_loss: 175.5472\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 3ms/step - loss: 168.6856 - val_loss: 170.5936\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.8598 - val_loss: 165.8979\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 158.7744 - val_loss: 162.1759\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 152.7568 - val_loss: 159.0015\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 148.9845 - val_loss: 155.4823\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.8452 - val_loss: 152.7802\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.0266 - val_loss: 151.5793\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 138.4379 - val_loss: 148.8970\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.1855 - val_loss: 147.7772\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.8598 - val_loss: 146.3512\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 132.1445 - val_loss: 144.1670\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.0655 - val_loss: 143.8021\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.5969 - val_loss: 143.4449\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 65ms/step - loss: 764136.6250 - val_loss: 657053.5000\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 576150.1250 - val_loss: 497439.1250\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 436253.4688 - val_loss: 376295.3750\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 328517.4375 - val_loss: 281921.4688\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 10ms/step - loss: 244404.9062 - val_loss: 207792.4844\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 178349.6094 - val_loss: 149986.5625\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 127116.8125 - val_loss: 105191.0547\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 87784.4062 - val_loss: 71336.0703\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 3ms/step - loss: 58519.5664 - val_loss: 46411.7734\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 37377.3945 - val_loss: 28935.0059\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 22811.0020 - val_loss: 17237.9727\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 13299.8154 - val_loss: 9795.0195\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 3ms/step - loss: 7417.4097 - val_loss: 5369.7109\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 4013.5471 - val_loss: 2889.8201\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 2172.9429 - val_loss: 1576.5350\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1224.6210 - val_loss: 947.3568\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 3ms/step - loss: 777.9955 - val_loss: 646.6104\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 577.4299 - val_loss: 511.7623\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 490.5565 - val_loss: 456.4742\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 453.7730 - val_loss: 432.7013\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 439.5298 - val_loss: 420.5203\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 431.4982 - val_loss: 415.0378\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 427.0789 - val_loss: 410.3720\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 423.2911 - val_loss: 406.9385\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 420.0835 - val_loss: 403.8647\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 416.4460 - val_loss: 400.4737\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 413.3063 - val_loss: 397.2252\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 409.6798 - val_loss: 394.4546\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 406.1437 - val_loss: 391.4004\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 402.9050 - val_loss: 388.2163\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 399.1348 - val_loss: 385.1321\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 396.0410 - val_loss: 382.3445\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 391.9043 - val_loss: 378.6313\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 3ms/step - loss: 388.1308 - val_loss: 375.4139\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 384.5466 - val_loss: 372.4772\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 381.0560 - val_loss: 369.2906\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 377.3359 - val_loss: 366.1784\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 3ms/step - loss: 374.0160 - val_loss: 363.1929\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 370.1842 - val_loss: 360.1009\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 366.4370 - val_loss: 357.0220\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 362.7243 - val_loss: 353.9996\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 359.0502 - val_loss: 351.1358\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 10ms/step - loss: 355.4648 - val_loss: 348.3353\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 351.7360 - val_loss: 345.2863\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 348.0394 - val_loss: 342.3318\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 344.3346 - val_loss: 339.5001\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 340.9683 - val_loss: 336.4890\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 337.4705 - val_loss: 333.5414\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 333.8112 - val_loss: 330.8805\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 330.4174 - val_loss: 328.1876\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 62ms/step - loss: 44486.2852 - val_loss: 14898.4502\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 6992.9624 - val_loss: 2073.3699\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 2079.0027 - val_loss: 1914.2990\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1926.1455 - val_loss: 1682.7827\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1734.1193 - val_loss: 1514.3894\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1576.2625 - val_loss: 1386.3535\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1430.9058 - val_loss: 1262.9844\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 3ms/step - loss: 1297.4299 - val_loss: 1164.8341\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1193.2960 - val_loss: 1075.7062\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 1101.6150 - val_loss: 993.3489\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1021.2969 - val_loss: 927.1469\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 956.9318 - val_loss: 870.0682\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 899.4172 - val_loss: 820.2560\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 848.8243 - val_loss: 779.4613\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 808.7252 - val_loss: 742.0629\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 773.0751 - val_loss: 708.9072\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 739.8612 - val_loss: 679.1672\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 711.5105 - val_loss: 654.4087\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 682.5255 - val_loss: 629.4509\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 659.9280 - val_loss: 607.4855\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 635.0080 - val_loss: 585.7334\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 10ms/step - loss: 613.9131 - val_loss: 566.5391\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 593.5035 - val_loss: 549.3250\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 574.8608 - val_loss: 531.3834\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 561.1672 - val_loss: 516.7545\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 540.8916 - val_loss: 502.7147\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 525.5496 - val_loss: 491.1589\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 512.8500 - val_loss: 476.7939\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 496.3573 - val_loss: 464.6310\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 483.7238 - val_loss: 451.4078\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 472.3366 - val_loss: 440.6622\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 460.3627 - val_loss: 429.7859\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 446.9857 - val_loss: 420.2881\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 437.8025 - val_loss: 410.6279\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 427.8081 - val_loss: 401.3299\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 418.9246 - val_loss: 392.6419\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 409.3829 - val_loss: 384.8464\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 400.8662 - val_loss: 376.1049\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 392.5032 - val_loss: 366.9349\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 383.9006 - val_loss: 359.8222\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 376.2877 - val_loss: 353.1034\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 369.3362 - val_loss: 345.5801\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 362.9153 - val_loss: 340.3948\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 355.3442 - val_loss: 332.6394\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 8ms/step - loss: 348.6180 - val_loss: 327.7530\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 344.8026 - val_loss: 326.9156\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 336.3608 - val_loss: 312.9846\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 334.1584 - val_loss: 314.2051\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 326.2230 - val_loss: 304.2265\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 320.5907 - val_loss: 299.5141\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 65ms/step - loss: 5248.6299 - val_loss: 3334.6729\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 2976.7517 - val_loss: 2274.9595\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 3ms/step - loss: 2142.7485 - val_loss: 1715.6469\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1625.6305 - val_loss: 1245.2319\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1167.8766 - val_loss: 930.8345\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 860.0070 - val_loss: 669.3809\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 624.4080 - val_loss: 484.7178\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 461.9822 - val_loss: 375.4948\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 353.1797 - val_loss: 284.0316\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 279.4417 - val_loss: 229.7683\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 8ms/step - loss: 223.0496 - val_loss: 189.6154\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 189.2020 - val_loss: 166.2055\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 166.5889 - val_loss: 154.3830\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 152.9109 - val_loss: 143.2713\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.8025 - val_loss: 134.8904\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 134.5637 - val_loss: 131.5457\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 8ms/step - loss: 130.2848 - val_loss: 128.7493\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 127.8555 - val_loss: 123.3650\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 123.1786 - val_loss: 126.8770\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 130.7719 - val_loss: 119.9372\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.4494 - val_loss: 118.1097\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.9982 - val_loss: 115.3784\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.3403 - val_loss: 116.2402\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.3427 - val_loss: 114.4990\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 119.1671 - val_loss: 112.5752\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.3661 - val_loss: 112.4516\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 10ms/step - loss: 115.6296 - val_loss: 111.3034\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.4911 - val_loss: 112.1506\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.2978 - val_loss: 113.7409\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 112.9562 - val_loss: 112.1432\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.8520 - val_loss: 116.1076\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.8575 - val_loss: 111.5223\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 3ms/step - loss: 114.0206 - val_loss: 112.6828\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.7685 - val_loss: 111.7933\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.9938 - val_loss: 113.5750\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.3754 - val_loss: 109.0749\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 8ms/step - loss: 114.2774 - val_loss: 107.5721\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 3ms/step - loss: 112.1067 - val_loss: 109.4225\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.4498 - val_loss: 116.4852\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.5591 - val_loss: 108.6058\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.5678 - val_loss: 108.2581\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.8558 - val_loss: 118.2042\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.7038 - val_loss: 110.0700\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.9545 - val_loss: 109.0598\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 10ms/step - loss: 112.7824 - val_loss: 113.4923\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - loss: 112.9807 - val_loss: 110.1340\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.3408 - val_loss: 110.7646\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.6560 - val_loss: 111.8861\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.2525 - val_loss: 112.1053\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 3ms/step - loss: 114.1522 - val_loss: 107.2533\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 61ms/step - loss: 22619.4336 - val_loss: 6877.9497\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 4473.5176 - val_loss: 3150.5571\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 3034.1082 - val_loss: 2372.3899\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 2443.5093 - val_loss: 2022.6533\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 2173.6887 - val_loss: 1854.2573\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1992.4081 - val_loss: 1712.6949\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1828.7573 - val_loss: 1591.8973\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1684.1744 - val_loss: 1481.4077\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1551.2158 - val_loss: 1383.8673\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 1432.1042 - val_loss: 1292.7977\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1328.8906 - val_loss: 1216.2719\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1234.8940 - val_loss: 1143.1527\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1154.9320 - val_loss: 1082.9064\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1085.0989 - val_loss: 1029.4435\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1017.2366 - val_loss: 972.0245\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 957.5092 - val_loss: 929.7589\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 904.6664 - val_loss: 882.2336\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 857.5198 - val_loss: 845.0408\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 812.4240 - val_loss: 810.9301\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 8ms/step - loss: 774.5460 - val_loss: 777.0999\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 737.7087 - val_loss: 751.2492\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 704.3306 - val_loss: 716.8346\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 10ms/step - loss: 673.5482 - val_loss: 686.8256\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 643.3195 - val_loss: 663.2555\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 614.8577 - val_loss: 640.4459\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 590.9764 - val_loss: 612.9412\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 7ms/step - loss: 569.2062 - val_loss: 596.8278\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 541.5975 - val_loss: 567.8029\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 7ms/step - loss: 521.4611 - val_loss: 553.3930\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 500.2550 - val_loss: 526.5093\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 483.4288 - val_loss: 516.1727\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 463.8409 - val_loss: 491.1867\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 444.6495 - val_loss: 471.5213\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 428.2743 - val_loss: 456.6505\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 410.4018 - val_loss: 435.6719\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 395.7998 - val_loss: 419.6761\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 3ms/step - loss: 382.3265 - val_loss: 403.8696\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 368.9185 - val_loss: 400.5390\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 353.9176 - val_loss: 374.3126\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 339.3455 - val_loss: 365.3827\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 327.4106 - val_loss: 350.7501\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 315.6085 - val_loss: 341.4139\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 303.1068 - val_loss: 321.1369\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 292.8819 - val_loss: 316.2412\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 286.8468 - val_loss: 298.8155\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 271.3608 - val_loss: 287.6344\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 8ms/step - loss: 260.6001 - val_loss: 278.6613\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 253.0834 - val_loss: 266.2547\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 244.2985 - val_loss: 261.4996\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 8ms/step - loss: 239.9699 - val_loss: 252.4844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 69ms/step - loss: 2006.4897 - val_loss: 1660.3518\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1432.3082 - val_loss: 1246.2031\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 7ms/step - loss: 1076.2212 - val_loss: 955.7095\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 811.3311 - val_loss: 740.8044\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 628.0464 - val_loss: 590.2280\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 499.3293 - val_loss: 478.8269\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 403.1252 - val_loss: 392.5139\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 3ms/step - loss: 340.1588 - val_loss: 331.7556\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 284.8385 - val_loss: 295.8043\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 252.1775 - val_loss: 257.3708\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 7ms/step - loss: 221.2047 - val_loss: 236.2082\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 202.0342 - val_loss: 202.6146\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 181.2481 - val_loss: 201.0298\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.8801 - val_loss: 173.5984\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.3417 - val_loss: 161.9946\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.7025 - val_loss: 157.6677\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 142.3123 - val_loss: 145.8868\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 134.8796 - val_loss: 146.5811\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.7677 - val_loss: 156.1718\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 130.7581 - val_loss: 140.7227\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.2630 - val_loss: 133.7064\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.3962 - val_loss: 134.6081\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 118.3622 - val_loss: 125.4768\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.3481 - val_loss: 121.5129\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.9775 - val_loss: 122.1500\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 119.0273 - val_loss: 120.7417\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.1023 - val_loss: 118.0979\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 115.8650 - val_loss: 117.5688\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.7607 - val_loss: 116.0964\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.6276 - val_loss: 116.0039\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.3844 - val_loss: 119.7252\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 112.4379 - val_loss: 117.6341\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 110.0084 - val_loss: 117.3229\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.5552 - val_loss: 115.0935\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.2473 - val_loss: 117.2253\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.1934 - val_loss: 113.4999\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.3528 - val_loss: 113.1840\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 110.4586 - val_loss: 114.2178\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.7928 - val_loss: 113.5029\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.4086 - val_loss: 113.2100\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.3113 - val_loss: 123.5224\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 107.2153 - val_loss: 111.9181\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 12ms/step - loss: 106.9840 - val_loss: 113.0017\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 3ms/step - loss: 115.9340 - val_loss: 116.4728\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.5287 - val_loss: 111.7029\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 108.5621 - val_loss: 113.3297\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.7295 - val_loss: 111.4873\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 106.1862 - val_loss: 112.9428\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 108.1347 - val_loss: 111.9524\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 107.3773 - val_loss: 111.0824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 60ms/step - loss: 350836.6562 - val_loss: 244258.4375\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 178255.2500 - val_loss: 114777.2031\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 79598.0625 - val_loss: 47013.3516\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 30917.0957 - val_loss: 16847.1914\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 10754.8291 - val_loss: 5827.4580\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 4044.8696 - val_loss: 2828.8816\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 3ms/step - loss: 2337.8052 - val_loss: 2219.3345\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 2009.4576 - val_loss: 2117.1145\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1931.3904 - val_loss: 2076.9004\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 1894.9296 - val_loss: 2042.7433\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 3ms/step - loss: 1845.6373 - val_loss: 1999.1093\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1804.0016 - val_loss: 1958.6659\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1762.7032 - val_loss: 1921.8285\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1720.6332 - val_loss: 1882.4644\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 6ms/step - loss: 1680.1810 - val_loss: 1846.8904\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1640.9679 - val_loss: 1808.7585\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1601.5461 - val_loss: 1772.8612\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1565.8466 - val_loss: 1739.4403\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1529.0812 - val_loss: 1706.2488\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1494.3450 - val_loss: 1674.0087\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1460.7579 - val_loss: 1643.0869\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1428.6542 - val_loss: 1615.1831\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 10ms/step - loss: 1398.0298 - val_loss: 1584.3033\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 1368.4077 - val_loss: 1556.9209\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 1340.2377 - val_loss: 1530.7974\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1312.8234 - val_loss: 1507.1401\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 3ms/step - loss: 1287.3512 - val_loss: 1482.6600\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1264.2451 - val_loss: 1459.1661\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1240.4203 - val_loss: 1439.0073\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 3ms/step - loss: 1217.5553 - val_loss: 1415.5343\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 1196.2076 - val_loss: 1395.6768\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 1175.9152 - val_loss: 1375.0736\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 1155.2322 - val_loss: 1356.3434\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 1136.2245 - val_loss: 1338.9506\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 1118.9305 - val_loss: 1320.2831\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 1101.8380 - val_loss: 1304.5366\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 1083.9597 - val_loss: 1286.2010\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 1067.9799 - val_loss: 1270.3280\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 1052.5197 - val_loss: 1255.2668\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 1037.7690 - val_loss: 1239.9296\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 1023.2404 - val_loss: 1223.9430\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 1010.8424 - val_loss: 1209.6246\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 995.6079 - val_loss: 1196.1941\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 3ms/step - loss: 982.1570 - val_loss: 1182.9689\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 968.0511 - val_loss: 1167.4896\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 957.5596 - val_loss: 1154.5449\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 949.9178 - val_loss: 1140.8929\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 931.7649 - val_loss: 1127.5781\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 919.7029 - val_loss: 1114.3279\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 3ms/step - loss: 907.6424 - val_loss: 1101.8273\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 62ms/step - loss: 259699.9531 - val_loss: 184479.9375\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 146795.1562 - val_loss: 103326.2422\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 81788.1797 - val_loss: 55286.7305\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 40532.8672 - val_loss: 22821.5488\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 13586.0801 - val_loss: 4991.4727\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 3ms/step - loss: 2829.6697 - val_loss: 1568.1306\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1590.5499 - val_loss: 1555.8511\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1521.4138 - val_loss: 1455.8921\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1457.2347 - val_loss: 1399.1941\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1410.7256 - val_loss: 1342.6099\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1356.1018 - val_loss: 1280.5189\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1311.4432 - val_loss: 1230.2769\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1257.1018 - val_loss: 1172.3876\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1209.2249 - val_loss: 1117.6803\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1158.5227 - val_loss: 1068.0308\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1115.7032 - val_loss: 1018.5003\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1067.7191 - val_loss: 972.8958\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 3ms/step - loss: 1026.4141 - val_loss: 925.5194\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 980.3472 - val_loss: 884.5859\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 941.8812 - val_loss: 847.0125\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 900.3236 - val_loss: 809.3126\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 860.6006 - val_loss: 769.2943\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 6ms/step - loss: 822.7263 - val_loss: 734.6399\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 788.6854 - val_loss: 701.1517\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 754.3094 - val_loss: 670.2468\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 720.7823 - val_loss: 639.6339\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 690.4133 - val_loss: 613.5151\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 9ms/step - loss: 661.5960 - val_loss: 587.5037\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 640.2842 - val_loss: 566.4766\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 612.0703 - val_loss: 546.8217\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 590.7326 - val_loss: 531.0783\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 3ms/step - loss: 573.5807 - val_loss: 516.6673\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 557.8827 - val_loss: 501.1736\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 539.5908 - val_loss: 491.2351\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 3ms/step - loss: 525.1816 - val_loss: 476.9170\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 512.8494 - val_loss: 471.2368\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 10ms/step - loss: 502.0999 - val_loss: 461.1286\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 490.7868 - val_loss: 455.4861\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 481.8116 - val_loss: 446.6932\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 472.8372 - val_loss: 440.9860\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 464.5935 - val_loss: 437.0140\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 457.9955 - val_loss: 432.4736\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 453.1197 - val_loss: 429.2834\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 12ms/step - loss: 447.3266 - val_loss: 426.4135\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 3ms/step - loss: 443.0251 - val_loss: 420.7455\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 440.6121 - val_loss: 421.5941\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 434.3823 - val_loss: 415.2682\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 431.2008 - val_loss: 417.1182\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 430.6994 - val_loss: 416.4323\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 426.3419 - val_loss: 409.7233\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 59ms/step - loss: 61698.8906 - val_loss: 38136.1758\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 24585.8418 - val_loss: 13774.5176\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 8278.1982 - val_loss: 4419.0503\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 2518.9814 - val_loss: 1416.8062\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 832.8564 - val_loss: 588.5531\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 415.6425 - val_loss: 396.9504\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 338.1196 - val_loss: 349.5836\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 319.1679 - val_loss: 334.5062\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 310.1707 - val_loss: 325.2854\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 301.9095 - val_loss: 315.6887\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 293.4917 - val_loss: 308.0504\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 284.7477 - val_loss: 298.5995\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 276.9218 - val_loss: 288.5711\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 268.8689 - val_loss: 282.2810\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 261.8753 - val_loss: 275.8211\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 254.9201 - val_loss: 268.0926\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 3ms/step - loss: 248.5988 - val_loss: 261.3452\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 242.6773 - val_loss: 256.0170\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 9ms/step - loss: 236.8626 - val_loss: 249.6723\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 231.8040 - val_loss: 244.3618\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 226.7907 - val_loss: 240.0504\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 222.5850 - val_loss: 235.9853\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 218.6911 - val_loss: 232.0218\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 10ms/step - loss: 214.6609 - val_loss: 228.9908\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 211.4153 - val_loss: 225.9649\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 208.3228 - val_loss: 222.5704\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 205.4281 - val_loss: 220.0121\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 202.0576 - val_loss: 216.9957\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 199.2650 - val_loss: 214.5808\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 196.6752 - val_loss: 211.7448\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 9ms/step - loss: 194.2749 - val_loss: 208.5088\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 191.5294 - val_loss: 206.5189\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 189.2879 - val_loss: 203.8066\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 187.1220 - val_loss: 200.8828\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 3ms/step - loss: 184.6418 - val_loss: 198.3618\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 182.3185 - val_loss: 195.3985\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 179.9030 - val_loss: 193.0165\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 177.4023 - val_loss: 190.0519\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 175.4637 - val_loss: 187.5799\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 172.7622 - val_loss: 184.3848\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 170.3055 - val_loss: 182.2769\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.8933 - val_loss: 179.5897\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.6149 - val_loss: 176.7454\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 3ms/step - loss: 163.3110 - val_loss: 174.5383\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 161.5398 - val_loss: 172.2859\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.1812 - val_loss: 169.2993\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.7977 - val_loss: 167.5268\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.8311 - val_loss: 165.3269\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 152.7148 - val_loss: 162.9673\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.7712 - val_loss: 161.2677\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 65ms/step - loss: 16212.4717 - val_loss: 5028.5063\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 2972.0374 - val_loss: 2702.5054\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 2200.0547 - val_loss: 2198.8733\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1743.4146 - val_loss: 1753.0892\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 6ms/step - loss: 1435.9088 - val_loss: 1432.2963\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1188.2544 - val_loss: 1201.8781\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 996.0283 - val_loss: 998.9267\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 841.9830 - val_loss: 858.4530\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 734.0142 - val_loss: 737.7409\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 642.8079 - val_loss: 659.7974\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 580.5970 - val_loss: 597.8642\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 530.3010 - val_loss: 542.8307\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 491.2097 - val_loss: 508.6715\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 459.4013 - val_loss: 473.2529\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 435.3170 - val_loss: 445.9561\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 416.6502 - val_loss: 423.3639\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 398.4510 - val_loss: 414.1253\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 379.0167 - val_loss: 389.3636\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 366.6819 - val_loss: 374.8026\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 353.5743 - val_loss: 363.4895\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 343.6710 - val_loss: 346.0393\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 329.5927 - val_loss: 330.3407\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 321.1035 - val_loss: 321.8805\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 309.9123 - val_loss: 308.5521\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 300.7506 - val_loss: 298.2253\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 294.3974 - val_loss: 292.8716\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 285.1040 - val_loss: 281.6328\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 276.3678 - val_loss: 267.3641\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 268.2051 - val_loss: 261.5414\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 261.3558 - val_loss: 251.1293\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 258.9987 - val_loss: 243.6189\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 248.2269 - val_loss: 236.5765\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 245.1238 - val_loss: 230.3961\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 235.9841 - val_loss: 224.2829\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 229.1080 - val_loss: 223.1653\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 225.1604 - val_loss: 213.7405\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 219.7811 - val_loss: 208.1322\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 214.1519 - val_loss: 206.6771\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 210.1293 - val_loss: 195.6046\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 205.2705 - val_loss: 193.7992\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 201.2106 - val_loss: 186.8116\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 198.7737 - val_loss: 183.4581\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 194.5626 - val_loss: 182.0702\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 10ms/step - loss: 190.4043 - val_loss: 175.7693\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 186.0403 - val_loss: 181.9546\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - loss: 185.1074 - val_loss: 178.4455\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 184.6621 - val_loss: 166.2680\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 7ms/step - loss: 179.5123 - val_loss: 166.2353\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 172.6212 - val_loss: 170.3850\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.7758 - val_loss: 159.3333\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 58ms/step - loss: 130602.5391 - val_loss: 105956.8516\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 7ms/step - loss: 83324.3359 - val_loss: 60241.0664\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 38635.1328 - val_loss: 18563.7246\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 7486.6602 - val_loss: 2308.3816\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1891.4860 - val_loss: 1552.9756\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1204.3652 - val_loss: 1057.3759\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 913.5675 - val_loss: 899.8873\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 819.8768 - val_loss: 832.8042\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 761.3323 - val_loss: 778.1434\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 711.5145 - val_loss: 730.5538\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 671.0439 - val_loss: 686.6655\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 631.6780 - val_loss: 651.4532\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 600.6439 - val_loss: 617.7136\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 576.3494 - val_loss: 595.6595\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 550.7260 - val_loss: 558.1694\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 524.5057 - val_loss: 532.6911\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 501.5551 - val_loss: 508.8163\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 483.2392 - val_loss: 487.0616\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 463.8560 - val_loss: 467.7973\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 7ms/step - loss: 449.5819 - val_loss: 448.1444\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 434.3089 - val_loss: 431.7480\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 6ms/step - loss: 418.4360 - val_loss: 419.7533\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 405.5388 - val_loss: 400.5465\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 11ms/step - loss: 399.5075 - val_loss: 403.5457\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 384.1544 - val_loss: 374.3306\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 370.2997 - val_loss: 363.0238\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 362.8429 - val_loss: 349.7654\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 351.3159 - val_loss: 340.1555\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 344.8328 - val_loss: 330.7680\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 336.5018 - val_loss: 322.6656\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 3ms/step - loss: 330.9506 - val_loss: 321.9799\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 324.5394 - val_loss: 305.9195\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 315.0161 - val_loss: 296.4941\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 308.5921 - val_loss: 289.8137\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 303.7013 - val_loss: 284.4180\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 3ms/step - loss: 298.3741 - val_loss: 277.3853\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 290.9059 - val_loss: 272.4908\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 7ms/step - loss: 285.2779 - val_loss: 261.2521\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 280.6700 - val_loss: 254.9223\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 274.6741 - val_loss: 250.6741\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 269.8260 - val_loss: 242.3789\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 265.5920 - val_loss: 236.2879\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 261.2311 - val_loss: 231.2649\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 256.3421 - val_loss: 234.0729\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 252.1633 - val_loss: 222.8947\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 245.8690 - val_loss: 215.9569\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 240.6520 - val_loss: 212.6995\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 3ms/step - loss: 235.0494 - val_loss: 223.0666\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 236.7265 - val_loss: 203.0064\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 229.1905 - val_loss: 199.3371\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 65ms/step - loss: 46902.8867 - val_loss: 22269.9961\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 10753.6523 - val_loss: 3946.8042\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 2935.4478 - val_loss: 2402.7297\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 3ms/step - loss: 2666.7090 - val_loss: 2299.6875\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 2510.6396 - val_loss: 2202.0930\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 2397.7239 - val_loss: 2111.6521\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 2282.5781 - val_loss: 1988.9648\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 2159.0859 - val_loss: 1887.3451\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 3ms/step - loss: 2045.6930 - val_loss: 1790.0724\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1942.6262 - val_loss: 1692.6859\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1830.0597 - val_loss: 1615.3665\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1732.3138 - val_loss: 1520.4338\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1636.9541 - val_loss: 1441.2639\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1548.8074 - val_loss: 1379.2407\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1467.5607 - val_loss: 1308.4761\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1390.5732 - val_loss: 1242.2467\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1316.5179 - val_loss: 1177.5406\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1250.4625 - val_loss: 1125.5646\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1185.0850 - val_loss: 1070.9237\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1127.0062 - val_loss: 1022.7519\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 3ms/step - loss: 1070.3419 - val_loss: 978.5074\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 1021.7397 - val_loss: 934.2575\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 969.7057 - val_loss: 897.6974\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 930.1760 - val_loss: 856.6007\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 885.1956 - val_loss: 827.0875\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 3ms/step - loss: 838.4911 - val_loss: 793.9921\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 802.1128 - val_loss: 760.6892\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 767.5212 - val_loss: 737.4524\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 735.9563 - val_loss: 707.3069\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 3ms/step - loss: 704.4379 - val_loss: 680.3605\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 676.4131 - val_loss: 656.1116\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 654.3011 - val_loss: 647.2441\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 623.8562 - val_loss: 609.8571\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 597.2011 - val_loss: 594.0181\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 572.7979 - val_loss: 568.3953\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 546.6431 - val_loss: 553.4565\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 523.7921 - val_loss: 529.4894\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 503.6339 - val_loss: 514.0442\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 481.5125 - val_loss: 495.7179\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 462.3503 - val_loss: 478.6911\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 445.0279 - val_loss: 459.0769\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 427.8030 - val_loss: 448.7592\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 407.6103 - val_loss: 427.5757\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 393.5554 - val_loss: 417.1792\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 377.0302 - val_loss: 400.9362\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 10ms/step - loss: 360.5744 - val_loss: 384.6067\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 3ms/step - loss: 346.6642 - val_loss: 376.8268\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 335.5414 - val_loss: 360.9401\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 320.8159 - val_loss: 345.1485\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 9ms/step - loss: 310.6220 - val_loss: 339.4862\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 75ms/step - loss: 258893.1562 - val_loss: 201494.7969\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 3ms/step - loss: 156749.3750 - val_loss: 118226.2500\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 89227.4531 - val_loss: 64197.3125\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 3ms/step - loss: 46444.6250 - val_loss: 31530.0352\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 21743.3711 - val_loss: 13585.4062\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 8930.4648 - val_loss: 5326.6787\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 3ms/step - loss: 3476.1360 - val_loss: 2158.2883\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1580.6416 - val_loss: 1227.9061\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1046.7349 - val_loss: 1017.1804\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 923.6922 - val_loss: 960.5101\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 15ms/step - loss: 883.4384 - val_loss: 928.7726\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 3ms/step - loss: 854.7869 - val_loss: 900.4996\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 826.7859 - val_loss: 871.2014\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 798.7956 - val_loss: 842.3236\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 771.5942 - val_loss: 813.8056\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 745.5842 - val_loss: 786.3826\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 3ms/step - loss: 719.4370 - val_loss: 759.1490\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 693.7762 - val_loss: 731.9653\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 669.0804 - val_loss: 705.6163\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 644.5765 - val_loss: 680.9565\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 621.9719 - val_loss: 657.1869\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 598.9247 - val_loss: 632.6602\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 577.0416 - val_loss: 610.1111\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 556.1033 - val_loss: 589.2037\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 536.8222 - val_loss: 567.7209\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 517.7610 - val_loss: 548.5246\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 499.7403 - val_loss: 529.0031\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 482.6472 - val_loss: 512.2242\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 466.5309 - val_loss: 494.7496\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 451.6632 - val_loss: 478.8010\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 438.6208 - val_loss: 465.0168\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 3ms/step - loss: 424.9338 - val_loss: 449.8041\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 412.2010 - val_loss: 437.3510\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 3ms/step - loss: 400.9709 - val_loss: 425.4093\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 390.5472 - val_loss: 414.6096\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 380.8597 - val_loss: 404.8683\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 371.8422 - val_loss: 395.0210\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 363.5961 - val_loss: 386.1069\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 356.0982 - val_loss: 377.8074\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 348.3426 - val_loss: 370.6805\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 3ms/step - loss: 341.5179 - val_loss: 363.7248\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 335.5073 - val_loss: 357.0115\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 329.2246 - val_loss: 350.4557\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 323.4709 - val_loss: 344.5816\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 12ms/step - loss: 319.0040 - val_loss: 339.3743\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 313.6662 - val_loss: 332.9761\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 308.4456 - val_loss: 328.3589\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 303.2883 - val_loss: 323.2931\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 299.1591 - val_loss: 318.2003\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 294.7307 - val_loss: 314.2228\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 61ms/step - loss: 294485.7812 - val_loss: 190065.8438\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 129118.8125 - val_loss: 72558.1406\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 45360.7227 - val_loss: 21618.9707\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 13340.8691 - val_loss: 6617.2598\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 5192.3452 - val_loss: 3890.4888\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 3814.6880 - val_loss: 3563.6602\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 3610.7712 - val_loss: 3411.1575\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 3446.0569 - val_loss: 3246.7832\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 3276.1228 - val_loss: 3074.3838\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 3106.8169 - val_loss: 2909.3596\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 2941.7021 - val_loss: 2749.2471\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 8ms/step - loss: 2786.8916 - val_loss: 2585.3821\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 3ms/step - loss: 2621.2495 - val_loss: 2433.7378\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 2468.1650 - val_loss: 2290.7446\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 2330.3960 - val_loss: 2144.4060\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 7ms/step - loss: 2186.1157 - val_loss: 2016.5419\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 2052.8430 - val_loss: 1888.8402\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1926.7236 - val_loss: 1762.7322\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1805.9435 - val_loss: 1650.7249\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1692.6666 - val_loss: 1543.7085\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1586.6415 - val_loss: 1442.1095\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1484.9484 - val_loss: 1346.4113\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 1391.0203 - val_loss: 1257.0221\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1302.4463 - val_loss: 1175.7526\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 1222.8021 - val_loss: 1095.0341\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 11ms/step - loss: 1144.7122 - val_loss: 1026.1239\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 1076.0104 - val_loss: 958.0966\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 10ms/step - loss: 1010.7856 - val_loss: 899.2885\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 951.3049 - val_loss: 839.6390\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 895.8464 - val_loss: 788.6069\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 841.9133 - val_loss: 742.2999\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 794.6061 - val_loss: 698.1028\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 750.7613 - val_loss: 657.0087\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 711.3818 - val_loss: 620.8880\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 674.9825 - val_loss: 588.8239\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 642.6322 - val_loss: 559.0319\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 612.1120 - val_loss: 531.7567\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 3ms/step - loss: 584.9140 - val_loss: 506.9401\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 559.0267 - val_loss: 484.2358\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 536.4983 - val_loss: 463.7266\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 515.2165 - val_loss: 445.0918\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 497.0794 - val_loss: 428.5012\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 479.4460 - val_loss: 413.0072\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 3ms/step - loss: 464.0570 - val_loss: 399.7226\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 451.2663 - val_loss: 387.7245\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 437.7719 - val_loss: 375.8654\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 424.8852 - val_loss: 366.4805\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 3ms/step - loss: 414.7204 - val_loss: 357.3001\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 404.8167 - val_loss: 347.9889\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 396.0756 - val_loss: 340.3736\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 63ms/step - loss: 8266.9209 - val_loss: 1605.5737\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1696.4377 - val_loss: 1598.0612\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1410.6105 - val_loss: 1185.6980\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 9ms/step - loss: 1188.9248 - val_loss: 1025.3793\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1009.2671 - val_loss: 876.6196\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 862.8604 - val_loss: 748.2617\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 753.1013 - val_loss: 652.2511\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 10ms/step - loss: 665.3795 - val_loss: 578.2354\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 592.7816 - val_loss: 517.3987\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 521.2184 - val_loss: 449.7679\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 459.6685 - val_loss: 398.1586\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 397.9500 - val_loss: 353.1911\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 348.4408 - val_loss: 313.6378\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 308.3351 - val_loss: 279.3158\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 269.7562 - val_loss: 247.2966\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 243.0971 - val_loss: 220.9281\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 214.2837 - val_loss: 205.0601\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 194.9756 - val_loss: 185.0225\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 178.1543 - val_loss: 172.7477\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 165.3232 - val_loss: 163.6252\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.2002 - val_loss: 163.2391\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 149.2964 - val_loss: 152.5955\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.8766 - val_loss: 150.9982\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.1886 - val_loss: 139.8646\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 133.3705 - val_loss: 135.6584\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 128.7732 - val_loss: 133.4488\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.0741 - val_loss: 130.4043\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 124.0504 - val_loss: 129.0130\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.5605 - val_loss: 129.0225\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 120.8108 - val_loss: 125.9486\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 118.1342 - val_loss: 124.4551\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 118.5884 - val_loss: 125.7264\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.7871 - val_loss: 122.3471\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.5133 - val_loss: 124.0262\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.9708 - val_loss: 121.4595\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.8962 - val_loss: 121.0938\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.5569 - val_loss: 121.3682\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.8847 - val_loss: 121.5106\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.5363 - val_loss: 119.5490\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.7922 - val_loss: 120.7617\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 113.1142 - val_loss: 119.1586\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.2725 - val_loss: 120.1656\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.4345 - val_loss: 118.4490\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.5600 - val_loss: 118.6581\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 12ms/step - loss: 110.9322 - val_loss: 117.5754\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 110.9901 - val_loss: 117.4757\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.7290 - val_loss: 124.4135\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.9184 - val_loss: 117.1544\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.3016 - val_loss: 118.6496\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 108.9767 - val_loss: 118.8163\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 142ms/step - loss: 467271.8438 - val_loss: 334733.6562\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 250583.5625 - val_loss: 170516.4844\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 3ms/step - loss: 125274.6328 - val_loss: 80289.0234\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 54793.2539 - val_loss: 31304.8730\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 19625.1367 - val_loss: 9813.1846\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 6215.4771 - val_loss: 3553.0142\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 2837.3328 - val_loss: 2321.7529\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 7ms/step - loss: 2223.3750 - val_loss: 2129.7764\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 2100.5979 - val_loss: 2039.1130\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 2002.8632 - val_loss: 1949.9926\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1914.0773 - val_loss: 1861.2227\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1828.8691 - val_loss: 1771.4043\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1736.9071 - val_loss: 1688.6035\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1652.0292 - val_loss: 1598.1364\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1565.8622 - val_loss: 1516.5533\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1484.5730 - val_loss: 1436.6157\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1404.4187 - val_loss: 1360.3292\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1330.5405 - val_loss: 1284.6003\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 1262.5100 - val_loss: 1214.0449\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 3ms/step - loss: 1190.0824 - val_loss: 1146.5646\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1125.6532 - val_loss: 1082.8275\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 7ms/step - loss: 1064.7212 - val_loss: 1023.0077\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 8ms/step - loss: 1007.4536 - val_loss: 964.4715\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 3ms/step - loss: 952.2888 - val_loss: 911.5472\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 7ms/step - loss: 901.2876 - val_loss: 861.4578\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 855.6091 - val_loss: 815.5906\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 809.8244 - val_loss: 770.8923\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 769.0981 - val_loss: 731.3442\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 730.7007 - val_loss: 694.2352\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 697.2693 - val_loss: 660.1095\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 664.3043 - val_loss: 627.4050\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 3ms/step - loss: 633.6127 - val_loss: 597.3165\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 606.0300 - val_loss: 570.6557\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 580.2649 - val_loss: 545.6787\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 556.7095 - val_loss: 522.3604\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 533.2218 - val_loss: 499.3014\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 514.0369 - val_loss: 480.2624\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 495.1702 - val_loss: 461.5287\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 475.8863 - val_loss: 445.2058\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 459.3436 - val_loss: 427.7890\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 442.8178 - val_loss: 411.8129\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 429.1468 - val_loss: 398.0385\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 413.2990 - val_loss: 384.2905\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 400.6976 - val_loss: 371.6719\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 388.3646 - val_loss: 358.7868\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 374.1650 - val_loss: 347.3221\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 362.9756 - val_loss: 337.8301\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 351.5544 - val_loss: 326.7326\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 340.4929 - val_loss: 316.7694\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 330.9745 - val_loss: 306.7566\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 66ms/step - loss: 3592.4744 - val_loss: 2241.4475\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 2101.6614 - val_loss: 1788.3685\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1732.1497 - val_loss: 1539.9501\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1520.6213 - val_loss: 1358.4304\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1329.8428 - val_loss: 1187.7721\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1155.9171 - val_loss: 1048.9487\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1010.1472 - val_loss: 912.2386\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 890.4329 - val_loss: 831.6566\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 3ms/step - loss: 785.9230 - val_loss: 733.1882\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 698.9090 - val_loss: 651.3458\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 627.5778 - val_loss: 590.3896\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 578.7009 - val_loss: 529.0311\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 519.1295 - val_loss: 481.7035\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 457.8284 - val_loss: 444.9525\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 416.2427 - val_loss: 393.9128\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 3ms/step - loss: 375.6931 - val_loss: 359.7801\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 342.8628 - val_loss: 335.0674\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 314.8395 - val_loss: 300.0828\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 287.0870 - val_loss: 275.0963\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 263.4914 - val_loss: 253.5893\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 3ms/step - loss: 244.1464 - val_loss: 235.7992\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 224.4828 - val_loss: 216.6235\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 209.0804 - val_loss: 203.3708\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 196.0718 - val_loss: 190.6178\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 187.5763 - val_loss: 176.1277\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 172.1237 - val_loss: 169.5777\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 164.8748 - val_loss: 163.3981\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.2101 - val_loss: 153.6968\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.1599 - val_loss: 143.6458\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.2733 - val_loss: 135.6956\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.6600 - val_loss: 131.1305\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.3807 - val_loss: 125.6806\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.9297 - val_loss: 121.6963\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.9507 - val_loss: 118.6629\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.7980 - val_loss: 115.9472\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 118.6000 - val_loss: 115.1245\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 117.1869 - val_loss: 111.0687\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.0734 - val_loss: 110.7668\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.8226 - val_loss: 110.0739\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.8206 - val_loss: 107.1174\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.6325 - val_loss: 110.1065\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.7574 - val_loss: 104.3647\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 108.7294 - val_loss: 103.7518\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 11ms/step - loss: 108.6811 - val_loss: 111.1245\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.1617 - val_loss: 102.0241\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - loss: 107.5379 - val_loss: 102.4057\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 108.9644 - val_loss: 100.7996\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 3ms/step - loss: 107.4345 - val_loss: 101.1589\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 3ms/step - loss: 105.2796 - val_loss: 99.6640\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 103.7650 - val_loss: 102.8320\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 78ms/step - loss: 143661.0781 - val_loss: 88077.3281\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 57240.6367 - val_loss: 28703.8066\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 17529.7559 - val_loss: 9026.8330\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 7257.1226 - val_loss: 6275.0488\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 5996.0913 - val_loss: 5609.3394\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 5355.0220 - val_loss: 4993.1084\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 3ms/step - loss: 4785.9009 - val_loss: 4445.9897\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 4276.6440 - val_loss: 3969.2456\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 3ms/step - loss: 3829.0842 - val_loss: 3550.7031\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 3426.6272 - val_loss: 3177.0510\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 3073.5801 - val_loss: 2840.6714\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 8ms/step - loss: 2765.1392 - val_loss: 2543.0811\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2490.1338 - val_loss: 2282.2988\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 2246.4495 - val_loss: 2053.7778\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 3ms/step - loss: 2022.9440 - val_loss: 1850.9689\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1842.4421 - val_loss: 1668.6969\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 3ms/step - loss: 1667.7642 - val_loss: 1513.9908\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1520.9875 - val_loss: 1377.3990\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 1392.8538 - val_loss: 1253.4734\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1279.4060 - val_loss: 1144.7827\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1176.1926 - val_loss: 1053.0981\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1092.5767 - val_loss: 966.9843\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1007.2645 - val_loss: 891.9160\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 937.1443 - val_loss: 826.4135\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 876.6795 - val_loss: 767.9556\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 824.1968 - val_loss: 718.5184\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 770.6908 - val_loss: 671.9886\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 729.2679 - val_loss: 630.8583\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 687.2197 - val_loss: 595.5939\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 652.6061 - val_loss: 561.7298\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 3ms/step - loss: 621.1694 - val_loss: 532.3947\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 590.9087 - val_loss: 507.3285\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 564.7480 - val_loss: 483.1139\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 540.2227 - val_loss: 459.1464\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 515.8083 - val_loss: 440.1811\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 495.1793 - val_loss: 421.5179\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 475.8249 - val_loss: 403.0974\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 457.0211 - val_loss: 387.5010\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 441.0592 - val_loss: 373.0527\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 425.4778 - val_loss: 359.4437\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 410.7203 - val_loss: 346.6505\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 397.2236 - val_loss: 336.1397\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 385.4111 - val_loss: 325.1702\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 374.6559 - val_loss: 314.6512\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 9ms/step - loss: 361.4326 - val_loss: 305.0218\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 12ms/step - loss: 347.8455 - val_loss: 291.8174\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 332.4468 - val_loss: 280.0627\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 312.5979 - val_loss: 264.3413\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 296.1313 - val_loss: 254.1180\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 277.7531 - val_loss: 240.2370\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Mean MSE: 424.30079044071294\n",
      "Standard Deviation of MSE: 652.3590805604039\n"
     ]
    }
   ],
   "source": [
    "# Store mean squared errors for 50 repetitions\n",
    "mse_list = []\n",
    "\n",
    "for _ in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=None)\n",
    "\n",
    "    # Build and train the model\n",
    "    model = regression_model(n_cols)\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=2)\n",
    "    \n",
    "    # Predict and calculate mean squared error\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)\n",
    "\n",
    "# Compute mean and standard deviation of the mean squared errors\n",
    "mean_mse = np.mean(mse_list)\n",
    "std_mse = np.std(mse_list)\n",
    "\n",
    "print(f'Mean MSE: {mean_mse}')\n",
    "print(f'Standard Deviation of MSE: {std_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step B: Normalize the data\n",
    "\n",
    "Repeat Step A using a normalized version of the data. Normalize the data by subtracting the mean from each feature and dividing by the standard deviation.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step A?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 78ms/step - loss: 1568.5656 - val_loss: 1438.4194\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1553.1650 - val_loss: 1424.2462\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1537.2451 - val_loss: 1409.8391\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1521.0220 - val_loss: 1394.8052\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1504.3405 - val_loss: 1378.8982\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1486.3772 - val_loss: 1362.5901\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1467.7377 - val_loss: 1345.2839\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1448.0605 - val_loss: 1327.0310\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1426.9197 - val_loss: 1308.1637\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1404.9615 - val_loss: 1287.8054\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1381.4242 - val_loss: 1266.4994\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1356.9956 - val_loss: 1243.8655\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1330.8792 - val_loss: 1220.4015\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1303.5879 - val_loss: 1195.4844\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1275.2041 - val_loss: 1169.2698\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1245.0376 - val_loss: 1143.0846\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1214.6589 - val_loss: 1115.0759\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1182.8214 - val_loss: 1086.2338\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 1149.9857 - val_loss: 1057.0442\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1116.5872 - val_loss: 1027.8402\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1083.2067 - val_loss: 996.8918\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1048.0675 - val_loss: 966.2914\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1013.7462 - val_loss: 934.7440\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 3ms/step - loss: 978.5336 - val_loss: 903.2488\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 942.8659 - val_loss: 872.5372\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 3ms/step - loss: 907.7537 - val_loss: 840.1406\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 871.6407 - val_loss: 808.3232\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 8ms/step - loss: 836.1664 - val_loss: 776.3799\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 800.7756 - val_loss: 744.5447\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 765.9883 - val_loss: 713.1591\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 731.7613 - val_loss: 682.6818\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 3ms/step - loss: 698.3731 - val_loss: 653.0093\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 666.4980 - val_loss: 623.4148\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 3ms/step - loss: 634.7450 - val_loss: 596.0149\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 605.2831 - val_loss: 568.9659\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 576.8403 - val_loss: 543.1722\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 549.4398 - val_loss: 518.9333\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 523.9361 - val_loss: 495.2212\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 499.3506 - val_loss: 473.3617\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 476.8108 - val_loss: 452.0914\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 3ms/step - loss: 454.9937 - val_loss: 432.3469\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 434.7340 - val_loss: 413.7743\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 415.8540 - val_loss: 396.1397\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 398.3504 - val_loss: 379.3018\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 11ms/step - loss: 381.6122 - val_loss: 364.4723\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 366.8634 - val_loss: 349.2770\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 352.1227 - val_loss: 336.2357\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 339.2610 - val_loss: 323.0916\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 326.5985 - val_loss: 311.8410\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 3ms/step - loss: 315.4321 - val_loss: 300.4518\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 60ms/step - loss: 1626.3008 - val_loss: 1551.4985\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1609.3770 - val_loss: 1536.1959\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1593.0339 - val_loss: 1521.4548\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1577.4113 - val_loss: 1506.8857\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 1561.8845 - val_loss: 1492.3906\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1546.1033 - val_loss: 1477.6342\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1529.8497 - val_loss: 1462.2657\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1512.9266 - val_loss: 1446.0704\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 3ms/step - loss: 1495.1841 - val_loss: 1428.9451\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - loss: 1476.1675 - val_loss: 1410.9835\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1456.2153 - val_loss: 1391.9985\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1435.0120 - val_loss: 1371.7214\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1412.6085 - val_loss: 1350.3037\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1389.0388 - val_loss: 1328.3909\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1364.5917 - val_loss: 1305.9559\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1339.5439 - val_loss: 1281.4814\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1313.0764 - val_loss: 1256.5215\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1286.0131 - val_loss: 1231.1610\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1258.0522 - val_loss: 1205.6250\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1229.9104 - val_loss: 1179.1981\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1200.8359 - val_loss: 1152.4642\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 1171.8737 - val_loss: 1124.9283\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1142.0139 - val_loss: 1097.6749\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 3ms/step - loss: 1112.5514 - val_loss: 1069.7162\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1082.1045 - val_loss: 1041.9967\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1052.2506 - val_loss: 1014.5673\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1022.5722 - val_loss: 986.5007\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 11ms/step - loss: 992.9028 - val_loss: 958.4249\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 3ms/step - loss: 962.9581 - val_loss: 931.1396\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 933.7408 - val_loss: 904.0765\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 904.8884 - val_loss: 876.5837\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 875.8560 - val_loss: 849.5086\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 847.3268 - val_loss: 823.2183\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 819.4948 - val_loss: 796.4606\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 792.0099 - val_loss: 769.5349\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 3ms/step - loss: 764.2072 - val_loss: 743.5981\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 737.4624 - val_loss: 717.5081\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 3ms/step - loss: 710.7372 - val_loss: 691.8342\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 684.7081 - val_loss: 666.4517\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 659.2378 - val_loss: 641.5147\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 634.5400 - val_loss: 617.3298\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 610.3093 - val_loss: 593.5569\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 586.6622 - val_loss: 570.3834\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 563.9784 - val_loss: 547.7526\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 541.7858 - val_loss: 526.1830\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 520.9409 - val_loss: 504.8192\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 500.4427 - val_loss: 484.5639\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 481.1858 - val_loss: 465.1326\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 3ms/step - loss: 462.6413 - val_loss: 445.9879\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 444.8458 - val_loss: 428.4904\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 1597.3712 - val_loss: 1629.2167\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1580.8398 - val_loss: 1612.5200\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1565.1947 - val_loss: 1596.7231\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 3ms/step - loss: 1550.1770 - val_loss: 1581.1587\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1535.4485 - val_loss: 1565.6613\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1520.9530 - val_loss: 1550.3860\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1506.5618 - val_loss: 1535.3684\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 9ms/step - loss: 1492.1078 - val_loss: 1520.3401\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1477.5413 - val_loss: 1504.6956\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1462.4719 - val_loss: 1489.0325\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1447.2838 - val_loss: 1472.5979\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1431.3959 - val_loss: 1456.1517\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 1415.1907 - val_loss: 1439.0739\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1398.4871 - val_loss: 1421.0283\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1380.6605 - val_loss: 1402.6252\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1362.2762 - val_loss: 1383.5404\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1343.1199 - val_loss: 1364.0007\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1323.3881 - val_loss: 1342.8528\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1302.5739 - val_loss: 1321.2832\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1280.9147 - val_loss: 1299.4814\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1258.8053 - val_loss: 1276.5494\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 1236.0723 - val_loss: 1253.1057\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1212.4313 - val_loss: 1229.3495\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1188.5483 - val_loss: 1205.3759\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 1164.2047 - val_loss: 1181.1064\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1139.6582 - val_loss: 1156.1748\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 1114.6912 - val_loss: 1131.9296\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 1090.0530 - val_loss: 1107.4069\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 1065.0812 - val_loss: 1082.9927\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 7ms/step - loss: 1040.3796 - val_loss: 1058.5856\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 1015.6369 - val_loss: 1034.5208\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 991.0630 - val_loss: 1010.8521\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 966.8773 - val_loss: 987.0558\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 942.5710 - val_loss: 963.9993\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 919.0970 - val_loss: 941.1808\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 895.7580 - val_loss: 918.8353\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 872.7692 - val_loss: 897.0204\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 850.4571 - val_loss: 875.3073\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 828.1373 - val_loss: 854.6758\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 3ms/step - loss: 806.7164 - val_loss: 833.7397\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 785.3108 - val_loss: 813.9274\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 764.6050 - val_loss: 794.2213\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 744.5476 - val_loss: 774.5025\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 3ms/step - loss: 724.5334 - val_loss: 756.2905\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 10ms/step - loss: 705.8151 - val_loss: 737.7227\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 686.9703 - val_loss: 719.8902\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 668.7454 - val_loss: 702.4952\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 650.9980 - val_loss: 685.3131\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 633.6187 - val_loss: 668.2385\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 616.7978 - val_loss: 651.3470\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 60ms/step - loss: 1594.8188 - val_loss: 1492.2821\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1579.0378 - val_loss: 1477.5221\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1563.9976 - val_loss: 1462.9619\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1549.1506 - val_loss: 1448.2917\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1534.4312 - val_loss: 1433.5662\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1519.2888 - val_loss: 1418.8024\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1503.9332 - val_loss: 1403.0447\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1487.8955 - val_loss: 1386.4067\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1470.9716 - val_loss: 1368.5481\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1452.6470 - val_loss: 1349.9531\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1433.1649 - val_loss: 1330.3328\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1412.4561 - val_loss: 1308.7992\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1390.0625 - val_loss: 1285.6415\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 3ms/step - loss: 1366.1371 - val_loss: 1261.2850\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 1340.6292 - val_loss: 1235.3776\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1313.6887 - val_loss: 1207.5551\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1284.6987 - val_loss: 1178.6392\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 3ms/step - loss: 1254.2070 - val_loss: 1148.2565\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1222.2854 - val_loss: 1116.0406\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1189.2660 - val_loss: 1081.9030\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1153.9301 - val_loss: 1048.2058\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 1118.8326 - val_loss: 1012.0880\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1081.8588 - val_loss: 976.2538\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1045.0652 - val_loss: 939.3005\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 1006.8174 - val_loss: 903.0437\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 969.0823 - val_loss: 866.2024\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 930.8383 - val_loss: 829.6951\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 10ms/step - loss: 892.8359 - val_loss: 792.9250\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 855.0779 - val_loss: 756.5634\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 817.5403 - val_loss: 721.2787\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 780.9028 - val_loss: 686.3773\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 744.9146 - val_loss: 652.5250\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 709.4585 - val_loss: 620.4081\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 675.5593 - val_loss: 588.4252\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 642.0321 - val_loss: 558.2673\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 609.8274 - val_loss: 528.6526\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 578.6400 - val_loss: 500.5767\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 549.1367 - val_loss: 473.6411\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 520.4917 - val_loss: 448.6613\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 493.9207 - val_loss: 424.8683\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 468.4529 - val_loss: 402.6530\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 444.6788 - val_loss: 381.9755\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 422.1239 - val_loss: 362.9265\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 3ms/step - loss: 401.1207 - val_loss: 345.0758\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 381.2783 - val_loss: 328.9890\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 363.1772 - val_loss: 313.6306\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 346.3935 - val_loss: 299.6559\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 330.8712 - val_loss: 287.4089\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 316.5355 - val_loss: 276.2952\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 303.8830 - val_loss: 265.8883\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 73ms/step - loss: 1520.5111 - val_loss: 1397.7924\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1503.4009 - val_loss: 1381.3757\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 3ms/step - loss: 1485.5627 - val_loss: 1364.3293\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1466.9849 - val_loss: 1346.3560\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1447.4188 - val_loss: 1327.1178\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1426.3103 - val_loss: 1307.3411\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 1404.2858 - val_loss: 1286.1255\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1380.8246 - val_loss: 1263.8337\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1356.1010 - val_loss: 1240.5690\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - loss: 1330.5378 - val_loss: 1215.9844\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1303.2756 - val_loss: 1190.3425\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 3ms/step - loss: 1275.3778 - val_loss: 1163.3931\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 1246.3160 - val_loss: 1135.9861\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1216.3674 - val_loss: 1107.7478\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1185.6207 - val_loss: 1078.5298\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1154.1748 - val_loss: 1048.5192\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1121.5234 - val_loss: 1018.0089\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1088.6196 - val_loss: 986.4240\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1054.7953 - val_loss: 954.4149\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1020.3713 - val_loss: 922.2089\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 985.7060 - val_loss: 889.5176\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 950.4361 - val_loss: 856.1484\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 915.3531 - val_loss: 821.8914\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 879.4911 - val_loss: 788.9106\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 3ms/step - loss: 844.4904 - val_loss: 756.0514\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 810.2993 - val_loss: 723.3051\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 776.4318 - val_loss: 691.3334\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 742.9589 - val_loss: 661.1024\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 711.2193 - val_loss: 631.0222\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 679.8094 - val_loss: 602.4056\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 3ms/step - loss: 650.0477 - val_loss: 574.8127\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 621.2994 - val_loss: 548.3506\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 593.4456 - val_loss: 523.6113\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 567.3735 - val_loss: 499.9662\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 542.5101 - val_loss: 477.4299\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 518.6234 - val_loss: 456.6880\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 496.4371 - val_loss: 436.6115\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 475.1186 - val_loss: 418.0366\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 455.4087 - val_loss: 400.2132\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 436.2100 - val_loss: 384.1488\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 418.5184 - val_loss: 368.8151\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 11ms/step - loss: 402.0717 - val_loss: 354.6146\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 386.2334 - val_loss: 341.8010\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 371.7803 - val_loss: 329.2717\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 357.8363 - val_loss: 317.7980\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 344.9800 - val_loss: 307.2707\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 332.8932 - val_loss: 297.2339\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 321.2436 - val_loss: 288.1329\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 310.7344 - val_loss: 279.2699\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 300.5709 - val_loss: 271.1926\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 62ms/step - loss: 1579.6837 - val_loss: 1687.9548\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1564.6488 - val_loss: 1672.9076\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1550.1798 - val_loss: 1658.3525\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1536.0931 - val_loss: 1644.0764\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1522.2083 - val_loss: 1629.8153\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1508.1196 - val_loss: 1615.5990\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1493.7307 - val_loss: 1601.0470\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1478.9856 - val_loss: 1585.7548\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 1463.4457 - val_loss: 1569.6622\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1447.0288 - val_loss: 1552.8018\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1429.6979 - val_loss: 1534.9774\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 1411.4016 - val_loss: 1516.3013\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1392.1814 - val_loss: 1496.2648\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1371.9368 - val_loss: 1475.5334\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1350.5712 - val_loss: 1453.7852\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1328.3607 - val_loss: 1430.7192\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1305.0760 - val_loss: 1406.9373\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1280.8871 - val_loss: 1382.1829\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 1255.9167 - val_loss: 1356.4071\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1230.0341 - val_loss: 1329.4803\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1203.5203 - val_loss: 1301.4166\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 11ms/step - loss: 1175.8872 - val_loss: 1273.6263\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1147.8859 - val_loss: 1244.5791\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1119.6670 - val_loss: 1214.4360\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1090.2246 - val_loss: 1184.3571\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1060.3405 - val_loss: 1153.9431\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 1030.4945 - val_loss: 1122.5275\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1000.0167 - val_loss: 1090.6146\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 969.2435 - val_loss: 1058.0037\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 938.1125 - val_loss: 1025.2761\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 906.8548 - val_loss: 992.9509\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 875.8356 - val_loss: 959.7338\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 844.3674 - val_loss: 927.4656\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 813.6850 - val_loss: 894.4352\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 782.5470 - val_loss: 862.2403\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 752.1605 - val_loss: 830.6185\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 722.2720 - val_loss: 799.2996\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 692.5023 - val_loss: 767.9642\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 663.2293 - val_loss: 737.7516\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 634.9448 - val_loss: 707.2717\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 607.0009 - val_loss: 677.8252\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 579.7896 - val_loss: 649.2451\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 553.3445 - val_loss: 622.1945\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 528.1600 - val_loss: 596.0540\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 504.2914 - val_loss: 569.8019\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 480.7467 - val_loss: 545.9898\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 458.6306 - val_loss: 522.6026\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 437.4856 - val_loss: 500.6780\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 417.4926 - val_loss: 479.6336\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 398.5977 - val_loss: 459.6359\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 65ms/step - loss: 1586.1399 - val_loss: 1578.0804\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1572.5066 - val_loss: 1565.9025\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1559.6068 - val_loss: 1554.0574\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1546.9884 - val_loss: 1542.4019\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1534.3878 - val_loss: 1530.7037\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1521.4795 - val_loss: 1518.5844\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 1507.7268 - val_loss: 1505.9855\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1493.3998 - val_loss: 1492.2958\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1477.7113 - val_loss: 1478.0671\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1461.3184 - val_loss: 1462.6971\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1443.6243 - val_loss: 1446.5675\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 6ms/step - loss: 1424.8502 - val_loss: 1429.4600\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1404.9867 - val_loss: 1411.6338\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1384.3890 - val_loss: 1392.8063\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1362.4506 - val_loss: 1373.0477\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 7ms/step - loss: 1339.4149 - val_loss: 1352.5511\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1315.5477 - val_loss: 1330.9315\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1290.4219 - val_loss: 1308.4771\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1264.5586 - val_loss: 1285.0906\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1237.9105 - val_loss: 1260.9340\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1210.3054 - val_loss: 1236.5339\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1182.4648 - val_loss: 1211.4720\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1154.1227 - val_loss: 1185.5524\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1125.3054 - val_loss: 1159.6943\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 1096.7629 - val_loss: 1133.1418\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1067.5823 - val_loss: 1106.6713\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1038.9331 - val_loss: 1080.3555\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1010.9172 - val_loss: 1053.3276\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 982.1440 - val_loss: 1027.4240\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 954.4977 - val_loss: 1001.0727\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 927.0466 - val_loss: 974.7500\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 7ms/step - loss: 899.5994 - val_loss: 948.5731\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 872.3455 - val_loss: 922.6091\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 845.7182 - val_loss: 895.6693\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 818.8879 - val_loss: 868.2425\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 791.3496 - val_loss: 840.6940\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 764.2525 - val_loss: 811.9220\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 736.3500 - val_loss: 783.7348\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 709.2292 - val_loss: 754.8625\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 682.2459 - val_loss: 726.5186\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 655.3043 - val_loss: 697.9653\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 10ms/step - loss: 628.8776 - val_loss: 669.9252\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 602.6319 - val_loss: 642.5593\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 7ms/step - loss: 577.4995 - val_loss: 614.4592\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 552.3915 - val_loss: 587.8328\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 528.1644 - val_loss: 561.7079\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 504.5688 - val_loss: 536.8395\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 482.4275 - val_loss: 512.2465\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 460.5166 - val_loss: 489.4467\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 440.3929 - val_loss: 466.1827\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 1587.5413 - val_loss: 1562.3109\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1567.2926 - val_loss: 1542.8640\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1546.9958 - val_loss: 1523.9696\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1527.3651 - val_loss: 1504.3652\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1506.9161 - val_loss: 1485.0813\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1486.8103 - val_loss: 1465.5693\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1466.4185 - val_loss: 1445.5798\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1445.3744 - val_loss: 1425.1429\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1423.7728 - val_loss: 1404.2673\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 1402.0070 - val_loss: 1382.9131\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1379.7826 - val_loss: 1361.1329\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1356.8054 - val_loss: 1338.9200\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1333.2413 - val_loss: 1316.1864\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1309.3872 - val_loss: 1292.3680\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1284.6324 - val_loss: 1268.3959\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1259.5793 - val_loss: 1244.1881\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1234.3210 - val_loss: 1219.0758\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1208.4037 - val_loss: 1193.4991\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1182.1835 - val_loss: 1168.1003\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1155.8452 - val_loss: 1142.5192\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1129.1721 - val_loss: 1116.3842\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 1102.1829 - val_loss: 1090.3357\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1075.5177 - val_loss: 1063.4602\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1048.2031 - val_loss: 1036.8462\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 1021.3717 - val_loss: 1010.0768\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 993.8542 - val_loss: 984.1705\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 3ms/step - loss: 967.6070 - val_loss: 956.8017\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 3ms/step - loss: 940.1896 - val_loss: 930.5633\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 913.5471 - val_loss: 904.5388\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 887.0145 - val_loss: 878.7592\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 860.9612 - val_loss: 852.9284\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 835.0305 - val_loss: 827.0843\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 809.7058 - val_loss: 801.6047\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 784.4724 - val_loss: 777.0836\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 760.0485 - val_loss: 752.6147\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 735.9249 - val_loss: 728.8898\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 712.1669 - val_loss: 705.4067\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 7ms/step - loss: 689.2048 - val_loss: 681.9804\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 666.5327 - val_loss: 659.4438\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 644.4304 - val_loss: 636.8846\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 3ms/step - loss: 622.4370 - val_loss: 615.3444\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 601.0217 - val_loss: 593.7734\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 3ms/step - loss: 579.9813 - val_loss: 572.2941\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 559.2483 - val_loss: 550.8871\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 12ms/step - loss: 538.4614 - val_loss: 530.3221\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 518.3205 - val_loss: 510.5983\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 498.8483 - val_loss: 490.5650\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 479.8190 - val_loss: 470.9604\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 460.7774 - val_loss: 452.8380\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 7ms/step - loss: 442.7445 - val_loss: 434.6352\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 96ms/step - loss: 1581.3289 - val_loss: 1520.8165\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 17ms/step - loss: 1566.4220 - val_loss: 1506.3947\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1551.3435 - val_loss: 1491.6265\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 9ms/step - loss: 1535.6353 - val_loss: 1476.3984\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1519.3877 - val_loss: 1460.6115\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 7ms/step - loss: 1502.5599 - val_loss: 1443.7485\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 9ms/step - loss: 1484.6715 - val_loss: 1426.1914\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 15ms/step - loss: 1465.8718 - val_loss: 1407.9337\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 12ms/step - loss: 1446.2819 - val_loss: 1388.7775\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 1425.5532 - val_loss: 1368.3350\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 7ms/step - loss: 1403.6351 - val_loss: 1347.0129\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 7ms/step - loss: 1380.8456 - val_loss: 1324.4852\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 9ms/step - loss: 1356.4634 - val_loss: 1301.2544\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 13ms/step - loss: 1331.5459 - val_loss: 1276.4407\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 6ms/step - loss: 1304.9102 - val_loss: 1251.5282\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 7ms/step - loss: 1278.0830 - val_loss: 1225.3390\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 7ms/step - loss: 1250.0853 - val_loss: 1198.5410\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1221.1158 - val_loss: 1171.0465\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1191.1141 - val_loss: 1143.1163\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1160.9530 - val_loss: 1113.7073\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1130.0408 - val_loss: 1083.5588\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1097.8844 - val_loss: 1053.8085\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 8ms/step - loss: 1065.4731 - val_loss: 1022.5231\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1032.2202 - val_loss: 990.0257\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 15ms/step - loss: 997.7543 - val_loss: 957.7980\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 963.2629 - val_loss: 924.2221\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 7ms/step - loss: 928.0087 - val_loss: 890.0259\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 7ms/step - loss: 892.1989 - val_loss: 856.0355\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 856.3372 - val_loss: 821.8282\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 821.1241 - val_loss: 786.6360\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 7ms/step - loss: 785.1238 - val_loss: 753.1041\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 7ms/step - loss: 750.7284 - val_loss: 719.5557\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 8ms/step - loss: 716.8617 - val_loss: 687.0218\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 683.7391 - val_loss: 655.3656\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 8ms/step - loss: 651.6457 - val_loss: 624.3719\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 620.4252 - val_loss: 594.3043\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 589.9751 - val_loss: 565.5109\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 561.0201 - val_loss: 537.4769\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 532.9442 - val_loss: 510.8732\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 506.2853 - val_loss: 485.4964\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 481.0476 - val_loss: 461.1543\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 457.0853 - val_loss: 438.1471\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 434.3199 - val_loss: 416.7821\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 7ms/step - loss: 413.0204 - val_loss: 396.7464\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 393.1190 - val_loss: 377.7160\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 374.6267 - val_loss: 359.5899\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 356.9913 - val_loss: 343.5645\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 7ms/step - loss: 341.0882 - val_loss: 327.8220\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 15ms/step - loss: 325.8996 - val_loss: 313.4861\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 311.8637 - val_loss: 301.1478\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 64ms/step - loss: 1561.2521 - val_loss: 1690.9816\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1545.3972 - val_loss: 1673.4042\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1530.3124 - val_loss: 1656.0328\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1515.1808 - val_loss: 1639.2627\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1500.2273 - val_loss: 1622.4594\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 1485.1445 - val_loss: 1605.4993\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1469.8887 - val_loss: 1587.8783\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1454.0930 - val_loss: 1569.8337\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1437.7993 - val_loss: 1551.4463\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1421.0217 - val_loss: 1532.4376\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1403.5378 - val_loss: 1512.5851\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 1385.5319 - val_loss: 1492.1635\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 3ms/step - loss: 1366.9906 - val_loss: 1471.0865\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1347.7081 - val_loss: 1449.6115\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1327.9362 - val_loss: 1427.1177\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1307.4625 - val_loss: 1404.0538\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 3ms/step - loss: 1286.2684 - val_loss: 1380.6664\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1264.8739 - val_loss: 1355.7527\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1242.5286 - val_loss: 1330.8910\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1219.7098 - val_loss: 1305.5575\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 8ms/step - loss: 1196.5680 - val_loss: 1279.0543\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1172.5406 - val_loss: 1252.4742\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1148.1216 - val_loss: 1224.8783\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1122.9216 - val_loss: 1197.3195\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1097.3746 - val_loss: 1168.3584\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 1071.1210 - val_loss: 1139.2201\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 1044.6451 - val_loss: 1109.1370\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1016.8151 - val_loss: 1078.9691\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 989.0138 - val_loss: 1048.3724\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 3ms/step - loss: 960.9598 - val_loss: 1016.3710\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 931.7064 - val_loss: 986.0408\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 903.0633 - val_loss: 953.9709\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 873.8436 - val_loss: 922.7598\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 845.0452 - val_loss: 891.1754\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 815.9568 - val_loss: 859.9461\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 787.4664 - val_loss: 828.8721\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 759.1264 - val_loss: 798.3124\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 730.9783 - val_loss: 768.6968\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 703.5681 - val_loss: 738.8757\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 676.5355 - val_loss: 709.0213\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 649.7425 - val_loss: 680.7849\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 624.0457 - val_loss: 652.8638\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 598.6633 - val_loss: 625.7623\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 574.5087 - val_loss: 598.9911\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 9ms/step - loss: 550.3956 - val_loss: 574.0297\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - loss: 527.8215 - val_loss: 549.0201\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 505.6798 - val_loss: 525.7333\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 484.4188 - val_loss: 502.6099\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 464.1944 - val_loss: 481.0987\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 445.0424 - val_loss: 460.2970\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 65ms/step - loss: 1603.6981 - val_loss: 1555.0267\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1586.5052 - val_loss: 1539.6831\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1569.9948 - val_loss: 1524.7084\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1553.9761 - val_loss: 1510.3042\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 6ms/step - loss: 1538.3165 - val_loss: 1496.2899\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 3ms/step - loss: 1523.0156 - val_loss: 1482.1510\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1507.6165 - val_loss: 1468.1343\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1492.4642 - val_loss: 1454.1876\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1477.0354 - val_loss: 1439.9272\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1461.2289 - val_loss: 1425.3937\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 1444.9988 - val_loss: 1410.2173\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1428.2959 - val_loss: 1394.4764\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 3ms/step - loss: 1410.7898 - val_loss: 1378.3596\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1392.9064 - val_loss: 1361.2981\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1374.0355 - val_loss: 1343.4008\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1354.4734 - val_loss: 1324.8033\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1333.9194 - val_loss: 1305.6671\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1312.6405 - val_loss: 1285.5015\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1290.5604 - val_loss: 1264.1967\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1267.1820 - val_loss: 1242.4767\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1243.2299 - val_loss: 1219.8004\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 1218.1873 - val_loss: 1196.2715\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1192.0516 - val_loss: 1171.9896\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 11ms/step - loss: 1165.7994 - val_loss: 1146.4589\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 1137.9283 - val_loss: 1121.1989\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1110.1720 - val_loss: 1094.9043\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1081.8430 - val_loss: 1067.6638\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1052.5630 - val_loss: 1040.3707\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 1023.4016 - val_loss: 1012.1061\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 993.5392 - val_loss: 984.2917\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 964.2514 - val_loss: 955.9598\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 934.5398 - val_loss: 927.5115\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 904.9990 - val_loss: 899.0580\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 876.0789 - val_loss: 870.2625\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 846.7772 - val_loss: 842.4645\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 818.4026 - val_loss: 814.2318\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 3ms/step - loss: 790.0856 - val_loss: 787.1251\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 762.7151 - val_loss: 759.9555\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 735.6397 - val_loss: 733.4170\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 709.0275 - val_loss: 707.6151\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 683.5313 - val_loss: 681.9172\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 658.2356 - val_loss: 657.4128\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 7ms/step - loss: 634.0989 - val_loss: 633.3853\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 610.5394 - val_loss: 610.3181\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 588.0449 - val_loss: 588.0596\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 566.4526 - val_loss: 566.5959\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 545.5482 - val_loss: 545.4549\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 525.6614 - val_loss: 524.7481\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 506.2505 - val_loss: 505.6573\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 488.0940 - val_loss: 487.1862\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 72ms/step - loss: 1443.2891 - val_loss: 1551.3977\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1423.0665 - val_loss: 1530.2943\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1402.4178 - val_loss: 1508.5795\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 6ms/step - loss: 1380.8077 - val_loss: 1486.5457\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 1358.6866 - val_loss: 1463.0782\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1335.6007 - val_loss: 1438.5640\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1311.0094 - val_loss: 1414.1008\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1286.2474 - val_loss: 1387.1489\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1259.2896 - val_loss: 1359.3772\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - loss: 1231.7668 - val_loss: 1331.0048\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1203.2858 - val_loss: 1300.9240\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1173.4677 - val_loss: 1270.7882\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1142.9175 - val_loss: 1239.8854\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1111.8357 - val_loss: 1207.1520\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1080.1324 - val_loss: 1173.6102\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1047.4911 - val_loss: 1139.8976\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1014.5914 - val_loss: 1106.4537\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 981.8911 - val_loss: 1072.5081\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 8ms/step - loss: 949.0883 - val_loss: 1038.2195\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 916.6638 - val_loss: 1003.9304\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 884.4602 - val_loss: 970.0177\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 852.3919 - val_loss: 937.3655\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 3ms/step - loss: 821.5506 - val_loss: 903.8624\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 791.0079 - val_loss: 870.8639\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 761.4692 - val_loss: 839.2814\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 732.7029 - val_loss: 808.1825\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 704.8690 - val_loss: 777.9046\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 678.1575 - val_loss: 747.9024\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 651.7411 - val_loss: 720.1468\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 626.7501 - val_loss: 693.3632\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 603.0674 - val_loss: 666.4012\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 3ms/step - loss: 579.8763 - val_loss: 640.9402\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 558.2064 - val_loss: 615.9788\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 7ms/step - loss: 536.8411 - val_loss: 592.6677\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 517.2730 - val_loss: 569.7839\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 498.0455 - val_loss: 548.9498\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 480.2464 - val_loss: 529.0511\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 463.1552 - val_loss: 509.9269\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 447.1254 - val_loss: 491.4896\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 431.6136 - val_loss: 474.4415\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 417.3025 - val_loss: 457.6897\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 10ms/step - loss: 403.2082 - val_loss: 442.1937\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 390.2173 - val_loss: 427.2014\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 377.4550 - val_loss: 413.9053\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 365.8339 - val_loss: 400.6438\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 354.5093 - val_loss: 388.6102\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 344.0256 - val_loss: 376.6981\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 333.8979 - val_loss: 365.5694\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 324.2674 - val_loss: 354.9794\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 315.1391 - val_loss: 345.0735\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 56ms/step - loss: 1490.6465 - val_loss: 1599.1730\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1474.3453 - val_loss: 1582.9127\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1457.6691 - val_loss: 1566.2302\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1440.2498 - val_loss: 1549.2621\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1422.3276 - val_loss: 1530.9884\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1403.3605 - val_loss: 1511.7389\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1383.1436 - val_loss: 1491.4933\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1362.2203 - val_loss: 1469.1318\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1339.3024 - val_loss: 1446.1886\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - loss: 1315.5399 - val_loss: 1421.0240\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1289.9323 - val_loss: 1394.3287\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1262.7869 - val_loss: 1366.5521\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1234.4697 - val_loss: 1336.9746\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1204.6522 - val_loss: 1305.6222\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 3ms/step - loss: 1173.5248 - val_loss: 1273.2993\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1140.8329 - val_loss: 1240.1626\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1107.5190 - val_loss: 1205.1361\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1073.1576 - val_loss: 1169.1643\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1037.7684 - val_loss: 1132.3713\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1002.2870 - val_loss: 1094.7755\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 966.1654 - val_loss: 1056.2876\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 929.0452 - val_loss: 1018.6003\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 892.6006 - val_loss: 979.8400\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 6ms/step - loss: 855.6699 - val_loss: 941.4281\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 10ms/step - loss: 819.2495 - val_loss: 902.8527\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 783.3872 - val_loss: 864.7398\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 747.9752 - val_loss: 826.9785\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 712.7700 - val_loss: 790.8595\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 679.2781 - val_loss: 753.9759\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 645.7316 - val_loss: 719.2047\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 3ms/step - loss: 613.7982 - val_loss: 684.9714\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 582.8794 - val_loss: 652.3259\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 553.4988 - val_loss: 620.1445\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 525.2162 - val_loss: 589.6357\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 498.2364 - val_loss: 560.6044\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 472.8526 - val_loss: 532.7477\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 448.9489 - val_loss: 507.1891\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 427.0180 - val_loss: 482.1532\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 405.9533 - val_loss: 459.5121\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 386.6851 - val_loss: 437.9615\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 368.7668 - val_loss: 418.1225\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 352.0511 - val_loss: 399.7228\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 336.7997 - val_loss: 382.4281\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 8ms/step - loss: 322.8360 - val_loss: 366.0035\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 309.9993 - val_loss: 351.4914\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 298.5097 - val_loss: 337.0567\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 287.6738 - val_loss: 324.4467\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 277.9588 - val_loss: 313.6976\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 269.5226 - val_loss: 302.8439\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 261.6510 - val_loss: 293.2682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 66ms/step - loss: 1628.9855 - val_loss: 1428.5359\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1611.5435 - val_loss: 1412.7974\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1594.4777 - val_loss: 1397.3489\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 3ms/step - loss: 1577.3663 - val_loss: 1382.0902\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1560.2788 - val_loss: 1366.7103\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1542.9431 - val_loss: 1351.2155\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1525.0326 - val_loss: 1335.3405\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1506.5378 - val_loss: 1319.0374\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1487.1362 - val_loss: 1302.2430\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1467.0961 - val_loss: 1284.2948\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1445.9960 - val_loss: 1265.6484\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1423.6365 - val_loss: 1246.5254\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1400.4146 - val_loss: 1226.2897\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 1376.0245 - val_loss: 1204.4938\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1349.8943 - val_loss: 1181.9454\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1322.7498 - val_loss: 1157.3892\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1293.8157 - val_loss: 1132.1082\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1263.8213 - val_loss: 1105.7756\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 3ms/step - loss: 1232.6891 - val_loss: 1078.3824\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1200.3204 - val_loss: 1050.3877\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1167.5824 - val_loss: 1020.8427\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 1133.7998 - val_loss: 991.0483\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1099.6438 - val_loss: 960.6578\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1064.7841 - val_loss: 930.4895\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1029.8560 - val_loss: 899.8176\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 994.8016 - val_loss: 868.4512\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 959.5726 - val_loss: 837.0064\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 924.2109 - val_loss: 805.9279\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 889.3945 - val_loss: 774.2312\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 854.4412 - val_loss: 743.4235\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 820.3030 - val_loss: 712.9285\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 786.5903 - val_loss: 683.2070\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 753.7292 - val_loss: 653.4927\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 721.2122 - val_loss: 624.6784\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 689.5955 - val_loss: 596.5759\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 658.9022 - val_loss: 569.1486\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 629.0797 - val_loss: 542.1547\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 600.2338 - val_loss: 516.6393\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 6ms/step - loss: 572.5566 - val_loss: 492.1706\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 3ms/step - loss: 546.2747 - val_loss: 468.1406\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 520.4952 - val_loss: 445.8186\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 496.0382 - val_loss: 424.6853\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 473.2870 - val_loss: 403.7297\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 9ms/step - loss: 451.2364 - val_loss: 384.2010\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 430.2662 - val_loss: 366.1597\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 410.8214 - val_loss: 348.8090\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 392.4603 - val_loss: 333.2079\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 375.5629 - val_loss: 318.2878\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 359.8590 - val_loss: 304.2504\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 345.0052 - val_loss: 291.6021\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 62ms/step - loss: 1540.8527 - val_loss: 1548.8589\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1525.4927 - val_loss: 1533.4233\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1510.0706 - val_loss: 1517.8469\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1494.6278 - val_loss: 1501.9260\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1478.9596 - val_loss: 1485.4473\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 3ms/step - loss: 1462.4930 - val_loss: 1468.6743\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1445.3740 - val_loss: 1450.8433\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1427.4606 - val_loss: 1431.5857\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1408.0518 - val_loss: 1411.6753\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - loss: 1387.8877 - val_loss: 1390.0973\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1366.0027 - val_loss: 1368.1017\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1343.4073 - val_loss: 1343.7397\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1318.7446 - val_loss: 1318.9705\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1293.1757 - val_loss: 1292.7953\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1266.6014 - val_loss: 1264.7468\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1237.7596 - val_loss: 1236.5417\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1208.7253 - val_loss: 1205.8464\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1177.6078 - val_loss: 1174.7657\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1145.5267 - val_loss: 1142.8243\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 1112.5996 - val_loss: 1110.1411\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1078.8678 - val_loss: 1076.1344\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 12ms/step - loss: 1044.3749 - val_loss: 1041.8494\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1009.3478 - val_loss: 1007.6821\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 973.9721 - val_loss: 972.9050\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 938.6824 - val_loss: 937.5942\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 903.0488 - val_loss: 903.2166\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 867.8575 - val_loss: 868.9120\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 832.8899 - val_loss: 835.1269\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 798.3002 - val_loss: 802.0698\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 7ms/step - loss: 764.1545 - val_loss: 769.3822\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 3ms/step - loss: 730.9647 - val_loss: 737.3121\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 698.3667 - val_loss: 706.0615\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 666.6696 - val_loss: 675.7199\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 635.8995 - val_loss: 645.6839\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 605.5898 - val_loss: 617.4044\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 3ms/step - loss: 577.1072 - val_loss: 589.5165\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 549.2158 - val_loss: 562.7386\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 522.6622 - val_loss: 537.5592\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 497.3842 - val_loss: 513.6360\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 473.4533 - val_loss: 490.6895\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 450.4637 - val_loss: 469.3707\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 429.6345 - val_loss: 448.2570\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 409.0419 - val_loss: 429.3320\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 390.1595 - val_loss: 411.6676\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 372.5971 - val_loss: 394.9015\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 356.3697 - val_loss: 378.7889\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 340.9359 - val_loss: 364.3054\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 327.0984 - val_loss: 350.3152\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 313.6800 - val_loss: 338.2224\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 301.8069 - val_loss: 326.7350\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 67ms/step - loss: 1583.1398 - val_loss: 1551.0386\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 15ms/step - loss: 1564.1716 - val_loss: 1533.2941\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1545.3555 - val_loss: 1515.7810\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1526.8710 - val_loss: 1497.8837\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 6ms/step - loss: 1507.7489 - val_loss: 1480.0800\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 7ms/step - loss: 1488.3322 - val_loss: 1461.8733\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1468.6377 - val_loss: 1442.1593\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1447.4098 - val_loss: 1422.2819\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 1426.1422 - val_loss: 1400.8578\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1403.7106 - val_loss: 1379.1381\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1380.5145 - val_loss: 1356.1847\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 1356.2002 - val_loss: 1332.1450\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 1330.6342 - val_loss: 1307.2090\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1304.1100 - val_loss: 1281.6252\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1276.6428 - val_loss: 1254.9669\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1248.2343 - val_loss: 1227.2856\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1218.6743 - val_loss: 1198.9849\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1188.7354 - val_loss: 1169.9559\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 8ms/step - loss: 1158.0425 - val_loss: 1140.4316\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 3ms/step - loss: 1126.7190 - val_loss: 1110.5815\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1095.2843 - val_loss: 1079.8405\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 1063.5989 - val_loss: 1048.7358\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1031.1521 - val_loss: 1018.1530\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 999.0535 - val_loss: 986.8381\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 966.6219 - val_loss: 955.8192\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 7ms/step - loss: 934.5143 - val_loss: 924.4894\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 902.4545 - val_loss: 893.6780\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 871.0599 - val_loss: 862.4946\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 839.5380 - val_loss: 832.5435\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 808.5703 - val_loss: 802.3513\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 778.2159 - val_loss: 772.2952\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 748.6094 - val_loss: 742.8195\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 719.0530 - val_loss: 714.4309\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 690.5392 - val_loss: 685.9616\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 662.3253 - val_loss: 658.3140\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 634.8769 - val_loss: 630.8416\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 607.8262 - val_loss: 604.0367\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 581.6797 - val_loss: 577.5541\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 555.7067 - val_loss: 552.5854\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 531.0044 - val_loss: 528.0985\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 507.3456 - val_loss: 503.7195\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 12ms/step - loss: 483.8470 - val_loss: 481.0216\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 461.4385 - val_loss: 459.3293\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 440.1653 - val_loss: 438.0495\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 419.6710 - val_loss: 417.3512\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 399.6270 - val_loss: 398.6682\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 381.1143 - val_loss: 381.1823\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 363.8565 - val_loss: 363.4525\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 346.9619 - val_loss: 347.8031\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 9ms/step - loss: 331.3624 - val_loss: 333.4464\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 62ms/step - loss: 1575.9514 - val_loss: 1574.3389\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1561.9958 - val_loss: 1560.9623\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1548.3041 - val_loss: 1547.6648\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1535.0405 - val_loss: 1534.2963\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 1521.5106 - val_loss: 1521.1033\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1508.0127 - val_loss: 1507.5356\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1493.8424 - val_loss: 1494.0321\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1479.5565 - val_loss: 1479.3121\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1464.2983 - val_loss: 1464.2710\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 1448.4370 - val_loss: 1448.4426\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1431.6455 - val_loss: 1431.6086\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1413.9054 - val_loss: 1413.7059\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1394.9108 - val_loss: 1394.9060\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1374.8710 - val_loss: 1374.8564\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1353.4059 - val_loss: 1353.9437\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1330.8802 - val_loss: 1331.8472\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1307.0347 - val_loss: 1308.5847\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1281.9368 - val_loss: 1283.9125\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1255.6177 - val_loss: 1258.4056\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1228.4814 - val_loss: 1231.7286\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1200.0404 - val_loss: 1204.5011\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 1171.0312 - val_loss: 1175.6246\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1140.6571 - val_loss: 1146.4318\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 11ms/step - loss: 1109.6610 - val_loss: 1116.6935\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1078.0804 - val_loss: 1086.0358\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 1045.4615 - val_loss: 1055.3368\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1012.6289 - val_loss: 1023.2272\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 978.7879 - val_loss: 990.4675\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 944.4379 - val_loss: 957.5049\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 909.6170 - val_loss: 924.6942\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 874.6483 - val_loss: 891.5657\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 840.1446 - val_loss: 857.2296\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 804.6538 - val_loss: 824.0516\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 769.6310 - val_loss: 791.1813\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 735.2469 - val_loss: 757.6624\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 700.8214 - val_loss: 725.1865\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 3ms/step - loss: 667.0214 - val_loss: 692.7855\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 633.5966 - val_loss: 661.3772\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 600.8350 - val_loss: 630.3843\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 569.3037 - val_loss: 599.6302\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 538.2631 - val_loss: 570.0250\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 508.5142 - val_loss: 541.3041\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 479.7515 - val_loss: 513.9379\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 452.4675 - val_loss: 487.8708\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 426.5674 - val_loss: 462.4414\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 402.1639 - val_loss: 438.5270\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 379.1628 - val_loss: 416.8124\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 358.0321 - val_loss: 395.5497\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 338.0256 - val_loss: 376.5703\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 320.2617 - val_loss: 358.1588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 65ms/step - loss: 1547.4554 - val_loss: 1566.9841\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 16ms/step - loss: 1532.7644 - val_loss: 1553.2838\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1517.9431 - val_loss: 1539.6707\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1502.9733 - val_loss: 1525.4163\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1486.9723 - val_loss: 1510.8588\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1470.4237 - val_loss: 1494.6642\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1452.4290 - val_loss: 1477.3124\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 9ms/step - loss: 1432.9845 - val_loss: 1458.9701\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1412.5145 - val_loss: 1439.3043\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1390.4844 - val_loss: 1418.1018\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1366.8273 - val_loss: 1395.8221\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1342.1039 - val_loss: 1371.7061\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 1315.3213 - val_loss: 1346.7581\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1287.4603 - val_loss: 1320.7137\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1258.9065 - val_loss: 1292.6029\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1228.6138 - val_loss: 1264.0398\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1197.7025 - val_loss: 1234.3199\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1165.4520 - val_loss: 1204.2998\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1132.9044 - val_loss: 1173.0615\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 3ms/step - loss: 1099.6257 - val_loss: 1141.4337\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1065.9950 - val_loss: 1109.7921\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1032.5872 - val_loss: 1076.5911\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 7ms/step - loss: 998.3098 - val_loss: 1044.2126\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 964.2925 - val_loss: 1011.7042\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 930.4639 - val_loss: 979.4106\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 3ms/step - loss: 897.2004 - val_loss: 946.9321\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 864.1846 - val_loss: 915.0805\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 831.9344 - val_loss: 884.0594\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 800.3521 - val_loss: 853.5563\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 769.4548 - val_loss: 823.1591\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 3ms/step - loss: 739.2073 - val_loss: 793.3936\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 709.8974 - val_loss: 764.2200\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 681.4603 - val_loss: 736.4529\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 654.3290 - val_loss: 708.9739\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 628.1509 - val_loss: 682.5797\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 603.0906 - val_loss: 657.2994\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 579.1418 - val_loss: 633.4046\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 556.3862 - val_loss: 609.8953\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 534.7255 - val_loss: 587.0636\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 513.7716 - val_loss: 565.8356\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 493.9374 - val_loss: 545.8116\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 11ms/step - loss: 475.6443 - val_loss: 525.9137\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 457.9612 - val_loss: 507.2424\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 441.1497 - val_loss: 489.5598\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 425.7382 - val_loss: 471.8055\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 410.6160 - val_loss: 456.3228\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 396.6302 - val_loss: 441.3741\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 383.5403 - val_loss: 427.0624\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 3ms/step - loss: 371.1973 - val_loss: 413.3910\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 359.4669 - val_loss: 400.2792\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 56ms/step - loss: 1556.0342 - val_loss: 1623.8279\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1540.5459 - val_loss: 1609.1223\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1525.2550 - val_loss: 1594.5413\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1509.9745 - val_loss: 1580.0752\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1494.7101 - val_loss: 1565.0823\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 1478.6617 - val_loss: 1550.0673\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1462.0920 - val_loss: 1534.3669\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1444.8315 - val_loss: 1517.4927\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1426.6638 - val_loss: 1500.0909\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1407.6064 - val_loss: 1481.7137\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1387.5079 - val_loss: 1462.3014\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1366.3229 - val_loss: 1441.7715\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 1344.1168 - val_loss: 1419.7656\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 3ms/step - loss: 1320.6290 - val_loss: 1396.4921\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1295.8170 - val_loss: 1372.1736\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1270.2676 - val_loss: 1346.5964\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1243.4152 - val_loss: 1319.5740\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1215.7731 - val_loss: 1291.7385\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1186.9437 - val_loss: 1263.3362\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1157.6385 - val_loss: 1234.1683\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1127.9607 - val_loss: 1203.6068\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 9ms/step - loss: 1097.5719 - val_loss: 1172.3589\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 8ms/step - loss: 1066.6426 - val_loss: 1141.3022\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1035.8612 - val_loss: 1109.5699\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 1004.8699 - val_loss: 1077.5887\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 973.8994 - val_loss: 1045.7249\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 942.9069 - val_loss: 1013.8493\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 912.5538 - val_loss: 981.5544\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 882.2744 - val_loss: 950.0742\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 3ms/step - loss: 852.7310 - val_loss: 918.7542\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 823.5349 - val_loss: 887.3234\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 794.9282 - val_loss: 856.6767\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 766.8209 - val_loss: 826.7201\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 739.3923 - val_loss: 797.3153\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 712.6183 - val_loss: 768.4197\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 686.4376 - val_loss: 739.6276\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 661.1039 - val_loss: 711.9287\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 636.8522 - val_loss: 684.4902\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 613.0905 - val_loss: 658.0048\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 590.1229 - val_loss: 632.6862\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 567.9880 - val_loss: 607.7472\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 546.3759 - val_loss: 584.2600\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 526.0288 - val_loss: 560.9385\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 506.2208 - val_loss: 538.5435\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 487.2802 - val_loss: 516.6263\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 469.0324 - val_loss: 496.1217\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 452.0738 - val_loss: 475.6948\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 435.3556 - val_loss: 457.4133\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 420.0477 - val_loss: 439.1155\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 404.9587 - val_loss: 422.2328\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 4s - 154ms/step - loss: 1533.6099 - val_loss: 1570.7771\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 6ms/step - loss: 1518.1777 - val_loss: 1553.6571\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 3ms/step - loss: 1502.3779 - val_loss: 1536.5300\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1486.4403 - val_loss: 1518.7231\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1469.8772 - val_loss: 1500.5468\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1452.7966 - val_loss: 1481.5969\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1435.0259 - val_loss: 1461.7214\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1416.5201 - val_loss: 1440.8827\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1397.1332 - val_loss: 1419.1882\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1376.6006 - val_loss: 1396.7323\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1355.4152 - val_loss: 1372.7838\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1333.4100 - val_loss: 1347.6149\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1310.1278 - val_loss: 1322.1071\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1286.2744 - val_loss: 1295.1416\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1261.1309 - val_loss: 1267.6387\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1235.2887 - val_loss: 1238.9037\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1208.3612 - val_loss: 1209.7290\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1180.9343 - val_loss: 1178.6357\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1152.5027 - val_loss: 1146.7118\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1122.7170 - val_loss: 1115.3134\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1093.3984 - val_loss: 1082.2910\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1062.4183 - val_loss: 1050.1730\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1032.1104 - val_loss: 1015.6481\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1000.2867 - val_loss: 982.0629\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 968.4445 - val_loss: 947.8958\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 936.2827 - val_loss: 913.8285\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 904.3337 - val_loss: 878.4946\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 871.2499 - val_loss: 844.9258\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 839.2784 - val_loss: 810.4213\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 806.6242 - val_loss: 777.0104\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 774.8796 - val_loss: 743.1043\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 743.3274 - val_loss: 710.0554\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 712.5005 - val_loss: 677.5341\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 681.6876 - val_loss: 646.4222\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 652.0608 - val_loss: 615.5307\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 622.8762 - val_loss: 585.9886\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 594.7996 - val_loss: 557.5152\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 567.6339 - val_loss: 529.6559\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 541.2671 - val_loss: 503.0537\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 515.8364 - val_loss: 477.6550\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 491.8660 - val_loss: 453.2990\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 10ms/step - loss: 468.9692 - val_loss: 430.7363\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 447.1271 - val_loss: 409.4643\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 426.6276 - val_loss: 389.0888\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 407.2638 - val_loss: 370.4420\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 389.0065 - val_loss: 352.7300\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 371.8303 - val_loss: 336.1197\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 355.9399 - val_loss: 320.5674\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 340.9152 - val_loss: 306.2990\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 326.9863 - val_loss: 293.1420\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 72ms/step - loss: 1523.7852 - val_loss: 1557.4839\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1509.5641 - val_loss: 1541.4186\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1495.3198 - val_loss: 1524.6278\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 6ms/step - loss: 1480.2013 - val_loss: 1507.4882\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1464.3849 - val_loss: 1489.2255\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1447.5659 - val_loss: 1469.7153\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1429.5040 - val_loss: 1448.8734\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1410.2573 - val_loss: 1426.6527\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1389.8556 - val_loss: 1402.9218\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1368.0127 - val_loss: 1378.3167\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1345.1526 - val_loss: 1352.1077\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1320.9067 - val_loss: 1324.8103\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 9ms/step - loss: 1295.6461 - val_loss: 1296.0792\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1269.4758 - val_loss: 1265.8495\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1241.7302 - val_loss: 1235.2762\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1213.0828 - val_loss: 1204.0193\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1183.8239 - val_loss: 1171.1813\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1153.5079 - val_loss: 1137.6807\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 1122.6204 - val_loss: 1103.4865\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 8ms/step - loss: 1091.0068 - val_loss: 1069.0551\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1059.7395 - val_loss: 1033.9760\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 10ms/step - loss: 1027.4576 - val_loss: 999.8463\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 995.4823 - val_loss: 965.3442\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 963.3183 - val_loss: 929.6875\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 930.9321 - val_loss: 895.1566\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 898.8569 - val_loss: 860.4949\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 3ms/step - loss: 867.0089 - val_loss: 826.4911\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 834.9634 - val_loss: 793.7592\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 804.1547 - val_loss: 760.2888\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 773.2703 - val_loss: 727.9798\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 743.2676 - val_loss: 696.3807\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 713.4919 - val_loss: 666.3628\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 684.8146 - val_loss: 636.9321\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 656.6366 - val_loss: 608.3976\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 9ms/step - loss: 629.5101 - val_loss: 580.7924\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 3ms/step - loss: 603.4539 - val_loss: 554.0123\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 578.0914 - val_loss: 528.7365\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 553.6052 - val_loss: 505.1418\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 530.7700 - val_loss: 481.6656\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 508.1815 - val_loss: 460.0705\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 487.1466 - val_loss: 439.1585\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 466.5816 - val_loss: 420.1955\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 447.7482 - val_loss: 401.5931\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 429.2595 - val_loss: 384.7708\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 412.5288 - val_loss: 368.0903\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 395.7835 - val_loss: 353.6942\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 380.6398 - val_loss: 339.7563\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 366.1297 - val_loss: 326.8499\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 352.6136 - val_loss: 314.7378\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 339.6255 - val_loss: 303.7191\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 76ms/step - loss: 1593.7654 - val_loss: 1698.8159\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1577.5709 - val_loss: 1682.3030\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1561.9406 - val_loss: 1666.2589\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1546.4624 - val_loss: 1650.4849\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1531.0641 - val_loss: 1634.7870\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1515.8330 - val_loss: 1618.5581\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1500.2330 - val_loss: 1602.5679\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1484.6123 - val_loss: 1586.1215\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1468.5688 - val_loss: 1569.2299\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 1452.0653 - val_loss: 1551.5026\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1434.9667 - val_loss: 1533.0697\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1416.9999 - val_loss: 1514.3910\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1398.5789 - val_loss: 1494.6866\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1379.2328 - val_loss: 1474.5280\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1359.3527 - val_loss: 1453.3010\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1338.4846 - val_loss: 1431.4635\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1317.1942 - val_loss: 1408.6840\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1295.0164 - val_loss: 1385.4927\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1272.1521 - val_loss: 1361.3021\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1248.7981 - val_loss: 1335.9596\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1224.6202 - val_loss: 1310.2513\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 1199.7773 - val_loss: 1284.3617\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1174.7103 - val_loss: 1257.6169\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1149.0560 - val_loss: 1230.2789\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1123.0439 - val_loss: 1202.7839\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1096.5569 - val_loss: 1174.6886\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1069.9635 - val_loss: 1145.5990\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1042.8485 - val_loss: 1117.1082\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1015.7989 - val_loss: 1088.4608\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 988.5150 - val_loss: 1059.1669\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 961.0684 - val_loss: 1030.4897\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 933.7674 - val_loss: 1001.2514\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 906.3628 - val_loss: 972.2519\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 879.2849 - val_loss: 943.1272\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 852.3517 - val_loss: 914.7031\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 825.9377 - val_loss: 886.1993\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 799.4888 - val_loss: 858.0638\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 773.4946 - val_loss: 830.0958\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 747.9651 - val_loss: 802.7252\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 722.7150 - val_loss: 775.4034\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 698.0265 - val_loss: 748.6057\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 10ms/step - loss: 673.6442 - val_loss: 722.4589\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 649.9532 - val_loss: 696.4508\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 3ms/step - loss: 626.6955 - val_loss: 671.2413\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 603.9800 - val_loss: 647.1658\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - loss: 582.4128 - val_loss: 623.3394\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 561.2983 - val_loss: 600.4566\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 540.8079 - val_loss: 578.5009\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 521.3882 - val_loss: 556.2844\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 502.1995 - val_loss: 535.8262\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 1542.4204 - val_loss: 1512.9672\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1525.8619 - val_loss: 1495.7744\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1508.3613 - val_loss: 1478.2850\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1490.3556 - val_loss: 1459.4236\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1471.2056 - val_loss: 1439.8463\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1451.4028 - val_loss: 1418.9476\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1429.9966 - val_loss: 1397.7242\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1407.8361 - val_loss: 1374.7009\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1384.2185 - val_loss: 1350.7749\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - loss: 1359.7289 - val_loss: 1325.8005\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1334.3484 - val_loss: 1299.4785\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1307.4962 - val_loss: 1272.3406\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1279.7212 - val_loss: 1244.3785\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1251.0785 - val_loss: 1215.2278\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1221.6588 - val_loss: 1184.9237\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1191.0851 - val_loss: 1154.3816\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 3ms/step - loss: 1160.3429 - val_loss: 1122.8007\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1128.5717 - val_loss: 1091.0513\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1096.4185 - val_loss: 1059.0902\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1064.1184 - val_loss: 1026.7493\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 1030.9762 - val_loss: 994.2495\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 997.9341 - val_loss: 961.5016\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 3ms/step - loss: 964.8216 - val_loss: 928.8419\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 931.7698 - val_loss: 896.4270\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 3ms/step - loss: 898.7846 - val_loss: 864.1088\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 865.8890 - val_loss: 832.8542\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 833.9218 - val_loss: 801.5325\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 802.2577 - val_loss: 770.3454\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 770.4678 - val_loss: 740.9113\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 3ms/step - loss: 740.4319 - val_loss: 711.3679\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 710.4277 - val_loss: 683.0046\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 681.7140 - val_loss: 655.1248\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 3ms/step - loss: 653.1588 - val_loss: 628.4958\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 625.7394 - val_loss: 601.9070\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 598.5281 - val_loss: 576.7345\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 572.7614 - val_loss: 551.9156\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 547.9614 - val_loss: 528.5291\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 523.5762 - val_loss: 506.5213\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 500.8011 - val_loss: 484.8239\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 478.4717 - val_loss: 464.8473\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 3ms/step - loss: 457.7249 - val_loss: 445.5828\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 437.8504 - val_loss: 427.3786\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 3ms/step - loss: 418.9221 - val_loss: 410.5006\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 401.2133 - val_loss: 394.2990\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 12ms/step - loss: 384.6978 - val_loss: 379.1025\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 368.9771 - val_loss: 365.3945\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 354.4578 - val_loss: 352.4792\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 341.0844 - val_loss: 340.5665\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 328.7918 - val_loss: 329.6102\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 317.0963 - val_loss: 319.7897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 60ms/step - loss: 1611.7332 - val_loss: 1621.5170\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1595.5057 - val_loss: 1605.7621\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1580.3955 - val_loss: 1590.4379\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1565.5845 - val_loss: 1576.0693\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1551.4967 - val_loss: 1561.6082\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1537.3871 - val_loss: 1547.6525\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1523.3844 - val_loss: 1533.4159\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1509.0028 - val_loss: 1518.5684\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1494.0294 - val_loss: 1503.1005\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1478.1902 - val_loss: 1486.8390\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1461.3680 - val_loss: 1469.6888\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1443.9270 - val_loss: 1450.8799\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 9ms/step - loss: 1425.0314 - val_loss: 1431.7075\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1405.4771 - val_loss: 1411.3716\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1384.7861 - val_loss: 1390.1194\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1362.8535 - val_loss: 1367.9810\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1340.1860 - val_loss: 1344.5563\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1316.2833 - val_loss: 1320.2981\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1291.5244 - val_loss: 1294.9554\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 3ms/step - loss: 1265.8605 - val_loss: 1269.3816\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1239.6667 - val_loss: 1242.8573\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1212.5787 - val_loss: 1215.6414\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1184.7736 - val_loss: 1187.6294\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 11ms/step - loss: 1156.5590 - val_loss: 1158.8671\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1127.6497 - val_loss: 1130.3807\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1098.8656 - val_loss: 1101.1912\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1069.3834 - val_loss: 1071.8278\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 1039.8593 - val_loss: 1042.6147\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1010.3326 - val_loss: 1012.5311\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 980.1755 - val_loss: 983.1365\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 6ms/step - loss: 950.4352 - val_loss: 953.8229\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 920.8993 - val_loss: 924.1467\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 891.6472 - val_loss: 894.2941\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 862.1270 - val_loss: 864.9918\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 832.8221 - val_loss: 836.1882\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 804.2717 - val_loss: 807.0544\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 775.2653 - val_loss: 778.9337\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 747.3759 - val_loss: 750.3438\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 9ms/step - loss: 719.5500 - val_loss: 721.9269\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 691.8207 - val_loss: 694.4681\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 3ms/step - loss: 664.9394 - val_loss: 667.4341\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 638.2819 - val_loss: 641.3103\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 613.0294 - val_loss: 615.0971\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 587.7700 - val_loss: 589.9583\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 563.3146 - val_loss: 565.4557\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 539.6465 - val_loss: 541.6697\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 3ms/step - loss: 516.6834 - val_loss: 519.4908\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 495.1990 - val_loss: 497.6715\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 474.4239 - val_loss: 476.6245\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 454.4813 - val_loss: 456.7259\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 64ms/step - loss: 1600.7771 - val_loss: 1487.7904\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1584.6097 - val_loss: 1472.4879\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 3ms/step - loss: 1568.4778 - val_loss: 1457.4172\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1552.5513 - val_loss: 1442.0319\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1536.2875 - val_loss: 1426.4343\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1519.8119 - val_loss: 1410.5725\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1502.9017 - val_loss: 1394.1875\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1485.3790 - val_loss: 1377.6171\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1467.4370 - val_loss: 1360.1580\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1448.5028 - val_loss: 1341.9866\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 9ms/step - loss: 1428.8113 - val_loss: 1323.2064\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1408.3433 - val_loss: 1303.7040\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1387.0658 - val_loss: 1283.0846\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1364.6385 - val_loss: 1261.8268\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1341.5587 - val_loss: 1239.4408\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1317.3192 - val_loss: 1216.6527\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1292.4113 - val_loss: 1193.1770\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1266.7823 - val_loss: 1169.0217\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1240.4882 - val_loss: 1143.8523\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1213.1721 - val_loss: 1118.8948\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1185.8844 - val_loss: 1093.0674\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1157.8217 - val_loss: 1066.8042\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 1129.2269 - val_loss: 1040.6715\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1100.6694 - val_loss: 1013.8751\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1071.5543 - val_loss: 987.0610\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1042.0619 - val_loss: 960.0341\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1012.3909 - val_loss: 932.5217\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 982.7950 - val_loss: 904.9727\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 953.2188 - val_loss: 877.2742\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 923.2166 - val_loss: 850.5608\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 893.8851 - val_loss: 823.8973\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 864.6359 - val_loss: 796.5892\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 3ms/step - loss: 835.1221 - val_loss: 770.0131\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 806.2717 - val_loss: 742.9371\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 776.8683 - val_loss: 716.5191\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 748.1788 - val_loss: 689.1512\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 718.9341 - val_loss: 662.6449\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 690.2059 - val_loss: 635.7359\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 661.3006 - val_loss: 609.5937\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 633.1411 - val_loss: 583.6211\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 605.5278 - val_loss: 558.1429\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 578.5090 - val_loss: 533.0037\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 551.7310 - val_loss: 509.5279\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 526.3361 - val_loss: 486.1075\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 9ms/step - loss: 501.7088 - val_loss: 463.1852\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 477.7862 - val_loss: 441.7332\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 3ms/step - loss: 455.2299 - val_loss: 421.1019\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 433.8004 - val_loss: 401.1528\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 413.3814 - val_loss: 382.5338\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 393.8211 - val_loss: 365.6000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 67ms/step - loss: 1527.1554 - val_loss: 1436.1094\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1508.2916 - val_loss: 1417.3893\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1488.8367 - val_loss: 1396.9012\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1467.9380 - val_loss: 1375.1729\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1445.6942 - val_loss: 1352.8885\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1422.5956 - val_loss: 1328.4885\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 7ms/step - loss: 1397.5341 - val_loss: 1303.3442\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1371.4080 - val_loss: 1276.3983\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1343.9091 - val_loss: 1248.2550\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 1314.7990 - val_loss: 1219.1774\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1284.8226 - val_loss: 1188.5330\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1253.5381 - val_loss: 1156.6122\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1220.8877 - val_loss: 1123.9915\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1187.4779 - val_loss: 1090.1689\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1153.3241 - val_loss: 1055.2939\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1118.2939 - val_loss: 1020.2820\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1082.6630 - val_loss: 985.5357\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1047.0560 - val_loss: 949.5649\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1010.7094 - val_loss: 913.8698\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 3ms/step - loss: 974.4844 - val_loss: 877.2283\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 937.4268 - val_loss: 842.2794\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 901.6021 - val_loss: 806.1594\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 865.8370 - val_loss: 770.2555\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 829.8358 - val_loss: 736.3958\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 7ms/step - loss: 795.0794 - val_loss: 702.3593\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 760.5698 - val_loss: 669.0356\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 726.8107 - val_loss: 636.2830\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 10ms/step - loss: 693.9950 - val_loss: 604.2623\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 661.8082 - val_loss: 573.9460\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 630.6805 - val_loss: 544.4249\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 600.9537 - val_loss: 516.0657\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 3ms/step - loss: 572.2966 - val_loss: 489.1548\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 545.0478 - val_loss: 463.0133\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 518.7136 - val_loss: 438.6908\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 493.7884 - val_loss: 415.6033\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 470.2380 - val_loss: 393.3555\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 447.6278 - val_loss: 373.0091\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 426.5482 - val_loss: 353.5645\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 406.9583 - val_loss: 335.5880\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 388.5435 - val_loss: 319.0824\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 371.3917 - val_loss: 304.2283\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 355.7651 - val_loss: 289.9597\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 341.1988 - val_loss: 277.2533\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 327.6590 - val_loss: 265.6716\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 315.3642 - val_loss: 255.1320\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - loss: 304.0583 - val_loss: 245.2990\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 293.6577 - val_loss: 236.1983\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 284.0355 - val_loss: 228.1847\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 275.2413 - val_loss: 221.3038\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 267.5337 - val_loss: 214.5572\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 67ms/step - loss: 1574.0399 - val_loss: 1545.5563\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1557.3176 - val_loss: 1530.3523\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1541.3168 - val_loss: 1515.3455\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1525.3820 - val_loss: 1500.4302\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1509.8428 - val_loss: 1485.2065\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 3ms/step - loss: 1493.6055 - val_loss: 1470.3020\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1477.7101 - val_loss: 1454.3995\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1460.9348 - val_loss: 1438.4612\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1443.6667 - val_loss: 1422.2174\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1426.0369 - val_loss: 1404.8848\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1407.4817 - val_loss: 1387.0363\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 1388.1454 - val_loss: 1368.0563\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1367.7188 - val_loss: 1348.4092\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1346.1167 - val_loss: 1327.7833\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1323.2776 - val_loss: 1305.5323\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1299.2654 - val_loss: 1281.9574\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1273.8658 - val_loss: 1257.5946\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1247.0378 - val_loss: 1232.2144\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1218.9376 - val_loss: 1205.4767\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1189.5944 - val_loss: 1176.7356\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1157.7373 - val_loss: 1147.1052\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 1125.2009 - val_loss: 1115.9766\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1091.1237 - val_loss: 1083.9550\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1055.8627 - val_loss: 1050.7821\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 1019.7842 - val_loss: 1016.4561\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 982.6622 - val_loss: 982.0446\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 945.1005 - val_loss: 947.4215\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 907.6191 - val_loss: 911.4567\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 868.9169 - val_loss: 876.5143\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 7ms/step - loss: 831.0781 - val_loss: 840.6376\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 792.7223 - val_loss: 805.0582\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 755.0113 - val_loss: 769.5737\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 717.7673 - val_loss: 735.1567\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 681.4008 - val_loss: 701.7139\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 7ms/step - loss: 645.8667 - val_loss: 669.0977\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 611.7357 - val_loss: 636.5084\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 578.1608 - val_loss: 605.3049\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 546.1838 - val_loss: 575.5783\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 516.4120 - val_loss: 546.8030\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 487.3576 - val_loss: 520.5258\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 460.9887 - val_loss: 495.0400\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 435.9845 - val_loss: 471.2251\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 10ms/step - loss: 412.4535 - val_loss: 449.3761\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 391.3057 - val_loss: 428.2014\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 370.9993 - val_loss: 409.2526\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 352.5063 - val_loss: 391.8319\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 335.9020 - val_loss: 375.3449\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 320.4814 - val_loss: 360.1510\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 306.3939 - val_loss: 346.3530\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 293.5240 - val_loss: 333.8393\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 57ms/step - loss: 1557.6282 - val_loss: 1602.4747\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 6ms/step - loss: 1542.1620 - val_loss: 1587.2726\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1527.0172 - val_loss: 1571.8953\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1511.3599 - val_loss: 1556.6948\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1495.7196 - val_loss: 1540.7126\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1479.6725 - val_loss: 1524.4166\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1462.9695 - val_loss: 1507.5812\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1445.6643 - val_loss: 1489.7559\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1427.4042 - val_loss: 1470.9974\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 1407.8376 - val_loss: 1451.6575\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1387.5554 - val_loss: 1430.7662\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1365.6301 - val_loss: 1408.4135\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1342.5575 - val_loss: 1384.3665\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 9ms/step - loss: 1317.6842 - val_loss: 1360.0226\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1292.1763 - val_loss: 1333.8300\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1265.0968 - val_loss: 1306.7537\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1237.3352 - val_loss: 1278.5363\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1208.3275 - val_loss: 1249.5718\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 1178.5719 - val_loss: 1219.6315\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1148.1189 - val_loss: 1189.0581\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1117.1447 - val_loss: 1157.6328\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1085.4388 - val_loss: 1125.6487\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1053.1294 - val_loss: 1094.1167\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 12ms/step - loss: 1021.3515 - val_loss: 1061.1332\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 988.7471 - val_loss: 1028.6620\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 3ms/step - loss: 956.3380 - val_loss: 995.8887\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 923.9880 - val_loss: 963.2980\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 3ms/step - loss: 891.5781 - val_loss: 931.2524\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 859.8386 - val_loss: 898.9972\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 828.1320 - val_loss: 867.1384\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 797.2746 - val_loss: 835.6495\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 767.0190 - val_loss: 804.4109\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 736.8168 - val_loss: 774.7213\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 708.0701 - val_loss: 744.1857\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 679.2228 - val_loss: 715.1476\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 651.4727 - val_loss: 686.4149\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 624.3328 - val_loss: 659.0873\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 598.5052 - val_loss: 632.2641\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 573.4754 - val_loss: 606.2435\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 3ms/step - loss: 549.1335 - val_loss: 581.3267\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 526.3619 - val_loss: 557.3687\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 504.5032 - val_loss: 534.9229\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 483.7187 - val_loss: 513.5380\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 464.0809 - val_loss: 493.2479\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 3ms/step - loss: 445.6013 - val_loss: 473.6296\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 428.0197 - val_loss: 455.1494\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 3ms/step - loss: 411.5949 - val_loss: 437.7775\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 396.1929 - val_loss: 421.1440\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 381.5361 - val_loss: 406.1096\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 368.2709 - val_loss: 391.4001\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 83ms/step - loss: 1502.1423 - val_loss: 1414.7153\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1482.5083 - val_loss: 1395.6418\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1462.6472 - val_loss: 1375.7686\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1442.1733 - val_loss: 1355.4756\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 6ms/step - loss: 1420.7786 - val_loss: 1334.5054\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1398.5834 - val_loss: 1312.4647\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 3ms/step - loss: 1375.3927 - val_loss: 1289.3608\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1351.0585 - val_loss: 1265.7444\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1325.9723 - val_loss: 1241.0007\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1299.5557 - val_loss: 1215.9846\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1272.8079 - val_loss: 1189.0387\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 1244.1102 - val_loss: 1162.0740\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1214.8118 - val_loss: 1134.2811\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1185.2992 - val_loss: 1105.6273\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1155.0084 - val_loss: 1076.3483\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1123.6674 - val_loss: 1046.8759\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1091.8163 - val_loss: 1016.8826\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1059.6616 - val_loss: 986.7411\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 3ms/step - loss: 1027.2567 - val_loss: 956.0767\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 994.1984 - val_loss: 925.7383\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 961.3109 - val_loss: 895.1539\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 928.5416 - val_loss: 864.6644\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 3ms/step - loss: 895.8860 - val_loss: 834.4295\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 863.3021 - val_loss: 804.7474\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 831.6318 - val_loss: 774.7998\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 799.7881 - val_loss: 745.9646\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 768.7354 - val_loss: 717.5098\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 738.2974 - val_loss: 690.1319\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 708.6901 - val_loss: 662.6791\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 679.7110 - val_loss: 636.0542\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 651.4059 - val_loss: 610.5912\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 623.8005 - val_loss: 586.2855\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 597.5695 - val_loss: 561.9557\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 571.7742 - val_loss: 539.1928\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 547.0737 - val_loss: 517.1826\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 523.1397 - val_loss: 496.1837\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 500.5128 - val_loss: 475.1716\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 478.4421 - val_loss: 455.9624\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 457.7724 - val_loss: 437.4847\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 437.7961 - val_loss: 420.0906\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 419.1335 - val_loss: 403.2887\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 401.0219 - val_loss: 387.6395\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 384.3869 - val_loss: 372.4302\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 368.1024 - val_loss: 358.6521\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 353.1478 - val_loss: 345.3948\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 338.9114 - val_loss: 332.8726\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 325.7583 - val_loss: 321.0869\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 12ms/step - loss: 313.1716 - val_loss: 310.2784\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 301.6777 - val_loss: 300.1920\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 290.8600 - val_loss: 290.6517\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 52ms/step - loss: 1532.8502 - val_loss: 1658.6519\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1515.4935 - val_loss: 1639.7202\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1498.2673 - val_loss: 1620.8270\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1481.0153 - val_loss: 1601.9270\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1463.4604 - val_loss: 1582.7521\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1445.8411 - val_loss: 1562.5170\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1427.4619 - val_loss: 1542.1135\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1408.5621 - val_loss: 1521.3492\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1389.2064 - val_loss: 1499.7048\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1369.0745 - val_loss: 1477.0109\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 7ms/step - loss: 1347.8187 - val_loss: 1453.8113\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1326.0718 - val_loss: 1429.4136\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1303.5657 - val_loss: 1403.8228\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1279.8419 - val_loss: 1377.6168\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1255.3623 - val_loss: 1350.0044\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1229.9534 - val_loss: 1320.8916\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1202.8575 - val_loss: 1291.8905\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1175.4626 - val_loss: 1261.0975\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1146.7234 - val_loss: 1229.6587\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1117.4005 - val_loss: 1196.7308\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1087.0088 - val_loss: 1163.1884\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1056.1189 - val_loss: 1129.5789\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1024.6082 - val_loss: 1095.0813\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 992.5684 - val_loss: 1059.9049\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 959.9738 - val_loss: 1024.4597\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 10ms/step - loss: 927.0469 - val_loss: 989.1328\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 9ms/step - loss: 894.1211 - val_loss: 953.7896\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 861.4327 - val_loss: 918.3046\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 828.6722 - val_loss: 883.3856\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 796.5033 - val_loss: 849.0222\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 764.4633 - val_loss: 815.0421\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 733.2174 - val_loss: 781.8280\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 702.3857 - val_loss: 750.0865\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 672.6686 - val_loss: 719.1320\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 644.0938 - val_loss: 688.2130\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 616.2716 - val_loss: 658.5556\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 589.0114 - val_loss: 630.9718\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 563.3144 - val_loss: 604.3531\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 538.8821 - val_loss: 578.7168\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 515.3062 - val_loss: 554.8034\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 493.0225 - val_loss: 532.0510\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 472.0723 - val_loss: 510.3152\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 451.9310 - val_loss: 490.2950\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 433.5426 - val_loss: 470.6794\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 415.8889 - val_loss: 453.0975\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 399.4917 - val_loss: 436.8098\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 384.2363 - val_loss: 421.4245\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 369.9431 - val_loss: 407.0076\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 356.8930 - val_loss: 393.4862\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 344.4720 - val_loss: 381.4607\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 74ms/step - loss: 1595.4753 - val_loss: 1479.8164\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1577.5619 - val_loss: 1463.2903\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1559.2606 - val_loss: 1446.2493\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1540.4329 - val_loss: 1428.5997\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1520.8540 - val_loss: 1410.2535\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1500.2966 - val_loss: 1391.1118\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1478.9650 - val_loss: 1370.8546\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1456.4254 - val_loss: 1350.2004\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1433.3416 - val_loss: 1328.5116\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1409.0367 - val_loss: 1306.1259\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1383.7708 - val_loss: 1283.1061\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1357.7095 - val_loss: 1259.3596\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1330.7812 - val_loss: 1234.2775\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1302.4561 - val_loss: 1208.9773\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1273.6953 - val_loss: 1183.0359\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1244.2213 - val_loss: 1155.9617\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1213.8019 - val_loss: 1128.9772\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1183.0063 - val_loss: 1101.8112\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 1151.9655 - val_loss: 1073.7280\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1120.0283 - val_loss: 1045.1995\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1087.7213 - val_loss: 1016.5258\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1055.4299 - val_loss: 987.8582\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1023.0277 - val_loss: 958.2446\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 989.8688 - val_loss: 929.7891\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 958.0925 - val_loss: 900.5062\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 925.4117 - val_loss: 872.3943\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 3ms/step - loss: 893.7597 - val_loss: 844.1196\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 862.5984 - val_loss: 816.2664\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 831.4578 - val_loss: 789.1663\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 801.4759 - val_loss: 761.9953\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 771.8084 - val_loss: 735.6100\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 743.1343 - val_loss: 710.1295\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 715.3661 - val_loss: 685.5639\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 688.7553 - val_loss: 660.8242\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 662.1663 - val_loss: 637.4608\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 637.3016 - val_loss: 614.5864\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 8ms/step - loss: 612.7595 - val_loss: 593.3507\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 589.4941 - val_loss: 572.3426\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 567.1415 - val_loss: 552.0521\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 545.8965 - val_loss: 532.3784\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 525.3625 - val_loss: 513.8669\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 505.9692 - val_loss: 496.3691\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 10ms/step - loss: 487.7216 - val_loss: 480.0848\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 470.5500 - val_loss: 464.1103\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 454.0063 - val_loss: 449.2497\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 438.5078 - val_loss: 434.7481\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 3ms/step - loss: 423.9543 - val_loss: 420.6494\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 409.6960 - val_loss: 408.4966\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 396.9403 - val_loss: 396.1490\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 384.6546 - val_loss: 384.8487\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 53ms/step - loss: 1693.6261 - val_loss: 1592.9048\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 10ms/step - loss: 1674.5020 - val_loss: 1574.8546\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1656.2848 - val_loss: 1557.5560\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1638.7294 - val_loss: 1540.7261\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1621.6403 - val_loss: 1524.4305\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1604.8152 - val_loss: 1508.6783\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 3ms/step - loss: 1588.4279 - val_loss: 1492.6643\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 3ms/step - loss: 1571.5250 - val_loss: 1476.7125\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1554.8651 - val_loss: 1460.7782\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1537.8750 - val_loss: 1444.1348\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1520.1123 - val_loss: 1427.3019\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1501.9102 - val_loss: 1409.6837\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 3ms/step - loss: 1482.9382 - val_loss: 1390.8695\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1462.3800 - val_loss: 1371.8021\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1441.7648 - val_loss: 1350.9248\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 3ms/step - loss: 1419.0857 - val_loss: 1329.5331\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1395.6207 - val_loss: 1306.5839\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1370.4304 - val_loss: 1283.0621\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 7ms/step - loss: 1344.6049 - val_loss: 1258.0575\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1317.0785 - val_loss: 1232.3578\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1288.9481 - val_loss: 1205.1732\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1259.6715 - val_loss: 1177.2982\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1229.5562 - val_loss: 1148.9406\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 3ms/step - loss: 1198.8335 - val_loss: 1119.7365\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1167.2643 - val_loss: 1089.7394\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1135.7804 - val_loss: 1059.8375\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1103.9131 - val_loss: 1030.1996\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1072.3339 - val_loss: 999.2833\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 3ms/step - loss: 1039.8817 - val_loss: 969.1404\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 1008.4559 - val_loss: 938.5808\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 976.7955 - val_loss: 909.0697\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 3ms/step - loss: 946.2968 - val_loss: 879.0907\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 915.8300 - val_loss: 850.1484\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 886.0928 - val_loss: 822.2867\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 857.5563 - val_loss: 794.0211\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 829.2364 - val_loss: 767.5798\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 802.1694 - val_loss: 741.8165\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 775.8928 - val_loss: 716.2006\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 750.5709 - val_loss: 691.1708\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 725.9377 - val_loss: 667.0974\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 702.0421 - val_loss: 644.5508\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 679.6713 - val_loss: 621.7411\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 9ms/step - loss: 657.3652 - val_loss: 600.9698\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 636.4703 - val_loss: 580.5275\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 615.9607 - val_loss: 561.0391\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - loss: 596.3945 - val_loss: 541.6290\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 577.3231 - val_loss: 523.4075\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 559.0835 - val_loss: 506.0168\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 541.8288 - val_loss: 489.0931\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 3ms/step - loss: 524.6274 - val_loss: 473.4183\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 52ms/step - loss: 1560.4888 - val_loss: 1479.5166\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 10ms/step - loss: 1544.9468 - val_loss: 1464.5590\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1529.1456 - val_loss: 1449.1235\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 3ms/step - loss: 1512.5641 - val_loss: 1432.9846\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1495.3093 - val_loss: 1416.1754\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1477.2463 - val_loss: 1398.4379\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1457.8918 - val_loss: 1379.8977\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1437.8381 - val_loss: 1359.8407\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1416.1523 - val_loss: 1338.9590\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 1393.3958 - val_loss: 1316.5977\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 1369.2035 - val_loss: 1293.1210\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 6ms/step - loss: 1343.6273 - val_loss: 1268.4584\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1316.8982 - val_loss: 1242.1937\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1288.5726 - val_loss: 1215.0698\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1259.4266 - val_loss: 1185.8995\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1228.3066 - val_loss: 1156.3241\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1196.5374 - val_loss: 1125.4956\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 3ms/step - loss: 1163.3309 - val_loss: 1093.4967\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1129.3527 - val_loss: 1061.0542\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1094.3790 - val_loss: 1027.7384\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1058.6273 - val_loss: 994.1224\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1022.1479 - val_loss: 959.8890\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 3ms/step - loss: 984.9749 - val_loss: 924.9992\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 947.8690 - val_loss: 889.1986\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 909.8636 - val_loss: 854.2086\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 872.3264 - val_loss: 818.8760\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 3ms/step - loss: 834.5786 - val_loss: 784.3919\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 797.6830 - val_loss: 750.1157\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 761.1392 - val_loss: 716.3298\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 725.4284 - val_loss: 683.3314\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 690.1996 - val_loss: 650.9521\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 655.9521 - val_loss: 619.7604\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 622.7790 - val_loss: 589.0333\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 590.6868 - val_loss: 559.8934\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 560.1288 - val_loss: 531.5225\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 3ms/step - loss: 530.7456 - val_loss: 504.6899\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 502.7848 - val_loss: 478.9714\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 476.2877 - val_loss: 454.5204\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 451.0004 - val_loss: 431.8913\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 427.5535 - val_loss: 410.1509\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 405.2915 - val_loss: 390.0017\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 384.7500 - val_loss: 370.6349\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 10ms/step - loss: 365.2322 - val_loss: 353.1991\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 347.3376 - val_loss: 337.2803\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 331.1970 - val_loss: 321.8344\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 315.9676 - val_loss: 307.5953\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 301.7822 - val_loss: 294.8196\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 289.1133 - val_loss: 282.8712\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 277.3219 - val_loss: 272.0248\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 3ms/step - loss: 266.6380 - val_loss: 262.2824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 58ms/step - loss: 1544.4802 - val_loss: 1613.3184\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1528.0537 - val_loss: 1596.0719\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1511.5298 - val_loss: 1578.8898\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1494.8914 - val_loss: 1561.3260\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1478.1212 - val_loss: 1543.1537\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1460.4719 - val_loss: 1524.3235\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1442.0691 - val_loss: 1504.8806\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1423.0394 - val_loss: 1484.1421\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1402.8307 - val_loss: 1462.7075\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1381.7777 - val_loss: 1440.1281\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1359.4945 - val_loss: 1416.3051\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 6ms/step - loss: 1336.0049 - val_loss: 1391.5734\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1311.5442 - val_loss: 1365.7990\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1286.0006 - val_loss: 1338.6782\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 1259.5094 - val_loss: 1310.6943\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1231.8445 - val_loss: 1282.0471\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1203.4794 - val_loss: 1252.2321\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1173.9996 - val_loss: 1221.6069\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 7ms/step - loss: 1143.7203 - val_loss: 1189.8289\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1112.8705 - val_loss: 1157.2786\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1081.2759 - val_loss: 1124.1901\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 6ms/step - loss: 1048.9789 - val_loss: 1090.7460\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1016.2729 - val_loss: 1056.0712\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 982.6328 - val_loss: 1022.0291\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 10ms/step - loss: 949.1945 - val_loss: 986.8836\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 915.0071 - val_loss: 951.6503\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 880.8874 - val_loss: 916.4553\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 846.6962 - val_loss: 881.0617\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 812.7027 - val_loss: 846.0894\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 778.9173 - val_loss: 811.3545\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 745.5793 - val_loss: 777.1451\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 712.6659 - val_loss: 744.3332\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 3ms/step - loss: 681.0599 - val_loss: 711.8892\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 649.8510 - val_loss: 680.8386\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 619.8104 - val_loss: 650.3127\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 590.8627 - val_loss: 620.0940\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 562.5927 - val_loss: 591.5970\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 3ms/step - loss: 535.5180 - val_loss: 564.8771\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 509.9786 - val_loss: 538.4579\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 485.1568 - val_loss: 513.8248\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 461.9348 - val_loss: 489.5443\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 439.4650 - val_loss: 467.1099\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 3ms/step - loss: 418.5748 - val_loss: 445.6543\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 8ms/step - loss: 399.0045 - val_loss: 425.3318\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 380.1755 - val_loss: 406.8659\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 363.1254 - val_loss: 389.2855\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 10ms/step - loss: 347.0342 - val_loss: 372.8116\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 331.8909 - val_loss: 357.8046\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 318.0738 - val_loss: 343.4732\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 305.2076 - val_loss: 330.1117\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 72ms/step - loss: 1600.8990 - val_loss: 1552.0835\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 3ms/step - loss: 1584.2992 - val_loss: 1535.5992\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1567.9583 - val_loss: 1519.1176\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 6ms/step - loss: 1551.4968 - val_loss: 1503.0203\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 1535.2546 - val_loss: 1486.7990\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1518.6643 - val_loss: 1470.7656\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1502.0309 - val_loss: 1454.1439\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1484.6992 - val_loss: 1437.2527\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1466.9335 - val_loss: 1420.1377\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1448.5829 - val_loss: 1402.3285\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1429.6732 - val_loss: 1383.9207\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1409.6915 - val_loss: 1365.1235\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 3ms/step - loss: 1389.1646 - val_loss: 1345.2986\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 1367.5408 - val_loss: 1324.9810\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 1345.2404 - val_loss: 1303.2927\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 3ms/step - loss: 1321.6302 - val_loss: 1280.8304\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1297.0387 - val_loss: 1257.9808\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1271.5623 - val_loss: 1234.3075\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1245.4611 - val_loss: 1209.4797\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 3ms/step - loss: 1218.2476 - val_loss: 1184.0078\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1190.6322 - val_loss: 1157.7616\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 1162.0656 - val_loss: 1130.8728\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 3ms/step - loss: 1132.7654 - val_loss: 1104.0908\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1103.2325 - val_loss: 1076.6073\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1073.1626 - val_loss: 1048.3539\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1042.3354 - val_loss: 1020.0690\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 1011.6995 - val_loss: 990.9081\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 980.0272 - val_loss: 962.1396\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 3ms/step - loss: 948.9433 - val_loss: 933.1764\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 917.7393 - val_loss: 904.1047\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 886.7116 - val_loss: 875.1022\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 855.5934 - val_loss: 846.7294\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 825.2892 - val_loss: 818.0496\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 794.9279 - val_loss: 789.9461\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 764.8457 - val_loss: 762.1988\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 735.5918 - val_loss: 734.2337\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 706.4385 - val_loss: 706.8635\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 678.2198 - val_loss: 680.0712\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 650.2261 - val_loss: 653.8892\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 623.2738 - val_loss: 628.2599\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 596.9528 - val_loss: 603.3204\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 571.3642 - val_loss: 579.3407\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 11ms/step - loss: 547.0689 - val_loss: 555.3973\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 523.1076 - val_loss: 532.9561\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 500.4537 - val_loss: 510.9972\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 478.3060 - val_loss: 490.5138\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 457.8946 - val_loss: 470.4183\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 437.8954 - val_loss: 451.6376\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 419.2116 - val_loss: 434.0723\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 401.7414 - val_loss: 417.0726\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 59ms/step - loss: 1572.4001 - val_loss: 1365.6135\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 21ms/step - loss: 1552.3412 - val_loss: 1347.4006\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1532.2299 - val_loss: 1328.6371\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1511.2384 - val_loss: 1309.1772\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1489.5824 - val_loss: 1289.1252\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1467.0656 - val_loss: 1268.4729\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1443.6274 - val_loss: 1247.0052\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1418.9727 - val_loss: 1225.0333\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1393.7042 - val_loss: 1202.0612\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1367.4207 - val_loss: 1178.2433\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 1340.1449 - val_loss: 1153.5867\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1311.8197 - val_loss: 1128.3459\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1282.6195 - val_loss: 1102.6116\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1252.8881 - val_loss: 1075.8499\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 3ms/step - loss: 1222.3322 - val_loss: 1048.6139\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1191.2200 - val_loss: 1021.4721\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1159.7338 - val_loss: 993.6496\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1127.3431 - val_loss: 965.8813\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1094.7974 - val_loss: 937.8038\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 1062.4926 - val_loss: 908.4048\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1029.1841 - val_loss: 879.9943\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 996.3106 - val_loss: 851.1746\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 962.9561 - val_loss: 822.9237\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 930.1819 - val_loss: 794.3465\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 897.4282 - val_loss: 766.3699\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 865.1723 - val_loss: 738.9002\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 833.4286 - val_loss: 711.5842\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 3ms/step - loss: 801.7263 - val_loss: 685.0523\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 771.2050 - val_loss: 658.1600\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 740.3851 - val_loss: 633.1334\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 711.0057 - val_loss: 608.1700\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 682.0449 - val_loss: 584.0145\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 3ms/step - loss: 653.9289 - val_loss: 560.5288\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 626.9485 - val_loss: 537.0818\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 600.0038 - val_loss: 515.6337\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 574.7956 - val_loss: 494.5007\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 550.4493 - val_loss: 473.5363\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 526.4078 - val_loss: 454.2594\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 503.9690 - val_loss: 435.4393\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 482.1985 - val_loss: 417.1239\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 461.6318 - val_loss: 399.7927\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 441.7673 - val_loss: 383.4388\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 10ms/step - loss: 423.2885 - val_loss: 367.7527\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 14ms/step - loss: 405.0794 - val_loss: 353.2517\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 388.3983 - val_loss: 339.3167\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 372.3915 - val_loss: 326.5101\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 357.6704 - val_loss: 313.8574\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 343.5804 - val_loss: 302.1403\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 330.0800 - val_loss: 291.4950\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 318.0079 - val_loss: 281.0936\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 62ms/step - loss: 1524.7266 - val_loss: 1383.0527\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1507.5038 - val_loss: 1367.4479\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1489.8832 - val_loss: 1351.2776\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1471.2379 - val_loss: 1334.3788\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1451.7294 - val_loss: 1316.0898\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 1430.8019 - val_loss: 1296.5629\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1408.4025 - val_loss: 1275.6976\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 6ms/step - loss: 1384.2920 - val_loss: 1253.7815\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 7ms/step - loss: 1358.8115 - val_loss: 1230.1301\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1331.3784 - val_loss: 1205.3309\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1302.8470 - val_loss: 1179.0721\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 1272.8783 - val_loss: 1151.8396\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1242.2054 - val_loss: 1123.0190\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1209.7468 - val_loss: 1093.9702\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1176.7201 - val_loss: 1063.8163\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1142.9310 - val_loss: 1032.8783\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1108.3151 - val_loss: 1001.8008\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1073.1753 - val_loss: 970.6295\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1037.7848 - val_loss: 938.8217\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1002.2320 - val_loss: 906.4860\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 966.2427 - val_loss: 874.2237\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 930.5213 - val_loss: 842.3225\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 895.2139 - val_loss: 810.1337\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 860.0548 - val_loss: 778.5273\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 825.3672 - val_loss: 747.5714\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 791.4078 - val_loss: 716.9237\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 758.0017 - val_loss: 686.7549\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 725.7032 - val_loss: 657.2676\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 7ms/step - loss: 694.3778 - val_loss: 629.0902\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 664.1757 - val_loss: 601.5032\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 634.6808 - val_loss: 575.3964\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 606.7604 - val_loss: 549.5690\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 579.6816 - val_loss: 524.6924\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 553.8417 - val_loss: 500.7872\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 529.1613 - val_loss: 478.3771\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 505.9218 - val_loss: 456.5661\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 483.4531 - val_loss: 435.9539\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 462.3258 - val_loss: 416.3361\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 442.5100 - val_loss: 397.5285\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 3ms/step - loss: 423.4189 - val_loss: 379.7759\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 12ms/step - loss: 405.5896 - val_loss: 362.7619\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 388.8260 - val_loss: 346.7348\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 373.2104 - val_loss: 331.8304\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 358.7330 - val_loss: 317.4730\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 344.6312 - val_loss: 304.4964\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 331.8551 - val_loss: 292.5770\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 319.9548 - val_loss: 280.9773\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 308.7478 - val_loss: 270.0273\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 298.2115 - val_loss: 259.7137\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 288.2257 - val_loss: 250.5902\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 66ms/step - loss: 1534.4995 - val_loss: 1604.7739\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1514.9232 - val_loss: 1585.8163\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1495.8264 - val_loss: 1567.2170\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1477.0780 - val_loss: 1548.4044\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1458.1467 - val_loss: 1529.6167\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 3ms/step - loss: 1439.0668 - val_loss: 1510.5718\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1419.6229 - val_loss: 1491.1362\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1399.5835 - val_loss: 1471.4240\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1379.0320 - val_loss: 1451.0923\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 1357.8766 - val_loss: 1430.0557\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1336.0558 - val_loss: 1408.5408\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1313.6005 - val_loss: 1386.1976\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1290.2566 - val_loss: 1363.5198\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1266.4421 - val_loss: 1339.6337\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1241.6093 - val_loss: 1315.5283\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1216.5909 - val_loss: 1290.4225\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1190.2773 - val_loss: 1265.6720\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1164.1859 - val_loss: 1239.5885\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1137.2742 - val_loss: 1213.0153\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1110.1969 - val_loss: 1185.8838\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1082.5352 - val_loss: 1159.0072\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1054.6799 - val_loss: 1131.9839\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1026.9846 - val_loss: 1104.2086\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 998.5416 - val_loss: 1076.6945\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 970.3701 - val_loss: 1048.6356\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 942.2027 - val_loss: 1020.7390\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 914.2255 - val_loss: 993.0912\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 886.3738 - val_loss: 965.6216\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 858.7291 - val_loss: 938.6367\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 831.6756 - val_loss: 910.8741\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 804.5060 - val_loss: 883.9273\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 777.8393 - val_loss: 857.2369\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 751.4612 - val_loss: 831.7246\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 726.3287 - val_loss: 805.3592\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 700.8649 - val_loss: 780.1976\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 8ms/step - loss: 676.2545 - val_loss: 755.7995\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 652.8903 - val_loss: 731.5817\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 629.9168 - val_loss: 708.6714\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - loss: 607.8981 - val_loss: 686.4037\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 586.8469 - val_loss: 664.2095\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 7ms/step - loss: 566.0147 - val_loss: 643.7661\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 546.5176 - val_loss: 623.7781\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 527.7372 - val_loss: 604.4586\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 509.9500 - val_loss: 585.4185\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 492.5790 - val_loss: 567.8281\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 10ms/step - loss: 476.2635 - val_loss: 550.8486\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 460.6201 - val_loss: 535.0592\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 446.2677 - val_loss: 519.0060\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 431.9446 - val_loss: 504.6525\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 418.8411 - val_loss: 490.4805\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 59ms/step - loss: 1455.1332 - val_loss: 1559.8127\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1436.4595 - val_loss: 1541.0807\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1417.4374 - val_loss: 1521.9155\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1398.0724 - val_loss: 1502.4430\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 1378.3258 - val_loss: 1482.1333\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1357.8545 - val_loss: 1461.2046\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1336.4132 - val_loss: 1439.3853\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1314.0181 - val_loss: 1416.3510\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1290.3695 - val_loss: 1392.1832\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 1265.5791 - val_loss: 1366.5065\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1239.4500 - val_loss: 1339.8524\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1212.3171 - val_loss: 1311.1569\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 1183.4150 - val_loss: 1282.1726\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1153.8315 - val_loss: 1250.9800\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1122.1990 - val_loss: 1219.4531\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1090.4143 - val_loss: 1185.2700\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1056.8613 - val_loss: 1150.4801\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1022.8217 - val_loss: 1114.9993\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 988.0244 - val_loss: 1079.4299\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 952.7981 - val_loss: 1042.5760\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 916.9636 - val_loss: 1004.9863\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 881.1281 - val_loss: 967.4882\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 844.9316 - val_loss: 929.7811\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 809.1689 - val_loss: 892.7868\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 774.2145 - val_loss: 855.2715\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 738.9435 - val_loss: 818.6150\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 704.6575 - val_loss: 782.9138\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 10ms/step - loss: 671.4871 - val_loss: 747.2445\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 638.6820 - val_loss: 712.9726\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 607.2466 - val_loss: 679.3146\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 576.6319 - val_loss: 647.0197\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 3ms/step - loss: 547.3940 - val_loss: 615.4113\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 519.2018 - val_loss: 585.7638\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 492.2031 - val_loss: 556.8786\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 466.8735 - val_loss: 528.3174\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 8ms/step - loss: 442.3417 - val_loss: 502.0488\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 419.3557 - val_loss: 477.1729\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 398.0982 - val_loss: 453.6360\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 377.9031 - val_loss: 431.6267\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 359.4635 - val_loss: 410.1074\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 3ms/step - loss: 341.5066 - val_loss: 391.1859\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 325.5132 - val_loss: 372.8215\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 310.6550 - val_loss: 355.6605\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 296.8701 - val_loss: 339.7566\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 3ms/step - loss: 283.9574 - val_loss: 325.9019\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 272.5191 - val_loss: 312.3259\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 261.9317 - val_loss: 299.2180\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 251.9874 - val_loss: 288.2867\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 243.2886 - val_loss: 277.7210\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 235.0759 - val_loss: 268.2414\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 67ms/step - loss: 1622.6793 - val_loss: 1553.4500\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 19ms/step - loss: 1608.2512 - val_loss: 1539.8356\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1594.6658 - val_loss: 1527.2281\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1582.0088 - val_loss: 1515.1722\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1569.8019 - val_loss: 1503.4515\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1557.8037 - val_loss: 1491.6167\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1545.5558 - val_loss: 1479.8242\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 6ms/step - loss: 1533.2196 - val_loss: 1467.4563\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 1520.2456 - val_loss: 1454.7014\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - loss: 1506.6771 - val_loss: 1441.2626\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1492.2472 - val_loss: 1427.1678\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1477.1562 - val_loss: 1411.5905\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 3ms/step - loss: 1460.5806 - val_loss: 1395.4354\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 1443.0748 - val_loss: 1378.0295\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1424.4927 - val_loss: 1359.1271\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 1404.0333 - val_loss: 1339.3300\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 3ms/step - loss: 1382.7651 - val_loss: 1318.1785\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1359.8452 - val_loss: 1295.6309\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1335.4867 - val_loss: 1271.7543\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1309.3990 - val_loss: 1246.6658\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 1282.2383 - val_loss: 1220.3284\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1253.8724 - val_loss: 1192.9479\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1224.8179 - val_loss: 1164.4689\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 3ms/step - loss: 1194.5715 - val_loss: 1136.3884\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1164.6570 - val_loss: 1106.7546\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 3ms/step - loss: 1133.2693 - val_loss: 1076.9495\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1101.4911 - val_loss: 1047.4255\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 1069.9036 - val_loss: 1017.0867\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1038.2333 - val_loss: 986.4994\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 1006.3049 - val_loss: 956.0750\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 973.7145 - val_loss: 926.7324\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 942.3438 - val_loss: 896.1406\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 910.3463 - val_loss: 866.4177\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 879.3187 - val_loss: 836.8005\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 848.3461 - val_loss: 807.8748\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 818.1375 - val_loss: 778.7537\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 787.6541 - val_loss: 750.8007\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 758.3339 - val_loss: 723.0682\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 6ms/step - loss: 729.4700 - val_loss: 696.0146\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 701.2701 - val_loss: 669.2968\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 673.3893 - val_loss: 643.5663\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 9ms/step - loss: 646.6357 - val_loss: 618.1536\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 620.1281 - val_loss: 593.6165\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 10ms/step - loss: 594.5363 - val_loss: 569.4258\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 569.5515 - val_loss: 546.2684\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 545.3718 - val_loss: 523.5706\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 522.1087 - val_loss: 501.4308\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 499.2868 - val_loss: 480.6895\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 3ms/step - loss: 477.5781 - val_loss: 460.2426\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 456.5055 - val_loss: 440.5556\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 65ms/step - loss: 1550.7917 - val_loss: 1517.9807\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1534.3046 - val_loss: 1502.1299\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1517.6725 - val_loss: 1486.4733\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1501.0978 - val_loss: 1470.2510\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1483.7479 - val_loss: 1454.2698\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 8ms/step - loss: 1466.3057 - val_loss: 1437.2349\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1447.8575 - val_loss: 1419.6418\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1428.9371 - val_loss: 1401.5994\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1409.2563 - val_loss: 1383.0695\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1388.8557 - val_loss: 1363.7014\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1368.0460 - val_loss: 1343.4259\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1345.9569 - val_loss: 1322.8630\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1323.3159 - val_loss: 1301.4297\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1300.3928 - val_loss: 1278.8428\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1276.4636 - val_loss: 1256.1179\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 3ms/step - loss: 1251.8149 - val_loss: 1232.8853\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 8ms/step - loss: 1226.9500 - val_loss: 1208.6207\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 8ms/step - loss: 1201.0280 - val_loss: 1183.8829\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 1174.8286 - val_loss: 1158.9567\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1148.5094 - val_loss: 1133.4819\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1121.8058 - val_loss: 1107.6967\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 1094.5015 - val_loss: 1082.2069\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1067.3788 - val_loss: 1056.0502\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 1039.9214 - val_loss: 1029.8293\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1012.3903 - val_loss: 1003.6592\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 984.7225 - val_loss: 977.3265\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 956.9418 - val_loss: 951.5787\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 929.7335 - val_loss: 925.0821\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 902.3857 - val_loss: 898.7538\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 875.3886 - val_loss: 872.6972\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 848.5662 - val_loss: 847.3233\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 822.3679 - val_loss: 821.9088\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 796.2065 - val_loss: 797.4816\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 770.6854 - val_loss: 773.1055\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 745.8774 - val_loss: 748.6144\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 721.2924 - val_loss: 724.7367\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 697.2745 - val_loss: 701.5010\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 673.7333 - val_loss: 679.2468\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 651.2200 - val_loss: 657.3942\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 629.2955 - val_loss: 636.1526\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 608.0128 - val_loss: 615.0331\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 587.3420 - val_loss: 594.7251\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 567.5016 - val_loss: 574.8585\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 11ms/step - loss: 547.9625 - val_loss: 556.3530\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 529.6711 - val_loss: 537.4070\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 511.4177 - val_loss: 519.6572\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 494.2390 - val_loss: 502.1383\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 477.6152 - val_loss: 485.6199\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 461.6702 - val_loss: 469.7686\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 446.6028 - val_loss: 454.3178\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 62ms/step - loss: 1540.6864 - val_loss: 1503.4882\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 16ms/step - loss: 1527.8337 - val_loss: 1491.2792\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1514.7008 - val_loss: 1478.5994\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1500.7793 - val_loss: 1465.4525\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1486.2559 - val_loss: 1451.3140\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1470.6467 - val_loss: 1436.2109\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1453.8302 - val_loss: 1419.9387\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1435.8190 - val_loss: 1402.3369\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 1416.3511 - val_loss: 1383.3090\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1395.2522 - val_loss: 1362.7416\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1372.5527 - val_loss: 1340.7709\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1348.3019 - val_loss: 1317.2426\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 9ms/step - loss: 1322.1963 - val_loss: 1291.8884\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1294.6115 - val_loss: 1264.4543\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1264.9656 - val_loss: 1236.0898\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1234.2614 - val_loss: 1205.9867\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 9ms/step - loss: 1201.9656 - val_loss: 1174.7783\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1168.6719 - val_loss: 1142.3374\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1134.2402 - val_loss: 1109.2466\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1099.2312 - val_loss: 1074.6527\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1062.9109 - val_loss: 1040.3016\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1026.3453 - val_loss: 1005.0386\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 989.3577 - val_loss: 969.0069\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 951.6452 - val_loss: 933.1051\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 913.8843 - val_loss: 897.1682\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 876.1428 - val_loss: 860.9129\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 838.5482 - val_loss: 825.3887\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 801.5732 - val_loss: 789.2833\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 764.6335 - val_loss: 754.1781\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 729.0353 - val_loss: 719.4459\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 693.6163 - val_loss: 686.5044\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 660.1381 - val_loss: 653.2969\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 626.8973 - val_loss: 622.0495\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 595.1315 - val_loss: 591.4863\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 3ms/step - loss: 564.8077 - val_loss: 561.6498\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 535.3900 - val_loss: 533.4793\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 507.3718 - val_loss: 506.3862\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 480.5001 - val_loss: 480.3950\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 455.1641 - val_loss: 456.0121\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 3ms/step - loss: 431.4690 - val_loss: 432.4460\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 408.9261 - val_loss: 410.3426\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 387.9959 - val_loss: 389.7119\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 368.2881 - val_loss: 370.6067\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 13ms/step - loss: 350.0625 - val_loss: 352.6548\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 7ms/step - loss: 333.1230 - val_loss: 335.5091\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 317.3088 - val_loss: 319.8497\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 302.7260 - val_loss: 305.6819\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 3ms/step - loss: 289.6099 - val_loss: 292.2448\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 277.5988 - val_loss: 279.6863\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 266.2920 - val_loss: 268.9069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 149ms/step - loss: 1539.8040 - val_loss: 1518.1985\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1523.1024 - val_loss: 1500.3790\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1506.0610 - val_loss: 1482.0211\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1488.3379 - val_loss: 1463.3313\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1470.3877 - val_loss: 1443.2952\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1451.2374 - val_loss: 1423.0527\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1431.5995 - val_loss: 1401.6122\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1410.9784 - val_loss: 1379.6344\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1389.7753 - val_loss: 1355.7531\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1367.1622 - val_loss: 1331.1958\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1344.0620 - val_loss: 1305.0978\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 1319.4003 - val_loss: 1279.1913\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1294.3219 - val_loss: 1251.6908\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1268.1042 - val_loss: 1223.0522\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1241.0293 - val_loss: 1192.8911\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1212.3118 - val_loss: 1162.8633\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1183.3369 - val_loss: 1131.2787\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1153.1461 - val_loss: 1098.4995\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1122.2217 - val_loss: 1065.3057\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1091.0106 - val_loss: 1031.4973\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 10ms/step - loss: 1058.7089 - val_loss: 998.1677\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1026.9370 - val_loss: 963.6598\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 994.2178 - val_loss: 929.9580\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 962.1108 - val_loss: 895.4701\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 929.5413 - val_loss: 862.0190\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 3ms/step - loss: 897.4303 - val_loss: 829.1414\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 865.5643 - val_loss: 796.4251\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 834.3383 - val_loss: 764.1328\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 803.4352 - val_loss: 732.8459\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 3ms/step - loss: 773.4968 - val_loss: 701.7325\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 743.7180 - val_loss: 672.7189\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 714.8636 - val_loss: 644.8691\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 687.3054 - val_loss: 616.9176\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 659.9299 - val_loss: 590.6437\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 634.1520 - val_loss: 564.1364\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 608.2599 - val_loss: 540.5826\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 3ms/step - loss: 584.1705 - val_loss: 517.0958\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 560.5523 - val_loss: 494.8933\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 538.6294 - val_loss: 473.0817\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 516.7475 - val_loss: 453.7715\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 497.0245 - val_loss: 434.5390\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 477.3415 - val_loss: 417.3950\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 459.3174 - val_loss: 400.7645\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 441.9798 - val_loss: 385.2070\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 425.4081 - val_loss: 370.7746\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 409.9272 - val_loss: 356.9516\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 395.0550 - val_loss: 344.6352\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 381.3144 - val_loss: 332.6563\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 368.1111 - val_loss: 321.6721\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 356.0267 - val_loss: 311.3293\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 76ms/step - loss: 1470.5372 - val_loss: 1585.7460\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1455.8417 - val_loss: 1569.3512\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1440.6189 - val_loss: 1551.8440\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1424.3354 - val_loss: 1533.5840\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1407.3372 - val_loss: 1513.8318\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1389.0505 - val_loss: 1492.9607\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1369.6897 - val_loss: 1470.5648\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1349.0200 - val_loss: 1446.8202\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1327.3297 - val_loss: 1421.1497\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1303.8820 - val_loss: 1394.3555\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1278.9495 - val_loss: 1365.9658\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1252.3706 - val_loss: 1335.5310\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1224.3684 - val_loss: 1303.1154\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 3ms/step - loss: 1194.9003 - val_loss: 1269.0471\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1163.2368 - val_loss: 1234.5178\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1131.1730 - val_loss: 1196.9154\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1097.1294 - val_loss: 1159.2810\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1062.6833 - val_loss: 1119.5834\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1026.8114 - val_loss: 1080.3740\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 990.8684 - val_loss: 1039.8662\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 954.3011 - val_loss: 999.4927\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 917.4590 - val_loss: 958.9937\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 3ms/step - loss: 880.9332 - val_loss: 917.7095\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 844.3833 - val_loss: 877.4713\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 808.2061 - val_loss: 838.0820\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 772.7722 - val_loss: 799.3017\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 737.8427 - val_loss: 760.8450\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 3ms/step - loss: 703.8128 - val_loss: 723.2021\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 670.8027 - val_loss: 687.4294\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 638.9017 - val_loss: 652.1588\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 607.8763 - val_loss: 619.4536\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 578.6907 - val_loss: 587.6423\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 550.7097 - val_loss: 557.4833\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 523.9438 - val_loss: 528.5394\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 498.4200 - val_loss: 501.6971\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 474.8682 - val_loss: 475.9367\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 452.1417 - val_loss: 453.0323\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 431.2380 - val_loss: 431.1487\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 411.7568 - val_loss: 410.0245\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 393.1497 - val_loss: 390.8051\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 376.0316 - val_loss: 372.6779\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 10ms/step - loss: 359.8659 - val_loss: 355.8868\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 3ms/step - loss: 344.9950 - val_loss: 340.9753\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 331.3555 - val_loss: 326.5669\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 318.6096 - val_loss: 313.3098\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 306.9526 - val_loss: 301.0226\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 295.9788 - val_loss: 290.0706\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 286.0808 - val_loss: 279.7644\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 276.6812 - val_loss: 270.2610\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 268.3794 - val_loss: 261.2049\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 64ms/step - loss: 1488.8821 - val_loss: 1508.3901\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1473.4880 - val_loss: 1491.9556\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1457.0360 - val_loss: 1474.0718\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1439.3330 - val_loss: 1454.6614\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 1420.2639 - val_loss: 1433.7610\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1399.5131 - val_loss: 1411.6490\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1377.3781 - val_loss: 1387.8864\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1354.0641 - val_loss: 1361.8956\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1328.7333 - val_loss: 1334.7114\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1302.0312 - val_loss: 1306.2058\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1274.0845 - val_loss: 1275.3052\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 3ms/step - loss: 1243.9531 - val_loss: 1244.3173\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 1212.9575 - val_loss: 1211.0951\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1180.1949 - val_loss: 1175.8638\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1146.0839 - val_loss: 1139.2750\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1110.1746 - val_loss: 1101.4113\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1073.1036 - val_loss: 1062.5344\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1035.1714 - val_loss: 1022.1620\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 3ms/step - loss: 996.3583 - val_loss: 980.8471\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 956.2655 - val_loss: 939.7527\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 915.9048 - val_loss: 898.5351\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 875.4546 - val_loss: 857.1780\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 835.5740 - val_loss: 815.5688\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 795.6241 - val_loss: 775.2557\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 756.6160 - val_loss: 735.3159\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 718.3022 - val_loss: 696.8728\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 681.3593 - val_loss: 659.0966\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 645.6337 - val_loss: 622.9669\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 611.2061 - val_loss: 589.2009\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 578.7453 - val_loss: 556.9527\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 547.2454 - val_loss: 526.5743\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 518.4229 - val_loss: 496.6743\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 3ms/step - loss: 490.3833 - val_loss: 469.5972\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 464.5709 - val_loss: 444.1910\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 440.4854 - val_loss: 420.8604\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 418.2744 - val_loss: 398.5537\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 397.5561 - val_loss: 378.4227\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 378.2096 - val_loss: 360.4279\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 361.1503 - val_loss: 343.0666\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 344.8713 - val_loss: 327.8188\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 330.6166 - val_loss: 313.4143\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 317.2840 - val_loss: 300.7884\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 305.2868 - val_loss: 289.3423\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 294.5486 - val_loss: 278.4296\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 284.6760 - val_loss: 268.7625\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 275.5399 - val_loss: 260.0478\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 14ms/step - loss: 267.5118 - val_loss: 252.0122\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 260.2960 - val_loss: 244.8618\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 253.3982 - val_loss: 237.9403\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 247.3016 - val_loss: 231.9906\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 1530.2932 - val_loss: 1534.7043\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1511.9617 - val_loss: 1516.4489\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1493.1237 - val_loss: 1497.3391\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1473.2068 - val_loss: 1477.3402\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 1452.4297 - val_loss: 1456.2482\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1430.5913 - val_loss: 1434.3329\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1407.8296 - val_loss: 1411.5575\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1384.1434 - val_loss: 1387.3781\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1359.2635 - val_loss: 1362.1672\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - loss: 1333.0547 - val_loss: 1336.3866\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1306.2368 - val_loss: 1309.4653\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 1278.2712 - val_loss: 1281.4927\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 1249.2737 - val_loss: 1252.6107\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1219.5880 - val_loss: 1223.1279\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 3ms/step - loss: 1189.1775 - val_loss: 1192.7672\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1157.7184 - val_loss: 1161.7660\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1125.8022 - val_loss: 1130.0721\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 1093.6719 - val_loss: 1097.6925\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1060.7728 - val_loss: 1065.6803\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1027.8462 - val_loss: 1033.4059\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 995.0103 - val_loss: 1000.5872\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - loss: 961.6140 - val_loss: 968.4128\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 929.0027 - val_loss: 935.4885\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 895.8573 - val_loss: 903.5877\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 3ms/step - loss: 863.8981 - val_loss: 871.8581\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 832.1880 - val_loss: 840.4579\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 3ms/step - loss: 800.8352 - val_loss: 810.5031\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 770.4069 - val_loss: 781.0422\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 740.7894 - val_loss: 751.2836\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 711.7393 - val_loss: 722.9268\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 683.6596 - val_loss: 695.4410\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 656.4872 - val_loss: 669.0808\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 630.6948 - val_loss: 643.2746\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 605.4561 - val_loss: 619.3321\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 581.5059 - val_loss: 595.4952\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 558.3842 - val_loss: 572.4194\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 536.2661 - val_loss: 550.5954\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 515.3593 - val_loss: 529.5950\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 495.4788 - val_loss: 509.7659\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 476.5152 - val_loss: 491.1927\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 458.7627 - val_loss: 473.0155\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 441.4675 - val_loss: 456.4044\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 3ms/step - loss: 425.7643 - val_loss: 439.4544\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 10ms/step - loss: 409.7945 - val_loss: 424.6288\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 395.7951 - val_loss: 409.6458\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 381.9760 - val_loss: 396.1690\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 369.3656 - val_loss: 383.0063\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 357.3380 - val_loss: 371.0664\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 346.0879 - val_loss: 359.7054\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 335.5722 - val_loss: 349.2161\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 63ms/step - loss: 1541.0034 - val_loss: 1529.1041\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1525.0309 - val_loss: 1513.8831\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1508.9723 - val_loss: 1498.3525\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1492.3044 - val_loss: 1482.5363\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1474.9694 - val_loss: 1465.8660\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1456.7429 - val_loss: 1448.1145\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1437.3314 - val_loss: 1429.6654\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1416.9189 - val_loss: 1409.6143\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1395.0575 - val_loss: 1388.6654\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1371.9406 - val_loss: 1366.2366\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1347.2307 - val_loss: 1343.0063\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1321.6062 - val_loss: 1317.6218\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 1293.9503 - val_loss: 1291.9712\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1265.3739 - val_loss: 1264.4036\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1235.4907 - val_loss: 1235.0504\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1204.0879 - val_loss: 1204.3555\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1171.3499 - val_loss: 1172.6890\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 3ms/step - loss: 1137.7631 - val_loss: 1140.5718\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1103.3333 - val_loss: 1107.2109\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1068.5667 - val_loss: 1072.5570\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 1032.9031 - val_loss: 1038.1249\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 10ms/step - loss: 997.2139 - val_loss: 1002.6809\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 961.2547 - val_loss: 967.3823\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 925.2269 - val_loss: 931.9343\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 890.2001 - val_loss: 896.0157\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 854.8381 - val_loss: 861.3239\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 820.5788 - val_loss: 827.3679\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 786.9546 - val_loss: 793.8271\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 753.9328 - val_loss: 761.3554\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 721.9246 - val_loss: 729.3992\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 691.3611 - val_loss: 697.4394\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 661.0325 - val_loss: 667.1769\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 632.2015 - val_loss: 637.8807\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 3ms/step - loss: 604.0920 - val_loss: 609.8525\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 577.7237 - val_loss: 582.1611\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 551.7570 - val_loss: 556.6281\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 3ms/step - loss: 527.5096 - val_loss: 531.2280\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 503.9619 - val_loss: 507.8620\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 481.9435 - val_loss: 484.7981\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 460.8288 - val_loss: 463.0117\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 440.5902 - val_loss: 442.4683\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 421.3124 - val_loss: 423.2115\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 3ms/step - loss: 403.2879 - val_loss: 404.2377\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 385.9514 - val_loss: 386.3280\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 369.4620 - val_loss: 369.9837\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 354.1783 - val_loss: 354.0539\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 3ms/step - loss: 339.3747 - val_loss: 339.7408\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 325.7179 - val_loss: 325.8899\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 312.7885 - val_loss: 313.0167\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 300.6241 - val_loss: 301.1842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 66ms/step - loss: 1502.2397 - val_loss: 1695.7451\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1486.4135 - val_loss: 1678.9617\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1471.3596 - val_loss: 1662.7327\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 7ms/step - loss: 1456.8467 - val_loss: 1646.6945\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 6ms/step - loss: 1442.4008 - val_loss: 1631.2780\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1428.3440 - val_loss: 1615.1691\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1413.6635 - val_loss: 1598.8693\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1398.6888 - val_loss: 1582.0570\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 1383.0393 - val_loss: 1564.0659\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 1366.7950 - val_loss: 1544.5813\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1349.1783 - val_loss: 1524.5951\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1330.5533 - val_loss: 1503.6605\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1311.0541 - val_loss: 1480.4301\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 1290.2302 - val_loss: 1457.0728\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1268.6605 - val_loss: 1432.3234\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1246.0719 - val_loss: 1405.9191\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1222.2578 - val_loss: 1378.4821\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1197.3677 - val_loss: 1350.4077\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1171.8145 - val_loss: 1321.0651\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1145.3871 - val_loss: 1290.7844\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1117.9943 - val_loss: 1260.3574\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 1089.9619 - val_loss: 1228.3169\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 1061.2190 - val_loss: 1195.4285\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1031.6096 - val_loss: 1162.1671\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1001.1856 - val_loss: 1128.4747\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 970.1007 - val_loss: 1094.0952\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 938.9096 - val_loss: 1058.3389\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 907.1213 - val_loss: 1023.2923\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 875.5994 - val_loss: 987.8535\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 843.2471 - val_loss: 953.7583\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 811.9579 - val_loss: 918.5012\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 780.3307 - val_loss: 883.4857\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 7ms/step - loss: 748.9326 - val_loss: 849.2607\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 718.1294 - val_loss: 815.5859\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 688.0210 - val_loss: 782.9982\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 658.6656 - val_loss: 751.0882\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 630.0707 - val_loss: 720.1462\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 602.5175 - val_loss: 690.3019\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 575.7772 - val_loss: 661.1660\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 550.0220 - val_loss: 632.9861\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 525.1840 - val_loss: 606.5542\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 501.8025 - val_loss: 581.1133\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 10ms/step - loss: 479.3503 - val_loss: 556.5630\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 457.7014 - val_loss: 533.6642\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 437.5521 - val_loss: 511.6243\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 418.0880 - val_loss: 490.9918\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 399.9979 - val_loss: 471.1659\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 382.8650 - val_loss: 452.1661\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 366.4770 - val_loss: 434.6769\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 351.2609 - val_loss: 418.5791\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 74ms/step - loss: 1533.7710 - val_loss: 1602.5767\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1520.5012 - val_loss: 1588.6975\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1507.4794 - val_loss: 1575.0385\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1494.3015 - val_loss: 1561.4708\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1481.0272 - val_loss: 1547.3658\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1467.5903 - val_loss: 1532.5209\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1453.3037 - val_loss: 1517.2388\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1438.3458 - val_loss: 1500.9215\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1422.2794 - val_loss: 1483.8907\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1405.5483 - val_loss: 1465.9149\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1388.1189 - val_loss: 1446.7164\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1369.5320 - val_loss: 1426.9526\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1349.9600 - val_loss: 1405.8667\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1329.0181 - val_loss: 1383.2815\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 1306.8159 - val_loss: 1359.6136\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1283.2677 - val_loss: 1334.9087\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1258.5288 - val_loss: 1309.3744\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1232.9810 - val_loss: 1282.2593\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1206.0430 - val_loss: 1254.1813\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1178.1730 - val_loss: 1224.3954\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1149.0038 - val_loss: 1194.4935\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 1119.2611 - val_loss: 1163.4340\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1088.6826 - val_loss: 1131.7185\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1057.4014 - val_loss: 1099.4340\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1025.7738 - val_loss: 1066.3243\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 993.1683 - val_loss: 1031.9803\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 3ms/step - loss: 959.6956 - val_loss: 997.0883\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 925.7917 - val_loss: 961.1255\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 891.0314 - val_loss: 924.2083\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 855.6060 - val_loss: 886.7546\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 819.7932 - val_loss: 849.0827\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 784.2379 - val_loss: 811.0781\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 748.7287 - val_loss: 773.6960\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 713.7614 - val_loss: 736.8167\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 679.6815 - val_loss: 700.4530\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 646.3646 - val_loss: 665.9101\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 614.4474 - val_loss: 632.2404\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 583.6299 - val_loss: 599.7486\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 7ms/step - loss: 554.0219 - val_loss: 568.4478\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 526.0802 - val_loss: 538.9751\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 499.6354 - val_loss: 510.2395\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 12ms/step - loss: 474.3806 - val_loss: 483.3861\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 450.6216 - val_loss: 457.8701\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 428.4185 - val_loss: 433.7812\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 407.3341 - val_loss: 411.3571\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 387.9440 - val_loss: 390.2529\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 369.8576 - val_loss: 371.2559\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 353.5648 - val_loss: 353.1617\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 338.1496 - val_loss: 336.2884\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 323.9785 - val_loss: 320.4725\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 67ms/step - loss: 1563.6868 - val_loss: 1670.0142\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1543.8680 - val_loss: 1650.3062\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1525.4182 - val_loss: 1631.6273\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1507.8209 - val_loss: 1613.7754\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 3ms/step - loss: 1491.0277 - val_loss: 1596.0706\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1474.9083 - val_loss: 1578.7072\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1459.0602 - val_loss: 1561.5812\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1443.1581 - val_loss: 1544.7815\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1427.2351 - val_loss: 1527.3966\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1411.1794 - val_loss: 1509.3984\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 3ms/step - loss: 1394.5994 - val_loss: 1490.6815\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1377.2061 - val_loss: 1471.5552\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1359.3718 - val_loss: 1451.6913\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1340.9247 - val_loss: 1431.0878\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 1321.8210 - val_loss: 1409.7180\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1301.9783 - val_loss: 1387.5361\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1281.5154 - val_loss: 1364.2183\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1259.9556 - val_loss: 1341.1195\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1238.2405 - val_loss: 1316.4753\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 3ms/step - loss: 1215.6259 - val_loss: 1290.7328\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1192.0916 - val_loss: 1265.2131\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1168.4065 - val_loss: 1239.4099\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 1144.5114 - val_loss: 1212.3578\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 1119.8645 - val_loss: 1185.6533\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 7ms/step - loss: 1094.9236 - val_loss: 1158.5066\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 1069.9915 - val_loss: 1130.0146\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1044.1627 - val_loss: 1102.7579\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 1018.7161 - val_loss: 1074.2202\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 992.9428 - val_loss: 1045.9176\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 966.8456 - val_loss: 1018.3973\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 941.2535 - val_loss: 989.8893\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 915.0256 - val_loss: 962.3243\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 889.9175 - val_loss: 933.5411\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 863.7167 - val_loss: 906.9946\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 838.7084 - val_loss: 879.5231\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 813.8628 - val_loss: 852.4000\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 11ms/step - loss: 789.1438 - val_loss: 825.9698\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 764.7523 - val_loss: 800.1135\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 740.7430 - val_loss: 775.0670\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 717.5162 - val_loss: 749.6532\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 694.2751 - val_loss: 725.7199\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 672.0168 - val_loss: 701.8395\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 649.8784 - val_loss: 679.3247\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 628.6472 - val_loss: 657.0228\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 607.9053 - val_loss: 635.1248\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 587.8535 - val_loss: 613.8694\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 567.9996 - val_loss: 593.6000\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 549.2354 - val_loss: 573.8568\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 531.1640 - val_loss: 554.7852\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 513.4590 - val_loss: 537.2043\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Mean MSE with Normalized Data: 364.7412743225821\n",
      "Standard Deviation of MSE with Normalized Data: 91.92585864320618\n"
     ]
    }
   ],
   "source": [
    "# Normalize the features\n",
    "mean = features.mean()\n",
    "std = features.std()\n",
    "features_normalized = (features - mean) / std\n",
    "\n",
    "# Store mean squared errors for 50 repetitions\n",
    "mse_list_normalized = []\n",
    "\n",
    "for _ in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized, target, test_size=0.3, random_state=None)\n",
    "\n",
    "    # Build and train the model\n",
    "    model = regression_model(n_cols)\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=2)\n",
    "    \n",
    "    # Predict and calculate mean squared error\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list_normalized.append(mse)\n",
    "\n",
    "# Compute mean and standard deviation of the mean squared errors\n",
    "mean_mse_normalized = np.mean(mse_list_normalized)\n",
    "std_mse_normalized = np.std(mse_list_normalized)\n",
    "\n",
    "print(f'Mean MSE with Normalized Data: {mean_mse_normalized}')\n",
    "print(f'Standard Deviation of MSE with Normalized Data: {std_mse_normalized}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step C: Increase the number of epochs\n",
    "\n",
    "Repeat Step B but train the model for 100 epochs instead of 50.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 79ms/step - loss: 1628.4221 - val_loss: 1556.4159\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1613.3646 - val_loss: 1541.5914\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 1598.9801 - val_loss: 1527.1625\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1584.9248 - val_loss: 1512.9083\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 3ms/step - loss: 1570.9098 - val_loss: 1498.7139\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1556.8815 - val_loss: 1484.3245\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 1542.5908 - val_loss: 1469.8052\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1528.1243 - val_loss: 1454.9785\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1513.2450 - val_loss: 1439.6439\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1497.9244 - val_loss: 1423.6357\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 1482.0049 - val_loss: 1407.0221\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1465.3826 - val_loss: 1389.9020\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1448.0038 - val_loss: 1372.0846\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1429.7058 - val_loss: 1353.3197\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1410.5996 - val_loss: 1333.0374\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 1390.3722 - val_loss: 1311.9392\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1368.9296 - val_loss: 1290.3608\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1346.7330 - val_loss: 1267.6938\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1323.7152 - val_loss: 1243.5547\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 3ms/step - loss: 1299.4741 - val_loss: 1218.9741\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 1274.6525 - val_loss: 1192.9863\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 1248.4625 - val_loss: 1167.2227\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 1222.1208 - val_loss: 1139.9001\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1194.9359 - val_loss: 1112.5577\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 3ms/step - loss: 1167.1337 - val_loss: 1085.1577\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 1139.1138 - val_loss: 1057.4409\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 1110.8007 - val_loss: 1028.4854\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 1081.3213 - val_loss: 1000.0842\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 1052.3076 - val_loss: 971.2314\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 3ms/step - loss: 1022.7797 - val_loss: 942.2101\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 992.6373 - val_loss: 913.6823\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 3ms/step - loss: 962.9876 - val_loss: 883.6673\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 932.5222 - val_loss: 854.6871\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 902.3531 - val_loss: 826.1342\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 6ms/step - loss: 872.4545 - val_loss: 797.9496\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 843.1397 - val_loss: 769.1429\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 813.2347 - val_loss: 741.6879\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 784.6460 - val_loss: 713.6786\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 3ms/step - loss: 755.5013 - val_loss: 687.2281\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 727.6398 - val_loss: 661.0262\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 3ms/step - loss: 700.0282 - val_loss: 636.0002\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 673.4537 - val_loss: 611.1761\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 646.9756 - val_loss: 588.3029\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 3ms/step - loss: 622.0219 - val_loss: 565.2778\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 597.5421 - val_loss: 543.2628\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 573.7534 - val_loss: 521.9022\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 10ms/step - loss: 550.7734 - val_loss: 502.0119\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 529.2626 - val_loss: 482.5204\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 508.1759 - val_loss: 463.9972\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 6ms/step - loss: 487.9307 - val_loss: 446.7232\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 6ms/step - loss: 468.9352 - val_loss: 430.1167\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 6ms/step - loss: 450.7672 - val_loss: 414.3612\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 433.3034 - val_loss: 399.6730\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 8ms/step - loss: 416.9507 - val_loss: 385.6768\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 401.3259 - val_loss: 372.7122\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 6ms/step - loss: 386.7877 - val_loss: 359.9846\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 7ms/step - loss: 372.9958 - val_loss: 348.2949\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 359.6337 - val_loss: 337.5603\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 347.3578 - val_loss: 327.6884\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 6ms/step - loss: 336.0234 - val_loss: 318.0652\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 325.1648 - val_loss: 309.2209\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 10ms/step - loss: 315.0380 - val_loss: 301.1870\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 305.8051 - val_loss: 293.6300\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 297.2509 - val_loss: 286.2144\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 288.7708 - val_loss: 279.8810\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 281.2890 - val_loss: 273.6113\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 274.0177 - val_loss: 268.0007\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 267.4588 - val_loss: 262.5523\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 261.2753 - val_loss: 257.6706\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 255.7119 - val_loss: 253.0345\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 3ms/step - loss: 250.2111 - val_loss: 249.0256\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 245.3514 - val_loss: 244.9099\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 240.7114 - val_loss: 241.2966\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 236.4612 - val_loss: 238.0792\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 3ms/step - loss: 232.4899 - val_loss: 234.7608\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 8ms/step - loss: 228.6918 - val_loss: 231.8954\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 225.1965 - val_loss: 228.9464\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 221.8230 - val_loss: 226.3035\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 218.8191 - val_loss: 223.8186\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 215.9426 - val_loss: 221.4870\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 213.3008 - val_loss: 219.1398\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 210.6311 - val_loss: 216.9666\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 208.3323 - val_loss: 214.8496\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.9238 - val_loss: 212.9610\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 203.8156 - val_loss: 211.0257\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 10ms/step - loss: 201.6716 - val_loss: 209.2245\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 3ms/step - loss: 199.7014 - val_loss: 207.2525\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.7865 - val_loss: 205.6519\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 195.9930 - val_loss: 204.0313\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.2791 - val_loss: 202.5930\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.7102 - val_loss: 201.0669\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.1343 - val_loss: 199.5650\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 189.5751 - val_loss: 198.1237\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 188.1410 - val_loss: 196.8153\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.8076 - val_loss: 195.4568\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.4314 - val_loss: 194.2754\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.2267 - val_loss: 192.9028\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.9269 - val_loss: 191.7271\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 181.7212 - val_loss: 190.5070\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.4828 - val_loss: 189.2621\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 60ms/step - loss: 1633.6366 - val_loss: 1435.3646\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1614.5302 - val_loss: 1419.8077\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 1595.4188 - val_loss: 1404.7456\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1576.8755 - val_loss: 1389.6360\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1558.5248 - val_loss: 1374.4901\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1539.7804 - val_loss: 1359.6436\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1521.3054 - val_loss: 1344.6324\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1502.4530 - val_loss: 1329.1979\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1483.4852 - val_loss: 1313.2126\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1463.6488 - val_loss: 1297.2534\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1443.8942 - val_loss: 1280.3556\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1423.1538 - val_loss: 1262.9481\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1401.3049 - val_loss: 1245.3889\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1379.3907 - val_loss: 1226.5077\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1355.9045 - val_loss: 1207.0729\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 3ms/step - loss: 1331.7026 - val_loss: 1186.7848\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 12ms/step - loss: 1306.5059 - val_loss: 1165.4534\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1280.1285 - val_loss: 1143.7151\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1253.0879 - val_loss: 1120.7428\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1224.4102 - val_loss: 1097.0719\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1195.3459 - val_loss: 1072.3931\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 1164.9167 - val_loss: 1047.4496\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 1134.0897 - val_loss: 1021.6014\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1102.3943 - val_loss: 995.2976\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 7ms/step - loss: 1070.2577 - val_loss: 968.4540\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 1037.7316 - val_loss: 941.0253\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 6ms/step - loss: 1005.0123 - val_loss: 913.1747\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 3ms/step - loss: 971.8567 - val_loss: 885.8580\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 939.2906 - val_loss: 858.0588\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 907.0815 - val_loss: 830.2847\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 874.3812 - val_loss: 803.1988\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 3ms/step - loss: 842.7780 - val_loss: 775.8203\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 811.1213 - val_loss: 749.1550\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 780.5231 - val_loss: 722.5513\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 750.1130 - val_loss: 696.7917\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 720.7879 - val_loss: 670.8593\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 3ms/step - loss: 692.0006 - val_loss: 645.8381\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 664.1965 - val_loss: 621.7568\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 637.2750 - val_loss: 598.5922\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 611.7321 - val_loss: 575.6923\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 3ms/step - loss: 586.6209 - val_loss: 554.5090\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 563.1666 - val_loss: 533.5500\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 540.4584 - val_loss: 513.2453\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 518.6690 - val_loss: 494.0676\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 3ms/step - loss: 498.0821 - val_loss: 475.8917\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 478.6048 - val_loss: 458.5754\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 460.2430 - val_loss: 441.7668\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 3ms/step - loss: 443.0064 - val_loss: 425.9924\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 426.6052 - val_loss: 411.3653\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 411.4481 - val_loss: 397.0278\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 3ms/step - loss: 396.7893 - val_loss: 383.3831\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 382.8064 - val_loss: 371.1375\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 370.1843 - val_loss: 358.8961\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 358.0118 - val_loss: 347.5202\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 346.6109 - val_loss: 336.8707\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 335.8632 - val_loss: 326.8413\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 325.7900 - val_loss: 316.9055\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 316.2071 - val_loss: 308.1021\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 9ms/step - loss: 307.3170 - val_loss: 299.5049\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 9ms/step - loss: 298.9773 - val_loss: 291.0567\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 290.8547 - val_loss: 283.8399\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 3ms/step - loss: 283.1571 - val_loss: 276.7918\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 276.2075 - val_loss: 269.8340\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 269.4547 - val_loss: 263.3347\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 263.2672 - val_loss: 257.3960\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 257.4337 - val_loss: 251.5458\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 251.7671 - val_loss: 246.0500\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 246.5101 - val_loss: 240.8134\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 241.6018 - val_loss: 235.8148\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 236.9960 - val_loss: 231.7144\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 232.7655 - val_loss: 227.4514\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 228.7327 - val_loss: 224.0271\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 225.0102 - val_loss: 220.5679\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 221.5664 - val_loss: 217.0533\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 3ms/step - loss: 218.1844 - val_loss: 213.8858\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.0374 - val_loss: 211.0234\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 212.1560 - val_loss: 208.3607\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 209.3008 - val_loss: 205.9760\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.7866 - val_loss: 203.4482\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 204.3240 - val_loss: 201.5836\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 201.9784 - val_loss: 199.4347\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.8568 - val_loss: 197.6065\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.8226 - val_loss: 195.7529\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 195.8605 - val_loss: 194.0286\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.0004 - val_loss: 192.4154\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.2323 - val_loss: 190.9654\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.4953 - val_loss: 189.5420\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.8660 - val_loss: 188.3530\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.2872 - val_loss: 187.0519\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.8939 - val_loss: 185.8927\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.4270 - val_loss: 184.2870\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.9771 - val_loss: 183.3318\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 181.6042 - val_loss: 182.2409\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.1809 - val_loss: 181.0364\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.8221 - val_loss: 179.8382\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.6005 - val_loss: 178.7455\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 7ms/step - loss: 176.2498 - val_loss: 177.6940\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.9707 - val_loss: 176.7385\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.8293 - val_loss: 175.6335\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.6297 - val_loss: 174.8472\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 59ms/step - loss: 1508.0892 - val_loss: 1521.5209\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1491.5806 - val_loss: 1505.0327\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1474.6196 - val_loss: 1487.1323\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1456.3213 - val_loss: 1468.2216\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1436.7438 - val_loss: 1447.8522\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1415.6858 - val_loss: 1426.3796\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1393.3009 - val_loss: 1402.5952\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1368.9113 - val_loss: 1377.3542\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1342.8977 - val_loss: 1350.4460\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1315.1382 - val_loss: 1322.0505\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1285.9712 - val_loss: 1292.0002\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 1254.9138 - val_loss: 1261.1648\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1223.3872 - val_loss: 1228.3059\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1189.9257 - val_loss: 1194.9185\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 1155.7900 - val_loss: 1159.9578\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 7ms/step - loss: 1119.7505 - val_loss: 1124.7296\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 3ms/step - loss: 1083.6390 - val_loss: 1087.5813\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1046.3639 - val_loss: 1050.8381\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1008.6743 - val_loss: 1014.3356\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 971.2690 - val_loss: 976.5485\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 933.3766 - val_loss: 938.7965\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 895.4570 - val_loss: 900.6450\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 857.1663 - val_loss: 863.7395\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 819.6086 - val_loss: 826.6972\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 782.2639 - val_loss: 789.6950\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 745.8742 - val_loss: 753.0772\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 709.5826 - val_loss: 718.9780\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 674.8952 - val_loss: 684.7020\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 641.2724 - val_loss: 650.9603\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 6ms/step - loss: 608.4981 - val_loss: 618.7668\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 577.0073 - val_loss: 588.4509\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 11ms/step - loss: 547.0206 - val_loss: 559.5652\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 518.7379 - val_loss: 531.4016\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 491.7614 - val_loss: 504.9055\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 466.0155 - val_loss: 480.3060\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 442.3272 - val_loss: 457.1809\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 420.2589 - val_loss: 435.2285\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 399.3914 - val_loss: 415.0981\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 379.9760 - val_loss: 396.9996\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 362.3928 - val_loss: 379.5427\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 345.8506 - val_loss: 363.5663\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 330.3831 - val_loss: 348.7513\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 316.5134 - val_loss: 335.0099\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 303.8196 - val_loss: 322.3788\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 292.1735 - val_loss: 311.0087\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 281.4980 - val_loss: 300.7530\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 271.8161 - val_loss: 291.3667\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 262.9145 - val_loss: 283.1379\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 255.1778 - val_loss: 275.1151\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 247.6785 - val_loss: 267.8896\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 241.1053 - val_loss: 261.0756\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 234.8062 - val_loss: 255.2497\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 229.3598 - val_loss: 249.6563\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 224.1823 - val_loss: 244.4938\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 219.3734 - val_loss: 240.0197\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 215.1677 - val_loss: 235.4118\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 211.0777 - val_loss: 231.3664\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 10ms/step - loss: 207.2516 - val_loss: 227.6950\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 203.8610 - val_loss: 224.0443\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 9ms/step - loss: 200.5577 - val_loss: 220.8091\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.4930 - val_loss: 217.6936\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.7766 - val_loss: 214.7517\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.0492 - val_loss: 211.9223\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 189.6000 - val_loss: 209.2883\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.2849 - val_loss: 206.8156\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.0100 - val_loss: 204.4726\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.9694 - val_loss: 202.3174\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 181.0649 - val_loss: 200.2012\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.1254 - val_loss: 198.3758\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.4154 - val_loss: 196.4058\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.5789 - val_loss: 194.5264\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.0325 - val_loss: 192.7531\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 12ms/step - loss: 172.3591 - val_loss: 191.0739\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.8422 - val_loss: 189.5361\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.3962 - val_loss: 187.9059\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.9045 - val_loss: 186.5176\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.4893 - val_loss: 184.9293\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.1204 - val_loss: 183.6638\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 6ms/step - loss: 163.8325 - val_loss: 182.2400\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.4680 - val_loss: 180.7379\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.1657 - val_loss: 179.3673\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.9690 - val_loss: 178.1096\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.8573 - val_loss: 176.8124\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.7190 - val_loss: 175.6191\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.5780 - val_loss: 174.3793\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 6ms/step - loss: 155.5036 - val_loss: 173.1520\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 3ms/step - loss: 154.4677 - val_loss: 171.8467\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.3777 - val_loss: 170.7264\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.3886 - val_loss: 169.7024\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 151.4010 - val_loss: 168.4950\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.4160 - val_loss: 167.3158\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 149.4779 - val_loss: 166.3567\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 148.5477 - val_loss: 165.2819\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.6523 - val_loss: 164.0813\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 146.7158 - val_loss: 163.0957\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 145.8162 - val_loss: 162.0582\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 144.8664 - val_loss: 160.9896\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 7ms/step - loss: 143.9630 - val_loss: 159.9811\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 143.1219 - val_loss: 158.9924\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 142.2547 - val_loss: 158.0778\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 1542.5327 - val_loss: 1598.2501\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1527.8303 - val_loss: 1583.3676\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1513.6045 - val_loss: 1568.8817\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 6ms/step - loss: 1499.6649 - val_loss: 1554.4097\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1485.6259 - val_loss: 1539.8014\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 3ms/step - loss: 1471.4805 - val_loss: 1524.7554\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1456.9183 - val_loss: 1509.0834\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1441.7957 - val_loss: 1492.7198\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1425.7156 - val_loss: 1475.5540\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 1408.8433 - val_loss: 1457.3110\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1391.0303 - val_loss: 1438.0095\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1372.1963 - val_loss: 1417.8660\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1352.6290 - val_loss: 1396.4319\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1331.7751 - val_loss: 1374.6415\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1310.1986 - val_loss: 1351.5173\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1288.0377 - val_loss: 1326.9413\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 6ms/step - loss: 1264.1470 - val_loss: 1302.6078\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1240.1433 - val_loss: 1276.7114\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1215.3135 - val_loss: 1250.0219\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1189.6980 - val_loss: 1222.9917\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1163.6434 - val_loss: 1195.7059\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1137.2357 - val_loss: 1167.7352\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1110.3121 - val_loss: 1139.3405\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1083.4573 - val_loss: 1110.4481\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 6ms/step - loss: 1055.6084 - val_loss: 1082.2576\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 1028.2793 - val_loss: 1053.0602\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 1000.3567 - val_loss: 1024.0420\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 972.6790 - val_loss: 994.8025\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 944.8372 - val_loss: 966.5474\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 917.7737 - val_loss: 937.5974\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 890.0765 - val_loss: 909.7032\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 3ms/step - loss: 863.4203 - val_loss: 880.8104\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 836.2867 - val_loss: 853.3392\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 6ms/step - loss: 809.9851 - val_loss: 825.9963\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 784.3151 - val_loss: 798.2325\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 758.3543 - val_loss: 771.8062\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 733.2507 - val_loss: 746.3990\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 708.9948 - val_loss: 721.0928\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 685.5330 - val_loss: 695.9063\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 662.1237 - val_loss: 672.0947\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 639.6281 - val_loss: 648.7272\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 617.8223 - val_loss: 626.0234\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 6ms/step - loss: 596.8515 - val_loss: 604.0157\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 576.3588 - val_loss: 582.8325\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 556.6276 - val_loss: 562.3683\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 537.8614 - val_loss: 542.6608\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 11ms/step - loss: 519.7218 - val_loss: 523.9504\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 6ms/step - loss: 502.4984 - val_loss: 506.0844\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 486.0838 - val_loss: 488.5740\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 469.9125 - val_loss: 472.5729\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 455.1046 - val_loss: 456.4247\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 440.4618 - val_loss: 441.3320\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 426.5558 - val_loss: 427.1582\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 413.4625 - val_loss: 413.4916\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 400.8213 - val_loss: 400.6548\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 388.7962 - val_loss: 388.6467\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 377.5066 - val_loss: 376.9312\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 366.5918 - val_loss: 365.8447\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 356.1549 - val_loss: 355.6813\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 346.6612 - val_loss: 345.7143\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 337.1855 - val_loss: 336.6910\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 3ms/step - loss: 328.6170 - val_loss: 327.7151\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 320.0525 - val_loss: 319.8851\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 312.1499 - val_loss: 312.0029\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 304.4073 - val_loss: 304.6324\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 3ms/step - loss: 296.7555 - val_loss: 297.3737\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 289.2959 - val_loss: 290.3936\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 282.1109 - val_loss: 283.2942\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 274.8343 - val_loss: 277.1650\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 268.0872 - val_loss: 270.7589\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 261.4476 - val_loss: 264.8025\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 254.9861 - val_loss: 259.4033\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 248.9821 - val_loss: 253.9971\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 243.1549 - val_loss: 248.9667\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 6ms/step - loss: 237.6471 - val_loss: 244.2693\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 3ms/step - loss: 232.3349 - val_loss: 239.8250\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 227.4587 - val_loss: 235.4360\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 6ms/step - loss: 222.8121 - val_loss: 231.5721\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 218.4910 - val_loss: 227.8326\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 3ms/step - loss: 214.4238 - val_loss: 224.6439\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 210.7199 - val_loss: 221.2793\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 6ms/step - loss: 207.0433 - val_loss: 218.4035\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 203.7033 - val_loss: 215.6097\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.3682 - val_loss: 212.9313\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.2926 - val_loss: 210.1962\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.3980 - val_loss: 207.7668\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.6016 - val_loss: 205.3981\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.0004 - val_loss: 203.1835\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 9ms/step - loss: 186.5176 - val_loss: 201.1009\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.0912 - val_loss: 199.0993\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.9077 - val_loss: 196.9897\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.5309 - val_loss: 195.0895\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.3495 - val_loss: 193.2444\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.3425 - val_loss: 191.5939\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.4007 - val_loss: 189.6579\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.4073 - val_loss: 187.8344\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.6351 - val_loss: 186.2388\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 3ms/step - loss: 167.6808 - val_loss: 184.5672\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.9826 - val_loss: 183.0928\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.2177 - val_loss: 181.4208\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 60ms/step - loss: 1653.4900 - val_loss: 1455.1024\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1638.0433 - val_loss: 1440.0848\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1623.3832 - val_loss: 1425.8022\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1609.1217 - val_loss: 1412.1887\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1595.3019 - val_loss: 1398.4729\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1581.4946 - val_loss: 1384.8517\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 1567.6172 - val_loss: 1371.0105\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1553.4005 - val_loss: 1356.8169\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1538.7379 - val_loss: 1342.1221\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1523.3320 - val_loss: 1327.1873\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1507.4225 - val_loss: 1311.2313\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1490.4778 - val_loss: 1294.5156\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1472.4661 - val_loss: 1276.7407\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1453.1060 - val_loss: 1258.1494\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1432.5789 - val_loss: 1238.3207\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 1410.6379 - val_loss: 1217.2002\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 1387.6792 - val_loss: 1194.8177\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1362.7744 - val_loss: 1171.9507\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 11ms/step - loss: 1337.3712 - val_loss: 1147.5609\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1309.9226 - val_loss: 1122.7126\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 1281.9602 - val_loss: 1096.8326\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 3ms/step - loss: 1252.2410 - val_loss: 1069.8431\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1221.9977 - val_loss: 1042.3477\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1190.7917 - val_loss: 1014.2250\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 7ms/step - loss: 1159.1431 - val_loss: 985.5211\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 1126.2655 - val_loss: 956.6704\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 1093.4460 - val_loss: 927.4935\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 1060.6381 - val_loss: 898.0255\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 1027.3458 - val_loss: 869.2493\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 994.1548 - val_loss: 840.2156\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 961.1070 - val_loss: 811.0895\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 927.7087 - val_loss: 782.8980\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 895.3395 - val_loss: 754.4583\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 6ms/step - loss: 862.4753 - val_loss: 726.5818\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 830.6530 - val_loss: 698.9708\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 798.5037 - val_loss: 672.2894\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 3ms/step - loss: 767.4468 - val_loss: 645.6678\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 736.4052 - val_loss: 619.8572\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 706.3937 - val_loss: 593.8660\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 676.2245 - val_loss: 568.8580\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 647.1022 - val_loss: 544.2526\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 8ms/step - loss: 618.2855 - val_loss: 520.8063\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 590.8224 - val_loss: 497.7666\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 563.8100 - val_loss: 476.1997\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 538.2072 - val_loss: 455.6270\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 513.8381 - val_loss: 436.0610\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 490.5905 - val_loss: 417.4734\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 468.5360 - val_loss: 400.2665\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 447.7600 - val_loss: 383.9641\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 428.5615 - val_loss: 368.9327\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 410.2425 - val_loss: 354.7979\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 393.0316 - val_loss: 341.7698\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 377.2362 - val_loss: 329.8654\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 362.3725 - val_loss: 318.4294\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 348.7437 - val_loss: 308.3126\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 335.9213 - val_loss: 298.8920\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 324.0615 - val_loss: 290.3182\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 313.4543 - val_loss: 282.5464\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 303.3255 - val_loss: 275.5486\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 3ms/step - loss: 294.0041 - val_loss: 269.0544\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 11ms/step - loss: 285.7554 - val_loss: 262.5286\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 277.5589 - val_loss: 256.9315\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 270.0255 - val_loss: 251.8755\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 263.2328 - val_loss: 246.9553\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 3ms/step - loss: 256.8651 - val_loss: 242.4360\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 250.8602 - val_loss: 238.5363\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 7ms/step - loss: 245.1805 - val_loss: 234.7645\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 240.0836 - val_loss: 231.1663\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 235.0953 - val_loss: 227.7773\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 230.5004 - val_loss: 224.7532\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 6ms/step - loss: 226.2479 - val_loss: 221.7169\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 222.2099 - val_loss: 219.0207\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 218.5121 - val_loss: 216.7412\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 214.8650 - val_loss: 214.2092\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 7ms/step - loss: 211.3925 - val_loss: 211.9988\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 14ms/step - loss: 208.3835 - val_loss: 209.7988\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 205.5023 - val_loss: 207.3661\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 7ms/step - loss: 202.6962 - val_loss: 205.7288\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.0534 - val_loss: 203.6149\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.6709 - val_loss: 202.3056\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 3ms/step - loss: 195.3025 - val_loss: 200.5603\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 193.1427 - val_loss: 199.3031\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.0900 - val_loss: 197.5538\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.2018 - val_loss: 195.9843\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 3ms/step - loss: 187.2987 - val_loss: 194.6855\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.4402 - val_loss: 193.6850\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.7822 - val_loss: 192.4252\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.1207 - val_loss: 191.2215\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.5686 - val_loss: 190.1790\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.9856 - val_loss: 189.0640\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 6ms/step - loss: 177.4726 - val_loss: 188.0045\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.0191 - val_loss: 187.1125\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.5486 - val_loss: 185.8345\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.2332 - val_loss: 184.5679\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 171.8741 - val_loss: 183.5914\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.5260 - val_loss: 182.5580\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.3072 - val_loss: 181.6959\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.1169 - val_loss: 180.5149\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.9438 - val_loss: 179.8337\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.8289 - val_loss: 178.8820\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 - 2s - 68ms/step - loss: 1547.5907 - val_loss: 1462.0509\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1531.9783 - val_loss: 1446.2113\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 3ms/step - loss: 1515.7797 - val_loss: 1430.1748\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1499.0560 - val_loss: 1413.1760\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1481.6406 - val_loss: 1394.9967\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 3ms/step - loss: 1462.9934 - val_loss: 1376.5427\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1443.5067 - val_loss: 1356.6779\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1422.6375 - val_loss: 1335.4974\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1400.5452 - val_loss: 1313.3999\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 1377.0594 - val_loss: 1289.8912\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 1352.2622 - val_loss: 1265.0381\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1325.9753 - val_loss: 1238.4883\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 9ms/step - loss: 1298.1982 - val_loss: 1210.9867\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1269.1157 - val_loss: 1182.5197\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1238.9489 - val_loss: 1152.6381\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 1207.9630 - val_loss: 1121.2233\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1175.3114 - val_loss: 1089.9691\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1142.1239 - val_loss: 1058.0602\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1108.4556 - val_loss: 1024.7572\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1073.6377 - val_loss: 991.1509\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1038.5530 - val_loss: 957.2754\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1003.0636 - val_loss: 923.6632\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 967.7032 - val_loss: 889.8672\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 932.4136 - val_loss: 855.7753\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 896.9144 - val_loss: 822.2746\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 861.4039 - val_loss: 789.3633\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 3ms/step - loss: 826.8882 - val_loss: 756.4249\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 792.7728 - val_loss: 723.5573\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 758.7239 - val_loss: 692.5558\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 726.2803 - val_loss: 662.1559\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 694.3381 - val_loss: 632.2688\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 663.1502 - val_loss: 604.2640\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 3ms/step - loss: 633.3726 - val_loss: 576.3545\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 604.4173 - val_loss: 549.8239\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 576.7411 - val_loss: 524.3801\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 9ms/step - loss: 549.9984 - val_loss: 500.5266\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 524.7909 - val_loss: 477.7210\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 501.1878 - val_loss: 455.3268\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 477.9968 - val_loss: 435.4972\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 456.7278 - val_loss: 416.1639\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 436.4131 - val_loss: 398.4333\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 417.5715 - val_loss: 381.4658\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 399.7360 - val_loss: 365.9646\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 383.1162 - val_loss: 351.6105\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 367.6777 - val_loss: 337.8661\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 353.3140 - val_loss: 325.1652\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 339.8635 - val_loss: 313.6335\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 327.5013 - val_loss: 303.1107\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 315.9750 - val_loss: 293.4585\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 305.4786 - val_loss: 284.3412\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 10ms/step - loss: 295.5303 - val_loss: 275.7592\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 286.0932 - val_loss: 268.4000\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 277.8396 - val_loss: 261.0453\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 269.7111 - val_loss: 254.7762\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 262.5886 - val_loss: 248.8635\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 255.9210 - val_loss: 243.2971\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 249.5282 - val_loss: 238.3042\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 243.8367 - val_loss: 233.7061\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 238.4003 - val_loss: 229.4041\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 233.5439 - val_loss: 225.3640\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 228.8445 - val_loss: 221.7402\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 224.5151 - val_loss: 218.4257\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 220.5651 - val_loss: 215.2085\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 216.7749 - val_loss: 212.2639\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 213.3491 - val_loss: 209.4058\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 210.0174 - val_loss: 206.7506\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 206.7678 - val_loss: 204.2041\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 3ms/step - loss: 203.7945 - val_loss: 201.8139\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.9369 - val_loss: 199.3864\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 198.0701 - val_loss: 197.2159\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 6ms/step - loss: 195.5351 - val_loss: 195.0896\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 3ms/step - loss: 193.1192 - val_loss: 192.9455\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 190.6852 - val_loss: 191.0259\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.4785 - val_loss: 189.1288\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.2362 - val_loss: 187.2413\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.0999 - val_loss: 185.5381\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.0768 - val_loss: 183.8168\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 12ms/step - loss: 180.1788 - val_loss: 182.1073\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.2980 - val_loss: 180.3989\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.5303 - val_loss: 178.9568\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.7827 - val_loss: 177.2815\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.1169 - val_loss: 175.8456\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 171.4330 - val_loss: 174.3488\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.9087 - val_loss: 173.0339\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 168.2632 - val_loss: 171.5843\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 166.8494 - val_loss: 170.1529\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.4354 - val_loss: 168.9228\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.0835 - val_loss: 167.5935\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.7700 - val_loss: 166.2642\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.4391 - val_loss: 165.0426\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.1754 - val_loss: 163.8089\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.8834 - val_loss: 162.7658\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.7322 - val_loss: 161.6235\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.5139 - val_loss: 160.3920\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.3553 - val_loss: 159.2919\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 154.3077 - val_loss: 158.4003\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.2216 - val_loss: 157.0699\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 9ms/step - loss: 152.0767 - val_loss: 155.9562\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.0802 - val_loss: 154.8155\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.0311 - val_loss: 153.8845\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 66ms/step - loss: 1666.5399 - val_loss: 1602.8529\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1647.9716 - val_loss: 1585.9530\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 6ms/step - loss: 1630.7902 - val_loss: 1570.1515\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 3ms/step - loss: 1614.6556 - val_loss: 1555.5859\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1599.3512 - val_loss: 1541.5914\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1584.9801 - val_loss: 1528.0804\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1571.0863 - val_loss: 1515.1561\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1557.6394 - val_loss: 1502.5558\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1544.4332 - val_loss: 1490.1846\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1531.4847 - val_loss: 1477.9508\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 1518.6948 - val_loss: 1465.7863\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1505.9376 - val_loss: 1453.7039\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1493.1620 - val_loss: 1441.6702\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1480.3738 - val_loss: 1429.5719\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 3ms/step - loss: 1467.6444 - val_loss: 1417.3839\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1454.7305 - val_loss: 1405.3208\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1441.8374 - val_loss: 1393.0703\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1428.7709 - val_loss: 1380.5649\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1415.4912 - val_loss: 1367.7075\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 3ms/step - loss: 1401.9241 - val_loss: 1354.5217\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1388.0033 - val_loss: 1341.1002\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1373.6757 - val_loss: 1327.0441\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1358.7529 - val_loss: 1312.3121\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1343.0502 - val_loss: 1296.7946\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1326.5135 - val_loss: 1280.2380\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 1308.7606 - val_loss: 1262.4159\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 1289.7683 - val_loss: 1243.2798\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 1269.4791 - val_loss: 1222.9694\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 1248.0366 - val_loss: 1201.4930\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 1225.5262 - val_loss: 1179.5356\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 1201.9911 - val_loss: 1156.8882\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 1177.9407 - val_loss: 1133.2869\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 7ms/step - loss: 1153.2102 - val_loss: 1109.1959\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 3ms/step - loss: 1127.8392 - val_loss: 1085.2528\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 1102.6311 - val_loss: 1060.3652\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 1076.7540 - val_loss: 1035.8906\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 1050.5046 - val_loss: 1011.0950\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 1024.4753 - val_loss: 986.0211\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 998.3557 - val_loss: 960.8411\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 972.1595 - val_loss: 935.7796\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 12ms/step - loss: 945.9521 - val_loss: 911.6232\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 920.4375 - val_loss: 886.7044\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 894.5569 - val_loss: 862.6631\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 869.0394 - val_loss: 838.3081\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 843.7652 - val_loss: 814.5295\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 818.4986 - val_loss: 791.2563\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 793.2091 - val_loss: 767.9326\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 768.1470 - val_loss: 744.3337\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 742.5782 - val_loss: 721.0826\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 717.4017 - val_loss: 697.4798\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 691.9211 - val_loss: 674.3167\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 7ms/step - loss: 666.4319 - val_loss: 651.4832\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 641.5441 - val_loss: 628.7312\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 617.3731 - val_loss: 606.5047\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 593.5001 - val_loss: 584.9561\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 3ms/step - loss: 570.1210 - val_loss: 564.7385\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 548.1918 - val_loss: 544.0645\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 526.2363 - val_loss: 525.3680\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 7ms/step - loss: 505.6954 - val_loss: 506.8367\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 7ms/step - loss: 486.0769 - val_loss: 488.8277\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 466.9550 - val_loss: 472.2779\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 449.1584 - val_loss: 456.1218\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 432.1595 - val_loss: 440.8374\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 3ms/step - loss: 415.8166 - val_loss: 426.9246\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 400.7774 - val_loss: 413.0909\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 386.3410 - val_loss: 400.1599\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 372.4459 - val_loss: 388.4204\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 359.9590 - val_loss: 376.7370\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 347.7175 - val_loss: 366.0263\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 336.5020 - val_loss: 355.9824\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 6ms/step - loss: 325.9004 - val_loss: 346.7458\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 316.2478 - val_loss: 337.9275\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 6ms/step - loss: 307.0357 - val_loss: 329.7438\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 298.4849 - val_loss: 322.1474\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 290.5299 - val_loss: 314.9816\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 6ms/step - loss: 283.2650 - val_loss: 308.0482\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 276.1608 - val_loss: 301.7357\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 269.6538 - val_loss: 295.6660\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 263.5265 - val_loss: 289.9709\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 257.8679 - val_loss: 284.8116\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 252.7136 - val_loss: 279.5413\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 247.6630 - val_loss: 275.2873\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 11ms/step - loss: 243.2265 - val_loss: 270.7543\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 238.9348 - val_loss: 266.6251\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 234.7071 - val_loss: 262.7170\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 231.0213 - val_loss: 258.8940\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 227.2580 - val_loss: 255.3207\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 6ms/step - loss: 223.9383 - val_loss: 251.8365\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 220.5293 - val_loss: 248.5964\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 217.4971 - val_loss: 245.4486\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 214.5438 - val_loss: 242.3880\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 211.6554 - val_loss: 239.5316\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 208.8813 - val_loss: 236.8751\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 6ms/step - loss: 206.3046 - val_loss: 234.1344\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 203.7315 - val_loss: 231.6648\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 201.2921 - val_loss: 228.9812\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 198.8996 - val_loss: 226.6035\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 196.6906 - val_loss: 224.2312\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 194.3181 - val_loss: 221.9094\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.1720 - val_loss: 219.5902\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 60ms/step - loss: 1637.1156 - val_loss: 1554.9679\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1617.1790 - val_loss: 1536.1796\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1597.8672 - val_loss: 1517.6478\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1579.1031 - val_loss: 1498.9165\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1559.9941 - val_loss: 1480.6935\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1541.3219 - val_loss: 1461.4823\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 6ms/step - loss: 1522.0973 - val_loss: 1442.2070\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1502.3940 - val_loss: 1422.9467\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1482.1547 - val_loss: 1403.0253\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 1461.4865 - val_loss: 1381.9211\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1439.7566 - val_loss: 1360.5608\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1417.2290 - val_loss: 1338.5839\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1393.8937 - val_loss: 1315.9435\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 7ms/step - loss: 1369.8115 - val_loss: 1291.6494\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 10ms/step - loss: 1344.6158 - val_loss: 1267.0785\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 6ms/step - loss: 1318.7699 - val_loss: 1242.4962\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1292.5007 - val_loss: 1217.0339\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 3ms/step - loss: 1265.8551 - val_loss: 1190.2764\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1238.1559 - val_loss: 1164.1040\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1210.1356 - val_loss: 1137.4941\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 1181.8103 - val_loss: 1110.5260\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1152.9020 - val_loss: 1082.8140\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1123.4717 - val_loss: 1055.6693\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1094.4332 - val_loss: 1027.4128\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1064.4966 - val_loss: 999.8029\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 1034.7365 - val_loss: 971.6161\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 1004.9251 - val_loss: 943.9623\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 6ms/step - loss: 975.6080 - val_loss: 916.1760\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 946.0229 - val_loss: 889.1469\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 917.0748 - val_loss: 862.0057\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 3ms/step - loss: 888.4084 - val_loss: 835.1826\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 860.0406 - val_loss: 808.7891\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 832.0327 - val_loss: 783.3337\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 804.8151 - val_loss: 758.3513\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 778.1633 - val_loss: 733.5200\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 3ms/step - loss: 752.0901 - val_loss: 709.4819\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 726.2689 - val_loss: 686.1771\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 701.7565 - val_loss: 662.3402\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 677.0285 - val_loss: 639.8434\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 3ms/step - loss: 653.0826 - val_loss: 618.0291\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 629.9573 - val_loss: 596.9962\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 607.6313 - val_loss: 576.3398\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 586.0975 - val_loss: 555.9350\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 564.4555 - val_loss: 537.1729\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 544.2365 - val_loss: 518.1562\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 524.4769 - val_loss: 500.3485\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 3ms/step - loss: 505.6742 - val_loss: 482.6207\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 487.4574 - val_loss: 466.5697\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 470.3167 - val_loss: 450.8500\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 454.0335 - val_loss: 436.0800\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 438.3352 - val_loss: 421.9588\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 3ms/step - loss: 423.4374 - val_loss: 408.5327\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 6ms/step - loss: 409.2080 - val_loss: 396.1418\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 396.1218 - val_loss: 383.6557\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 383.4562 - val_loss: 372.4290\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 371.8136 - val_loss: 361.8624\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 10ms/step - loss: 360.7422 - val_loss: 351.5999\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 350.3760 - val_loss: 342.0468\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 340.4359 - val_loss: 333.1492\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 331.5187 - val_loss: 324.6664\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 3ms/step - loss: 322.9413 - val_loss: 316.5804\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 314.8543 - val_loss: 308.8080\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 307.4849 - val_loss: 301.0268\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 299.9829 - val_loss: 294.2836\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 293.4257 - val_loss: 287.5981\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 287.0742 - val_loss: 281.3585\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 281.1431 - val_loss: 275.5282\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 275.7136 - val_loss: 269.4389\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 270.0956 - val_loss: 264.2439\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 265.1534 - val_loss: 259.2853\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 260.3377 - val_loss: 254.4255\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 255.7240 - val_loss: 249.6414\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 251.3960 - val_loss: 244.9940\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 247.0958 - val_loss: 240.9144\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 243.2084 - val_loss: 236.8293\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 239.3761 - val_loss: 232.6981\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 235.7048 - val_loss: 228.9534\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 232.0611 - val_loss: 225.3536\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 228.7099 - val_loss: 221.8717\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 3ms/step - loss: 225.4153 - val_loss: 218.4934\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 222.2384 - val_loss: 215.3369\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 219.2054 - val_loss: 212.1478\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 6ms/step - loss: 216.3057 - val_loss: 208.8992\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 213.3082 - val_loss: 206.0879\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 210.5173 - val_loss: 203.1714\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 207.6374 - val_loss: 200.5197\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 205.0359 - val_loss: 197.6520\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 202.4084 - val_loss: 194.9487\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 199.9188 - val_loss: 192.3891\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 197.4823 - val_loss: 189.8739\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 195.0758 - val_loss: 187.4659\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.7494 - val_loss: 185.1094\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 3ms/step - loss: 190.5206 - val_loss: 182.8715\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.3087 - val_loss: 180.6243\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.2569 - val_loss: 178.3374\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.0741 - val_loss: 176.2967\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.0802 - val_loss: 174.2598\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 3ms/step - loss: 180.0404 - val_loss: 172.4282\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 11ms/step - loss: 178.1616 - val_loss: 170.5745\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.4055 - val_loss: 168.7383\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 62ms/step - loss: 1540.3098 - val_loss: 1675.7769\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1526.6835 - val_loss: 1662.4755\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1513.6501 - val_loss: 1650.0017\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1501.0747 - val_loss: 1637.8147\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1488.8188 - val_loss: 1625.8519\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1476.7649 - val_loss: 1613.7094\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1464.2249 - val_loss: 1601.6606\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1451.4705 - val_loss: 1589.3676\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1438.2965 - val_loss: 1576.5417\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1424.6233 - val_loss: 1562.9915\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1410.2292 - val_loss: 1548.6979\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1394.9303 - val_loss: 1533.4919\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1378.5508 - val_loss: 1517.6764\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1361.6917 - val_loss: 1500.5938\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1343.8004 - val_loss: 1482.5500\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1324.8214 - val_loss: 1464.3661\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1305.7889 - val_loss: 1444.5760\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1285.4661 - val_loss: 1424.8636\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1265.1327 - val_loss: 1404.2014\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1243.8590 - val_loss: 1382.9886\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1222.2496 - val_loss: 1361.0952\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1200.4385 - val_loss: 1338.7229\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1178.0118 - val_loss: 1316.8464\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1155.7874 - val_loss: 1294.4125\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1133.2211 - val_loss: 1271.3932\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 8ms/step - loss: 1110.6868 - val_loss: 1248.0076\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 1088.0070 - val_loss: 1224.6854\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 1065.3097 - val_loss: 1201.9690\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 1042.9080 - val_loss: 1178.9335\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 10ms/step - loss: 1020.7831 - val_loss: 1155.9379\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 998.8148 - val_loss: 1133.1371\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 976.9548 - val_loss: 1110.2462\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 955.2580 - val_loss: 1087.3755\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 934.0681 - val_loss: 1064.1737\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 912.4424 - val_loss: 1041.6580\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 891.4748 - val_loss: 1018.4821\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 870.3230 - val_loss: 995.2510\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 849.3725 - val_loss: 972.2435\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 828.2498 - val_loss: 948.4907\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 807.1327 - val_loss: 924.3265\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 785.3834 - val_loss: 900.3651\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 764.0974 - val_loss: 876.1024\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 742.5641 - val_loss: 851.3770\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 6ms/step - loss: 720.6871 - val_loss: 826.5607\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 698.6669 - val_loss: 800.5982\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 676.3984 - val_loss: 774.8798\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 653.8275 - val_loss: 748.6989\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 630.7909 - val_loss: 722.4238\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 6ms/step - loss: 608.0112 - val_loss: 695.5626\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 584.4407 - val_loss: 669.7363\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 562.2949 - val_loss: 642.3359\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 538.9079 - val_loss: 616.6638\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 516.2768 - val_loss: 590.2919\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 493.9403 - val_loss: 564.5464\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 472.1172 - val_loss: 539.4058\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 450.8246 - val_loss: 514.4307\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 429.9160 - val_loss: 490.3210\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 410.0314 - val_loss: 466.8579\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 390.6134 - val_loss: 444.2025\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 371.8453 - val_loss: 422.7315\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 353.7184 - val_loss: 402.8654\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 337.0286 - val_loss: 383.4149\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 320.9352 - val_loss: 365.2065\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 306.0104 - val_loss: 348.1205\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 291.7813 - val_loss: 332.5517\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 278.7230 - val_loss: 317.8823\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 266.3289 - val_loss: 304.1375\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 254.6559 - val_loss: 291.5006\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 243.8328 - val_loss: 280.1143\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 234.0282 - val_loss: 270.2493\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 10ms/step - loss: 225.4930 - val_loss: 260.4875\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 217.3083 - val_loss: 252.0477\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 7ms/step - loss: 210.2264 - val_loss: 244.1361\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 203.6060 - val_loss: 237.4367\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.8280 - val_loss: 231.6152\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.7430 - val_loss: 226.1349\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.9552 - val_loss: 221.5618\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.9449 - val_loss: 217.1340\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.2843 - val_loss: 213.1600\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.9637 - val_loss: 209.8869\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 3ms/step - loss: 174.0609 - val_loss: 206.9503\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.6874 - val_loss: 204.2062\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.1871 - val_loss: 201.7740\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 8ms/step - loss: 167.2589 - val_loss: 199.5123\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 3ms/step - loss: 165.3992 - val_loss: 197.6069\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.8345 - val_loss: 195.7015\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.3290 - val_loss: 194.1418\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.0584 - val_loss: 192.6547\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.8688 - val_loss: 191.2980\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.8596 - val_loss: 190.0117\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.8936 - val_loss: 188.8730\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.0335 - val_loss: 187.7539\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.1942 - val_loss: 186.7555\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.4359 - val_loss: 185.5710\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 154.6960 - val_loss: 184.5697\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.9933 - val_loss: 183.5587\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 6ms/step - loss: 153.2932 - val_loss: 182.6064\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.6828 - val_loss: 181.5873\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.0543 - val_loss: 180.7445\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 151.4774 - val_loss: 179.7292\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 63ms/step - loss: 1548.5829 - val_loss: 1644.4525\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1531.9182 - val_loss: 1627.7928\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1515.7765 - val_loss: 1611.9520\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1500.2896 - val_loss: 1596.2256\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1484.6106 - val_loss: 1580.8611\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 3ms/step - loss: 1469.4596 - val_loss: 1564.7858\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1453.8378 - val_loss: 1548.7488\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1437.8473 - val_loss: 1532.4338\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 1421.5261 - val_loss: 1515.5107\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1404.5203 - val_loss: 1498.0190\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1387.0443 - val_loss: 1479.9833\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1368.8662 - val_loss: 1461.1149\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 3ms/step - loss: 1349.7465 - val_loss: 1441.8062\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 7ms/step - loss: 1330.2129 - val_loss: 1421.7296\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1310.0359 - val_loss: 1400.8262\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1288.9005 - val_loss: 1379.5912\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 6ms/step - loss: 1267.3184 - val_loss: 1357.5814\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1245.1527 - val_loss: 1334.7549\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 6ms/step - loss: 1222.1598 - val_loss: 1311.3022\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1198.2600 - val_loss: 1287.7582\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1174.3153 - val_loss: 1262.5535\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1148.9718 - val_loss: 1237.3026\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1123.3774 - val_loss: 1211.4999\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1097.2568 - val_loss: 1185.0370\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1070.5533 - val_loss: 1157.6848\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 1042.8180 - val_loss: 1130.1509\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 1015.0367 - val_loss: 1102.1161\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 986.6906 - val_loss: 1073.5493\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 3ms/step - loss: 958.0549 - val_loss: 1044.5656\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 928.9532 - val_loss: 1015.7205\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 900.1705 - val_loss: 986.6624\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 871.3870 - val_loss: 957.7982\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 842.7928 - val_loss: 929.4631\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 814.6995 - val_loss: 900.9526\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 786.8643 - val_loss: 872.6549\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 759.5396 - val_loss: 845.0040\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 6ms/step - loss: 732.4944 - val_loss: 818.6494\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 706.4536 - val_loss: 792.2818\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 681.0950 - val_loss: 766.6956\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 656.6027 - val_loss: 741.3557\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 632.4199 - val_loss: 717.5462\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 12ms/step - loss: 609.4167 - val_loss: 693.9517\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 3ms/step - loss: 586.8561 - val_loss: 671.0944\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 565.4418 - val_loss: 649.4344\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 545.1420 - val_loss: 627.8688\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 525.3312 - val_loss: 607.5290\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 506.4762 - val_loss: 588.3362\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 488.5432 - val_loss: 569.5540\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 471.5818 - val_loss: 551.2964\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 3ms/step - loss: 455.1596 - val_loss: 534.3629\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 439.8813 - val_loss: 517.3473\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 424.9829 - val_loss: 501.6609\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 410.9622 - val_loss: 486.2377\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 3ms/step - loss: 397.4216 - val_loss: 471.6126\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 384.5411 - val_loss: 456.1373\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 371.8925 - val_loss: 441.5167\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 9ms/step - loss: 359.6563 - val_loss: 427.8201\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 348.1294 - val_loss: 414.2422\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 336.9879 - val_loss: 400.7228\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 326.3434 - val_loss: 387.8736\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 316.2287 - val_loss: 375.5011\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 6ms/step - loss: 306.6705 - val_loss: 363.6337\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 297.4995 - val_loss: 352.5184\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 288.7711 - val_loss: 342.1436\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 280.7491 - val_loss: 331.6994\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 273.2726 - val_loss: 322.1097\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 266.1095 - val_loss: 313.3659\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 259.5715 - val_loss: 304.6305\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 3ms/step - loss: 253.4599 - val_loss: 296.3993\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 247.7249 - val_loss: 289.1408\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 242.4155 - val_loss: 282.0945\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 237.5153 - val_loss: 275.5822\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 232.9994 - val_loss: 269.8897\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 228.9033 - val_loss: 264.2196\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 225.0328 - val_loss: 258.9731\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 221.6355 - val_loss: 253.9679\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 218.3669 - val_loss: 249.9722\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 215.4132 - val_loss: 245.5956\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 212.7480 - val_loss: 241.6355\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 210.1683 - val_loss: 238.3830\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 207.8839 - val_loss: 235.1449\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.7853 - val_loss: 231.4515\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 203.6402 - val_loss: 229.0314\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 10ms/step - loss: 201.8412 - val_loss: 226.2924\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.0614 - val_loss: 223.4944\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 7ms/step - loss: 198.4569 - val_loss: 221.5174\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 6ms/step - loss: 196.8834 - val_loss: 219.7826\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 195.4594 - val_loss: 217.3322\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 193.9923 - val_loss: 215.6875\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.6701 - val_loss: 213.5566\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.3833 - val_loss: 211.7164\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 190.1606 - val_loss: 209.9811\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.0591 - val_loss: 208.3909\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.8716 - val_loss: 207.4672\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.7855 - val_loss: 205.9975\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.6713 - val_loss: 204.2420\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.5459 - val_loss: 203.1329\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.5294 - val_loss: 202.0573\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.5479 - val_loss: 200.5070\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 8ms/step - loss: 181.5304 - val_loss: 199.4950\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 1575.9867 - val_loss: 1499.0137\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1557.3370 - val_loss: 1481.2681\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 1538.7347 - val_loss: 1463.7141\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 6ms/step - loss: 1520.4105 - val_loss: 1445.9728\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1501.7200 - val_loss: 1428.1300\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 6ms/step - loss: 1482.8159 - val_loss: 1409.7550\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1463.6443 - val_loss: 1390.6987\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1443.9176 - val_loss: 1371.3624\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1423.5273 - val_loss: 1351.4375\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1402.6509 - val_loss: 1330.7344\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1381.4803 - val_loss: 1309.0052\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1359.2559 - val_loss: 1287.0090\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1336.3638 - val_loss: 1264.1177\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1312.6434 - val_loss: 1240.5033\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 1288.4232 - val_loss: 1215.9065\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1263.3408 - val_loss: 1190.1254\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1237.2778 - val_loss: 1164.5292\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 3ms/step - loss: 1210.8997 - val_loss: 1137.9757\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1183.8303 - val_loss: 1110.7754\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1155.9553 - val_loss: 1082.9459\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 1127.3309 - val_loss: 1054.8202\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 1098.3937 - val_loss: 1025.6948\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 3ms/step - loss: 1068.7997 - val_loss: 996.4078\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1038.9984 - val_loss: 966.7473\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1008.9338 - val_loss: 936.7693\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 978.1939 - val_loss: 906.3573\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 947.2186 - val_loss: 875.8660\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 916.4677 - val_loss: 845.2657\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 885.3751 - val_loss: 815.2048\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 854.2333 - val_loss: 785.2268\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 823.6881 - val_loss: 754.9178\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 6ms/step - loss: 792.9008 - val_loss: 725.2082\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 762.7490 - val_loss: 695.9776\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 733.0520 - val_loss: 667.3961\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 703.5788 - val_loss: 639.4459\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 675.3293 - val_loss: 611.3029\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 647.0348 - val_loss: 584.3522\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 619.9638 - val_loss: 558.6443\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 593.8978 - val_loss: 533.7043\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 3ms/step - loss: 568.8372 - val_loss: 509.6639\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 544.4263 - val_loss: 487.1650\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 521.3036 - val_loss: 465.6397\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 7ms/step - loss: 499.1271 - val_loss: 444.9075\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 6ms/step - loss: 477.9792 - val_loss: 425.0956\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 457.8538 - val_loss: 406.1609\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 11ms/step - loss: 438.5540 - val_loss: 388.9004\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 420.5268 - val_loss: 372.4348\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 403.4489 - val_loss: 356.7077\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 3ms/step - loss: 387.4787 - val_loss: 342.2123\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 372.3939 - val_loss: 328.6975\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 358.4239 - val_loss: 315.9332\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 345.3006 - val_loss: 304.1673\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 332.6611 - val_loss: 293.4662\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 7ms/step - loss: 321.2587 - val_loss: 283.1904\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 310.5536 - val_loss: 273.6245\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 300.4832 - val_loss: 265.4606\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 291.5169 - val_loss: 257.3793\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 282.8838 - val_loss: 250.2677\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 275.1695 - val_loss: 243.4985\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 267.6440 - val_loss: 237.6031\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 261.0764 - val_loss: 231.8521\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 254.7493 - val_loss: 226.9060\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 249.0834 - val_loss: 222.1103\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 243.6775 - val_loss: 217.7646\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 238.6146 - val_loss: 213.7648\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 233.9395 - val_loss: 210.1085\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 229.5606 - val_loss: 206.7368\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 225.5884 - val_loss: 203.6744\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 221.6404 - val_loss: 200.7876\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 218.1096 - val_loss: 198.0550\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 214.6792 - val_loss: 195.6267\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 6ms/step - loss: 211.5367 - val_loss: 193.2418\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 208.5783 - val_loss: 191.0401\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 205.7575 - val_loss: 189.1788\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 203.0832 - val_loss: 187.3304\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.6008 - val_loss: 185.5681\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 198.1600 - val_loss: 183.8867\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 195.8620 - val_loss: 182.3133\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 193.7115 - val_loss: 180.7811\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 6ms/step - loss: 191.6508 - val_loss: 179.4686\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 189.6710 - val_loss: 178.1947\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.7988 - val_loss: 176.8979\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.0203 - val_loss: 175.6574\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.3551 - val_loss: 174.5365\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.8412 - val_loss: 173.3862\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 181.2124 - val_loss: 172.3176\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 12ms/step - loss: 179.6350 - val_loss: 171.3211\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.2258 - val_loss: 170.3771\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.7272 - val_loss: 169.4871\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.4239 - val_loss: 168.5043\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 6ms/step - loss: 174.0683 - val_loss: 167.6235\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.7025 - val_loss: 166.8099\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 171.5265 - val_loss: 165.9305\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.2981 - val_loss: 164.9818\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.9817 - val_loss: 164.1834\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.8286 - val_loss: 163.3427\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.6414 - val_loss: 162.2184\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.3630 - val_loss: 161.4897\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 164.2606 - val_loss: 160.5844\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.1712 - val_loss: 159.7564\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 60ms/step - loss: 1631.6527 - val_loss: 1562.2166\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1612.4270 - val_loss: 1543.3026\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1594.2382 - val_loss: 1523.9581\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1576.0477 - val_loss: 1505.5627\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1557.9712 - val_loss: 1487.6239\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1539.9353 - val_loss: 1469.6338\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1522.1580 - val_loss: 1450.8424\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1503.5676 - val_loss: 1433.1448\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1485.4397 - val_loss: 1414.4525\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1466.4431 - val_loss: 1395.6890\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1447.2532 - val_loss: 1376.0414\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1427.3977 - val_loss: 1356.7584\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1407.4233 - val_loss: 1336.6774\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 11ms/step - loss: 1386.8711 - val_loss: 1316.3270\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1366.0297 - val_loss: 1295.5869\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1344.3516 - val_loss: 1274.4713\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 10ms/step - loss: 1322.2913 - val_loss: 1252.9336\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1299.7783 - val_loss: 1230.6343\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1276.8507 - val_loss: 1207.8646\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1253.1886 - val_loss: 1184.9104\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1229.2582 - val_loss: 1161.4613\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 1204.5911 - val_loss: 1137.1494\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1179.4763 - val_loss: 1112.5482\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 1154.0256 - val_loss: 1086.9753\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1127.3158 - val_loss: 1061.3171\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 1100.7484 - val_loss: 1034.2412\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 6ms/step - loss: 1072.7101 - val_loss: 1007.3574\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 3ms/step - loss: 1044.6278 - val_loss: 979.9929\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 1015.9193 - val_loss: 952.2416\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 986.8135 - val_loss: 924.1714\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 957.5309 - val_loss: 895.2003\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 927.7758 - val_loss: 865.9916\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 897.4053 - val_loss: 836.8947\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 867.1221 - val_loss: 808.5025\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 3ms/step - loss: 837.3026 - val_loss: 779.5139\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 807.1275 - val_loss: 751.0919\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 777.5295 - val_loss: 722.9192\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 748.2100 - val_loss: 695.1373\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 719.2625 - val_loss: 668.0014\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 691.0576 - val_loss: 641.7140\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 663.5801 - val_loss: 616.5508\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 637.1219 - val_loss: 592.0220\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 611.5153 - val_loss: 568.3847\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 586.5047 - val_loss: 545.8506\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 562.7133 - val_loss: 524.3179\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 539.8186 - val_loss: 503.7746\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 6ms/step - loss: 517.9618 - val_loss: 484.3993\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 6ms/step - loss: 497.0952 - val_loss: 466.1696\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 477.1921 - val_loss: 448.8568\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 458.4191 - val_loss: 432.2007\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 440.1279 - val_loss: 416.8528\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 423.0562 - val_loss: 402.2346\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 406.7907 - val_loss: 388.4155\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 391.3958 - val_loss: 375.6693\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 376.8370 - val_loss: 363.9524\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 363.3390 - val_loss: 352.5553\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 350.3836 - val_loss: 342.1836\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 11ms/step - loss: 338.3119 - val_loss: 332.3464\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 326.7434 - val_loss: 323.3661\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 315.9553 - val_loss: 314.8865\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 305.8208 - val_loss: 306.9475\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 3ms/step - loss: 296.2143 - val_loss: 299.6895\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 287.2208 - val_loss: 292.5508\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 278.6420 - val_loss: 286.0368\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 270.7235 - val_loss: 280.0819\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 263.4980 - val_loss: 274.2627\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 256.2844 - val_loss: 269.2501\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 249.9192 - val_loss: 264.0590\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 243.6667 - val_loss: 259.6472\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 237.9733 - val_loss: 255.1812\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 232.3789 - val_loss: 251.0559\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 227.3793 - val_loss: 247.3680\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 222.4948 - val_loss: 243.7616\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 218.0768 - val_loss: 240.4657\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 213.9405 - val_loss: 237.1892\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 3ms/step - loss: 209.9538 - val_loss: 234.4402\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.2667 - val_loss: 231.7056\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 202.8999 - val_loss: 229.0324\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 199.4761 - val_loss: 226.6494\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 196.4591 - val_loss: 223.9959\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.4284 - val_loss: 221.8117\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.7052 - val_loss: 219.9064\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.0359 - val_loss: 218.0045\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.6800 - val_loss: 216.0170\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.3138 - val_loss: 214.3769\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 181.2736 - val_loss: 212.5076\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 6ms/step - loss: 179.2409 - val_loss: 210.9853\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.4022 - val_loss: 209.3333\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.5947 - val_loss: 208.0381\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.9094 - val_loss: 207.0126\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.3509 - val_loss: 205.5071\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.8058 - val_loss: 204.2101\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.2897 - val_loss: 202.8821\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 3ms/step - loss: 167.9088 - val_loss: 201.7045\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.5402 - val_loss: 200.7406\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.3131 - val_loss: 199.3055\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 3ms/step - loss: 164.0525 - val_loss: 198.4243\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.8376 - val_loss: 197.4331\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.6720 - val_loss: 196.1685\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 11ms/step - loss: 160.5446 - val_loss: 195.5200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 1521.4381 - val_loss: 1631.9159\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1505.8419 - val_loss: 1615.5691\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1490.4048 - val_loss: 1599.4189\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1475.0919 - val_loss: 1582.9532\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1459.4159 - val_loss: 1566.5027\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1443.4963 - val_loss: 1549.7705\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 1427.2935 - val_loss: 1532.2231\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1410.5393 - val_loss: 1514.0261\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 1393.1564 - val_loss: 1495.4156\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 6ms/step - loss: 1375.3719 - val_loss: 1475.5129\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1356.4250 - val_loss: 1454.9160\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1336.5306 - val_loss: 1433.3986\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1316.0656 - val_loss: 1410.0771\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 6ms/step - loss: 1294.1511 - val_loss: 1386.2493\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 1271.4539 - val_loss: 1361.1963\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 3ms/step - loss: 1247.7424 - val_loss: 1334.2520\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1222.3645 - val_loss: 1307.0240\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 1196.4009 - val_loss: 1277.8972\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1169.0408 - val_loss: 1247.6949\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1140.8699 - val_loss: 1216.4542\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1111.5468 - val_loss: 1184.5186\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1081.5594 - val_loss: 1151.3057\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 1050.7570 - val_loss: 1117.6963\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1019.5709 - val_loss: 1083.8732\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 988.2018 - val_loss: 1049.6658\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 956.2986 - val_loss: 1015.0667\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 924.1420 - val_loss: 980.7416\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 892.2088 - val_loss: 946.2993\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 860.6429 - val_loss: 911.6792\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 10ms/step - loss: 828.9316 - val_loss: 877.7674\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 797.9824 - val_loss: 844.6659\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 767.3177 - val_loss: 812.0574\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 737.4382 - val_loss: 779.0222\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 9ms/step - loss: 707.3580 - val_loss: 747.3897\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 678.4561 - val_loss: 716.2576\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 650.3173 - val_loss: 686.5841\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 623.2735 - val_loss: 657.2039\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 596.9492 - val_loss: 628.6032\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 571.5120 - val_loss: 601.3164\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 8ms/step - loss: 546.8658 - val_loss: 575.4628\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 523.4470 - val_loss: 550.1085\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 500.5717 - val_loss: 525.8600\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 478.9157 - val_loss: 503.2570\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 458.4336 - val_loss: 481.0490\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 438.7610 - val_loss: 460.4696\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 3ms/step - loss: 420.4143 - val_loss: 440.4847\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 402.8870 - val_loss: 421.8258\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 386.2018 - val_loss: 404.4697\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 370.7157 - val_loss: 388.2924\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 356.4384 - val_loss: 372.5717\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 342.9579 - val_loss: 357.7122\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 330.1204 - val_loss: 344.1351\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 318.2796 - val_loss: 331.3842\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 307.1290 - val_loss: 319.2400\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 296.8542 - val_loss: 308.0970\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 287.4090 - val_loss: 297.7784\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 278.4973 - val_loss: 287.8687\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 270.2464 - val_loss: 278.7915\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 262.5408 - val_loss: 270.6425\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 255.5469 - val_loss: 262.8740\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 249.1088 - val_loss: 255.4688\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 243.0911 - val_loss: 249.0564\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 237.3665 - val_loss: 243.3033\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 9ms/step - loss: 232.3467 - val_loss: 237.5296\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 227.6170 - val_loss: 232.3307\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 223.1591 - val_loss: 227.5549\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 219.0958 - val_loss: 223.5125\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.4003 - val_loss: 219.1405\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 3ms/step - loss: 211.9002 - val_loss: 215.5905\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 3ms/step - loss: 208.6429 - val_loss: 212.0477\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 205.5648 - val_loss: 208.7004\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 11ms/step - loss: 202.6254 - val_loss: 205.9596\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.8436 - val_loss: 202.9587\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 3ms/step - loss: 197.1888 - val_loss: 200.2847\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 3ms/step - loss: 194.7847 - val_loss: 197.8718\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 3ms/step - loss: 192.4115 - val_loss: 195.4526\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 3ms/step - loss: 190.0711 - val_loss: 192.8452\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.8850 - val_loss: 190.8428\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.9256 - val_loss: 188.6780\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.9319 - val_loss: 186.9154\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.0185 - val_loss: 185.1297\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.2365 - val_loss: 183.1321\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.4009 - val_loss: 181.4316\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.7676 - val_loss: 179.8778\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.0786 - val_loss: 178.2695\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.5382 - val_loss: 176.8391\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.9154 - val_loss: 175.2363\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.4887 - val_loss: 173.6659\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 3ms/step - loss: 168.9543 - val_loss: 172.4328\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.6278 - val_loss: 171.0867\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 3ms/step - loss: 166.1842 - val_loss: 170.1438\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.9067 - val_loss: 168.9099\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.6198 - val_loss: 167.9569\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.2878 - val_loss: 166.8095\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.1382 - val_loss: 165.6313\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 6ms/step - loss: 159.8653 - val_loss: 164.6040\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.7843 - val_loss: 163.7947\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.6514 - val_loss: 162.5662\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.4676 - val_loss: 161.9100\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.3729 - val_loss: 160.9767\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 66ms/step - loss: 1497.3724 - val_loss: 1514.4984\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1479.0492 - val_loss: 1496.3436\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1460.1193 - val_loss: 1477.2565\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1440.4293 - val_loss: 1457.2952\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 3ms/step - loss: 1419.9481 - val_loss: 1436.2607\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1398.4634 - val_loss: 1413.9156\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1375.5359 - val_loss: 1390.8658\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 3ms/step - loss: 1351.8042 - val_loss: 1366.4540\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1326.9982 - val_loss: 1340.2673\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1300.6807 - val_loss: 1313.9189\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1274.3495 - val_loss: 1285.6610\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1246.4408 - val_loss: 1257.1367\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 1217.6725 - val_loss: 1228.3964\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 8ms/step - loss: 1188.3187 - val_loss: 1198.6359\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1158.6594 - val_loss: 1167.3994\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1128.0741 - val_loss: 1135.9307\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 12ms/step - loss: 1097.0546 - val_loss: 1103.7179\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 1065.3381 - val_loss: 1071.4639\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1033.5765 - val_loss: 1038.7683\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1001.1533 - val_loss: 1006.0836\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 968.8834 - val_loss: 973.5437\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 937.2581 - val_loss: 939.8305\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 904.4856 - val_loss: 908.2797\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 3ms/step - loss: 873.3144 - val_loss: 875.3513\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 841.7538 - val_loss: 843.6407\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 810.7823 - val_loss: 811.7314\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 780.6644 - val_loss: 780.8680\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 3ms/step - loss: 750.6982 - val_loss: 752.2218\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 6ms/step - loss: 722.6324 - val_loss: 722.8215\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 694.4630 - val_loss: 694.9060\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 667.3628 - val_loss: 667.8654\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 641.1225 - val_loss: 641.4995\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 616.0574 - val_loss: 615.8155\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 591.3827 - val_loss: 591.9193\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 3ms/step - loss: 568.4219 - val_loss: 568.4041\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 545.7213 - val_loss: 546.3253\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 524.5962 - val_loss: 524.2812\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 503.9825 - val_loss: 503.9803\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 484.6661 - val_loss: 484.8929\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 466.5021 - val_loss: 466.9531\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 6ms/step - loss: 449.4884 - val_loss: 449.5760\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 433.1876 - val_loss: 433.5565\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 417.8988 - val_loss: 418.2613\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 403.3242 - val_loss: 404.1742\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 389.7841 - val_loss: 390.2067\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 11ms/step - loss: 376.7393 - val_loss: 377.2941\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 3ms/step - loss: 364.6340 - val_loss: 365.2508\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 353.1651 - val_loss: 354.1596\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 342.6389 - val_loss: 343.3722\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 332.5489 - val_loss: 332.9288\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 322.7899 - val_loss: 323.6209\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 3ms/step - loss: 313.8183 - val_loss: 314.5537\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 305.1682 - val_loss: 306.2827\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 297.0943 - val_loss: 298.1637\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 289.4142 - val_loss: 290.7161\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 282.3582 - val_loss: 283.4241\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 7ms/step - loss: 275.4289 - val_loss: 277.0210\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 269.0497 - val_loss: 270.6945\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 263.0382 - val_loss: 264.6570\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 257.2260 - val_loss: 259.0010\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 251.8302 - val_loss: 253.6268\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 246.8042 - val_loss: 248.0552\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 241.6147 - val_loss: 243.5032\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 236.8734 - val_loss: 238.9790\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 232.5614 - val_loss: 234.2144\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 228.1047 - val_loss: 229.9538\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 223.9241 - val_loss: 226.2914\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 220.2616 - val_loss: 222.4641\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 216.5157 - val_loss: 218.9978\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 213.2557 - val_loss: 215.6938\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 210.0043 - val_loss: 212.7620\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 207.0710 - val_loss: 209.8044\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 204.2098 - val_loss: 207.1207\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 201.5491 - val_loss: 204.3699\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 198.9697 - val_loss: 201.9101\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 196.5281 - val_loss: 199.3694\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.1671 - val_loss: 197.0946\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.8755 - val_loss: 195.0168\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 189.8364 - val_loss: 192.8879\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.7394 - val_loss: 190.9480\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.8127 - val_loss: 189.1323\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.9717 - val_loss: 187.4646\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.2099 - val_loss: 185.5964\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.4861 - val_loss: 183.9420\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.7008 - val_loss: 182.2648\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.2183 - val_loss: 180.9338\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 11ms/step - loss: 175.6924 - val_loss: 179.3459\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.1816 - val_loss: 178.0977\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 3ms/step - loss: 172.8596 - val_loss: 176.8188\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 171.5276 - val_loss: 175.5909\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.2260 - val_loss: 174.3149\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.0299 - val_loss: 173.2159\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 3ms/step - loss: 167.7789 - val_loss: 172.1341\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.6719 - val_loss: 170.9537\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.5169 - val_loss: 169.7815\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 6ms/step - loss: 164.4010 - val_loss: 168.7794\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 3ms/step - loss: 163.3911 - val_loss: 167.8458\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.3858 - val_loss: 166.6589\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.3598 - val_loss: 165.8792\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.3837 - val_loss: 164.9363\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 57ms/step - loss: 1563.4105 - val_loss: 1626.3341\n",
      "Epoch 2/100\n",
      "23/23 - 1s - 22ms/step - loss: 1548.7571 - val_loss: 1611.0131\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 3ms/step - loss: 1534.3258 - val_loss: 1595.6405\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1519.4978 - val_loss: 1580.1520\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1504.5310 - val_loss: 1563.8357\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1488.6465 - val_loss: 1547.1227\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 1472.0850 - val_loss: 1529.5249\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 3ms/step - loss: 1454.3981 - val_loss: 1510.6304\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1435.6129 - val_loss: 1490.7815\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 1415.9896 - val_loss: 1469.5452\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1394.7310 - val_loss: 1447.8770\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1372.7789 - val_loss: 1424.2952\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1349.5471 - val_loss: 1399.6965\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 1325.1075 - val_loss: 1374.3098\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1299.6509 - val_loss: 1348.0745\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 11ms/step - loss: 1273.5612 - val_loss: 1319.7352\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1245.9655 - val_loss: 1291.1621\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 3ms/step - loss: 1217.6177 - val_loss: 1261.8271\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1188.5146 - val_loss: 1231.5342\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1158.7318 - val_loss: 1200.3701\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 1128.2537 - val_loss: 1168.3749\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1097.1625 - val_loss: 1136.3860\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1065.6716 - val_loss: 1103.2745\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1033.9131 - val_loss: 1069.3982\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1001.3995 - val_loss: 1036.1589\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 969.0683 - val_loss: 1002.0743\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 936.4135 - val_loss: 968.4282\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 904.0480 - val_loss: 933.8069\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 871.4202 - val_loss: 899.4573\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 838.8026 - val_loss: 865.7264\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 806.6044 - val_loss: 832.0383\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 774.6665 - val_loss: 798.4856\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 743.2238 - val_loss: 765.0058\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 6ms/step - loss: 712.3554 - val_loss: 732.4482\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 682.0259 - val_loss: 701.3670\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 653.0486 - val_loss: 670.1485\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 624.4161 - val_loss: 640.2009\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 597.2281 - val_loss: 611.3895\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 570.7191 - val_loss: 583.8958\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 6ms/step - loss: 545.1510 - val_loss: 558.3975\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 521.3407 - val_loss: 532.1951\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 497.9661 - val_loss: 507.5466\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 475.7320 - val_loss: 485.3796\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 455.0173 - val_loss: 463.3892\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 3ms/step - loss: 435.2793 - val_loss: 442.9659\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 416.8034 - val_loss: 422.8075\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 6ms/step - loss: 399.1977 - val_loss: 405.0119\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 383.0270 - val_loss: 388.4436\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 367.9699 - val_loss: 372.8973\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 3ms/step - loss: 353.9247 - val_loss: 358.0819\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 340.8723 - val_loss: 344.2053\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 328.4258 - val_loss: 332.2279\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 317.4257 - val_loss: 320.2583\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 3ms/step - loss: 306.7339 - val_loss: 309.6280\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 297.1235 - val_loss: 300.1789\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 288.1235 - val_loss: 290.6644\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 279.6444 - val_loss: 282.3597\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 11ms/step - loss: 272.0864 - val_loss: 274.7813\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 3ms/step - loss: 265.2225 - val_loss: 267.4846\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 258.5929 - val_loss: 261.1890\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 252.7425 - val_loss: 255.2667\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 247.2427 - val_loss: 249.4801\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 242.0853 - val_loss: 244.6944\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 237.4778 - val_loss: 240.0157\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 233.1748 - val_loss: 235.5997\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 229.2151 - val_loss: 231.6954\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 225.3834 - val_loss: 228.2518\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 6ms/step - loss: 221.7407 - val_loss: 224.5145\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 218.3800 - val_loss: 221.0120\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 215.2598 - val_loss: 218.0346\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 212.4720 - val_loss: 214.6830\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 209.5016 - val_loss: 212.4987\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 207.0737 - val_loss: 209.9266\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 204.4711 - val_loss: 207.6640\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 202.1389 - val_loss: 205.3649\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 3ms/step - loss: 199.8541 - val_loss: 202.9695\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.7066 - val_loss: 200.9991\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 195.7007 - val_loss: 198.5266\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 9ms/step - loss: 193.5971 - val_loss: 196.9366\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.6162 - val_loss: 194.7012\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 189.7825 - val_loss: 193.0720\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.0903 - val_loss: 191.0003\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.3572 - val_loss: 189.6048\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.7272 - val_loss: 188.0045\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.0853 - val_loss: 186.2211\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.4939 - val_loss: 184.4882\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.9684 - val_loss: 183.0954\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.4672 - val_loss: 181.6238\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.0745 - val_loss: 180.3951\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.5953 - val_loss: 178.9895\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.2731 - val_loss: 177.6814\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.9229 - val_loss: 176.4859\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.6398 - val_loss: 175.0355\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.3781 - val_loss: 173.9158\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.1096 - val_loss: 172.6120\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.0134 - val_loss: 171.2119\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.7856 - val_loss: 170.2932\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.5966 - val_loss: 169.0926\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 11ms/step - loss: 164.4602 - val_loss: 167.8584\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.4110 - val_loss: 166.8014\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 - 1s - 64ms/step - loss: 1509.4401 - val_loss: 1500.8551\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1494.3268 - val_loss: 1486.0929\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1478.0537 - val_loss: 1470.3411\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1460.8596 - val_loss: 1453.0094\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1441.7915 - val_loss: 1434.5074\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1421.3491 - val_loss: 1414.0153\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1398.9750 - val_loss: 1392.1857\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1374.9170 - val_loss: 1368.7500\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1349.0109 - val_loss: 1343.4584\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1321.3229 - val_loss: 1316.8293\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1292.2714 - val_loss: 1288.4092\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 3ms/step - loss: 1261.7446 - val_loss: 1258.4165\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1229.6206 - val_loss: 1227.2069\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1195.9832 - val_loss: 1194.9908\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1161.4508 - val_loss: 1161.5339\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 9ms/step - loss: 1125.8119 - val_loss: 1126.6064\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1089.2158 - val_loss: 1091.0487\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1051.7614 - val_loss: 1054.6884\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1013.8138 - val_loss: 1018.2357\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 6ms/step - loss: 975.9489 - val_loss: 981.2985\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 937.9419 - val_loss: 943.4778\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 899.6069 - val_loss: 906.6288\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 861.8272 - val_loss: 870.1686\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 824.6324 - val_loss: 833.5214\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 10ms/step - loss: 787.6784 - val_loss: 798.0741\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 752.2440 - val_loss: 762.7407\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 716.9745 - val_loss: 728.9211\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 683.4399 - val_loss: 695.4607\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 650.6216 - val_loss: 663.7613\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 619.4973 - val_loss: 632.1149\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 6ms/step - loss: 588.7849 - val_loss: 603.0023\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 560.6830 - val_loss: 573.5327\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 533.1802 - val_loss: 546.1128\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 507.4642 - val_loss: 520.2206\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 482.9638 - val_loss: 495.8904\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 7ms/step - loss: 459.9759 - val_loss: 472.8210\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 438.5035 - val_loss: 450.7552\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 418.1733 - val_loss: 430.2338\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 399.5941 - val_loss: 410.2557\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 381.9046 - val_loss: 392.6291\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 365.9951 - val_loss: 376.1134\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 351.2889 - val_loss: 360.1342\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 337.2114 - val_loss: 345.4184\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 324.1794 - val_loss: 332.1367\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 312.6997 - val_loss: 319.0588\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 301.3560 - val_loss: 307.8018\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 291.4052 - val_loss: 297.2048\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 281.9521 - val_loss: 287.5150\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 273.3990 - val_loss: 278.0494\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 265.5080 - val_loss: 269.5095\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 258.0570 - val_loss: 261.8222\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 3ms/step - loss: 251.1864 - val_loss: 254.8398\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 244.8607 - val_loss: 247.9927\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 238.9567 - val_loss: 241.8050\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 7ms/step - loss: 233.5397 - val_loss: 235.8650\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 228.3906 - val_loss: 230.8007\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 223.7992 - val_loss: 225.9129\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 219.3133 - val_loss: 221.7563\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 215.2216 - val_loss: 218.0403\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 211.3089 - val_loss: 214.1844\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 207.8130 - val_loss: 210.2011\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 204.0765 - val_loss: 207.0896\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 200.9953 - val_loss: 204.1136\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.9175 - val_loss: 201.3852\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 195.2047 - val_loss: 198.6027\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.3090 - val_loss: 196.3103\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 10ms/step - loss: 189.8006 - val_loss: 194.0686\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.3788 - val_loss: 191.7930\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.1055 - val_loss: 189.8480\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.9272 - val_loss: 187.8396\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.8462 - val_loss: 186.0340\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.9636 - val_loss: 184.2306\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.0894 - val_loss: 182.6960\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 3ms/step - loss: 175.2298 - val_loss: 181.3755\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.5169 - val_loss: 179.8349\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 6ms/step - loss: 171.8529 - val_loss: 178.4926\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.2806 - val_loss: 177.0662\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 3ms/step - loss: 168.7820 - val_loss: 175.8981\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.3063 - val_loss: 174.5547\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 3ms/step - loss: 165.8728 - val_loss: 173.4640\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 7ms/step - loss: 164.4770 - val_loss: 172.2843\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 3ms/step - loss: 163.1288 - val_loss: 171.1451\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.8591 - val_loss: 169.9695\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.5421 - val_loss: 168.9554\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.2972 - val_loss: 167.9126\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.1522 - val_loss: 166.7917\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.9338 - val_loss: 165.8657\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.7732 - val_loss: 164.7759\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 154.7684 - val_loss: 163.6383\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.5250 - val_loss: 162.6896\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.5426 - val_loss: 161.8009\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 3ms/step - loss: 151.4362 - val_loss: 160.8126\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.4167 - val_loss: 159.9734\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 149.3196 - val_loss: 158.9974\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 148.3407 - val_loss: 157.9708\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 147.2935 - val_loss: 157.1641\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 146.3828 - val_loss: 156.2968\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 3ms/step - loss: 145.2945 - val_loss: 155.4190\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 144.3492 - val_loss: 154.5978\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 143.5119 - val_loss: 153.7535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 72ms/step - loss: 1565.0730 - val_loss: 1460.8401\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1550.6287 - val_loss: 1447.4696\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1535.6283 - val_loss: 1433.4921\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1519.7454 - val_loss: 1418.8247\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1502.8428 - val_loss: 1403.0862\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1484.7767 - val_loss: 1386.4708\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1465.6165 - val_loss: 1368.8652\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 7ms/step - loss: 1444.9568 - val_loss: 1350.1730\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1423.0348 - val_loss: 1330.2996\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 1399.8097 - val_loss: 1309.1078\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1375.0404 - val_loss: 1287.1238\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1349.4191 - val_loss: 1263.5024\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1322.1577 - val_loss: 1239.3160\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1294.0447 - val_loss: 1213.7810\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1264.6990 - val_loss: 1187.4556\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 6ms/step - loss: 1234.0775 - val_loss: 1160.3834\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1202.7318 - val_loss: 1132.1685\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1170.1940 - val_loss: 1103.4473\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1136.9706 - val_loss: 1074.0322\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1102.6907 - val_loss: 1043.6472\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1068.1377 - val_loss: 1013.0380\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1032.8606 - val_loss: 982.0978\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 6ms/step - loss: 997.5708 - val_loss: 950.4767\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 961.4952 - val_loss: 919.2286\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 925.6479 - val_loss: 887.8899\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 890.2094 - val_loss: 855.4365\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 3ms/step - loss: 854.2930 - val_loss: 823.4001\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 818.4328 - val_loss: 791.3998\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 782.8760 - val_loss: 759.5419\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 747.6057 - val_loss: 727.5214\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 712.4507 - val_loss: 696.1704\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 677.6161 - val_loss: 665.0226\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 644.1028 - val_loss: 633.5733\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 610.2961 - val_loss: 603.7923\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 578.4403 - val_loss: 574.1654\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 547.0975 - val_loss: 546.7259\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 517.4695 - val_loss: 519.6608\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 489.0746 - val_loss: 494.0656\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 462.3246 - val_loss: 469.7689\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 436.7503 - val_loss: 446.8709\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 413.0433 - val_loss: 424.9839\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 6ms/step - loss: 390.6598 - val_loss: 404.8506\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 370.1308 - val_loss: 386.2538\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 10ms/step - loss: 350.8066 - val_loss: 368.3736\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 333.0419 - val_loss: 352.4449\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 317.0701 - val_loss: 337.3521\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 302.2642 - val_loss: 323.5322\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 288.8047 - val_loss: 311.0489\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 6ms/step - loss: 276.6680 - val_loss: 299.3114\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 265.5237 - val_loss: 288.5130\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 255.6725 - val_loss: 278.5495\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 6ms/step - loss: 246.6749 - val_loss: 269.7475\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 15ms/step - loss: 238.6471 - val_loss: 262.0834\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 3ms/step - loss: 231.4130 - val_loss: 254.3684\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 224.9376 - val_loss: 247.7647\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 9ms/step - loss: 219.1819 - val_loss: 241.6624\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 213.9474 - val_loss: 236.2217\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 3ms/step - loss: 209.3707 - val_loss: 231.4440\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.3797 - val_loss: 226.5051\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 6ms/step - loss: 201.4665 - val_loss: 222.4312\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 198.1722 - val_loss: 218.7340\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 10ms/step - loss: 195.1478 - val_loss: 215.0015\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.3715 - val_loss: 212.0952\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 6ms/step - loss: 189.9969 - val_loss: 209.1046\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.6399 - val_loss: 206.7207\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.6433 - val_loss: 204.1199\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.7818 - val_loss: 201.3901\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 181.9245 - val_loss: 199.4974\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.2827 - val_loss: 197.7156\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.7826 - val_loss: 195.6520\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.2861 - val_loss: 193.5650\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.8296 - val_loss: 192.3167\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 3ms/step - loss: 174.4891 - val_loss: 190.6273\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 3ms/step - loss: 173.2473 - val_loss: 189.1124\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.0424 - val_loss: 187.2015\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 3ms/step - loss: 170.7864 - val_loss: 185.8456\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.7317 - val_loss: 184.6708\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 6ms/step - loss: 168.5011 - val_loss: 183.1533\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 3ms/step - loss: 167.4106 - val_loss: 181.4557\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 3ms/step - loss: 166.2753 - val_loss: 180.2196\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.1720 - val_loss: 178.6827\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 3ms/step - loss: 164.1397 - val_loss: 177.4538\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.9869 - val_loss: 176.0293\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.9071 - val_loss: 174.6775\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 11ms/step - loss: 160.8077 - val_loss: 173.3920\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.7725 - val_loss: 172.0191\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 158.6944 - val_loss: 171.0977\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.7115 - val_loss: 170.0439\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.7185 - val_loss: 168.5596\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.7466 - val_loss: 167.3705\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.7748 - val_loss: 165.9730\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.7301 - val_loss: 164.7791\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 3ms/step - loss: 152.7729 - val_loss: 163.9770\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 151.8037 - val_loss: 162.7656\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.9948 - val_loss: 161.7854\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.0304 - val_loss: 160.7786\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 149.2105 - val_loss: 159.7585\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 8ms/step - loss: 148.3863 - val_loss: 158.7809\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.5935 - val_loss: 157.9646\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 146.7179 - val_loss: 156.6824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 67ms/step - loss: 1511.4196 - val_loss: 1619.8728\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1494.2098 - val_loss: 1602.6938\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1477.4279 - val_loss: 1586.0896\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1461.1812 - val_loss: 1569.3423\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1445.0671 - val_loss: 1552.8987\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1428.6989 - val_loss: 1536.3273\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1411.9496 - val_loss: 1519.0292\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1394.5476 - val_loss: 1500.9279\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1376.2350 - val_loss: 1482.1990\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1357.0509 - val_loss: 1462.6140\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1336.9517 - val_loss: 1441.8983\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1315.6703 - val_loss: 1419.7410\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 1293.1106 - val_loss: 1396.9915\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1270.0322 - val_loss: 1372.3848\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 1245.1736 - val_loss: 1347.3031\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 6ms/step - loss: 1219.3601 - val_loss: 1321.1354\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 1192.6562 - val_loss: 1293.3590\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1165.0789 - val_loss: 1263.7225\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 10ms/step - loss: 1136.1246 - val_loss: 1233.4690\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1106.1733 - val_loss: 1202.6049\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1076.1134 - val_loss: 1169.8274\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1044.3380 - val_loss: 1137.2444\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 1012.4623 - val_loss: 1103.5035\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 980.2157 - val_loss: 1068.1835\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 946.7750 - val_loss: 1032.9622\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 913.5390 - val_loss: 996.8065\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 6ms/step - loss: 879.8535 - val_loss: 961.0618\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 846.4294 - val_loss: 925.0732\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 813.3197 - val_loss: 888.5674\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 780.4349 - val_loss: 853.4326\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 748.3488 - val_loss: 817.7696\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 716.6226 - val_loss: 783.3558\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 685.5671 - val_loss: 749.9997\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 8ms/step - loss: 655.3873 - val_loss: 717.3394\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 626.5818 - val_loss: 685.1760\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 599.0216 - val_loss: 653.8657\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 571.6445 - val_loss: 624.9921\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 546.2196 - val_loss: 596.6339\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 521.8160 - val_loss: 569.5762\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 498.4784 - val_loss: 543.7363\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 476.4526 - val_loss: 519.4545\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 455.6532 - val_loss: 496.5652\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 12ms/step - loss: 436.1080 - val_loss: 474.0907\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 6ms/step - loss: 417.6292 - val_loss: 453.3112\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 400.1730 - val_loss: 434.4352\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 384.2077 - val_loss: 416.4791\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 369.2365 - val_loss: 399.2768\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 354.8630 - val_loss: 383.8268\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 341.8608 - val_loss: 368.7099\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 3ms/step - loss: 329.6313 - val_loss: 354.8270\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 318.1078 - val_loss: 342.4662\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 307.8606 - val_loss: 330.6363\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 298.2752 - val_loss: 319.4440\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 289.3303 - val_loss: 309.4118\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 6ms/step - loss: 281.2189 - val_loss: 299.9085\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 273.8390 - val_loss: 290.7193\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 266.5074 - val_loss: 282.7266\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 259.9780 - val_loss: 275.0440\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 253.9979 - val_loss: 267.7119\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 248.3330 - val_loss: 261.0223\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 6ms/step - loss: 243.1445 - val_loss: 254.5393\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 238.2223 - val_loss: 248.9681\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 3ms/step - loss: 233.6937 - val_loss: 243.8392\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 229.4953 - val_loss: 238.6492\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 225.5143 - val_loss: 233.9056\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 221.7147 - val_loss: 229.4702\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 3ms/step - loss: 218.1623 - val_loss: 225.3794\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 214.8419 - val_loss: 221.1155\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 211.6282 - val_loss: 217.4802\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 3ms/step - loss: 208.5563 - val_loss: 214.0603\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 205.7603 - val_loss: 210.4626\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 203.0288 - val_loss: 207.2137\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 200.3952 - val_loss: 204.4364\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 197.9666 - val_loss: 201.3913\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 3ms/step - loss: 195.6283 - val_loss: 198.5128\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 193.2151 - val_loss: 196.0696\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.0643 - val_loss: 193.4154\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.8460 - val_loss: 190.9546\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 186.7521 - val_loss: 188.5265\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.7157 - val_loss: 186.4165\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.6861 - val_loss: 184.2254\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.7051 - val_loss: 182.0036\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.6875 - val_loss: 180.0066\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.6785 - val_loss: 177.9331\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 11ms/step - loss: 174.7342 - val_loss: 175.8880\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.8601 - val_loss: 173.8558\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.9616 - val_loss: 172.0897\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.2275 - val_loss: 170.4393\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.3948 - val_loss: 168.5782\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.6216 - val_loss: 166.8993\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 6ms/step - loss: 163.9498 - val_loss: 165.2570\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.2571 - val_loss: 163.6814\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.6761 - val_loss: 161.9977\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 159.0493 - val_loss: 160.3167\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 6ms/step - loss: 157.3006 - val_loss: 158.7557\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 3ms/step - loss: 155.7727 - val_loss: 157.0560\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.0989 - val_loss: 155.5180\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.5957 - val_loss: 154.0353\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 151.0151 - val_loss: 152.5974\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 149.5126 - val_loss: 151.2390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 64ms/step - loss: 1574.1893 - val_loss: 1523.3884\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1556.6815 - val_loss: 1506.5538\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1539.6257 - val_loss: 1490.0056\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1522.6189 - val_loss: 1473.3497\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 3ms/step - loss: 1505.5203 - val_loss: 1456.6989\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1488.1078 - val_loss: 1439.7687\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 1470.3499 - val_loss: 1421.9243\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1451.6825 - val_loss: 1403.6619\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1432.4930 - val_loss: 1384.8511\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1412.5719 - val_loss: 1365.4683\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1392.0044 - val_loss: 1345.0546\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1370.4816 - val_loss: 1323.9944\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1348.4056 - val_loss: 1302.4154\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 6ms/step - loss: 1325.6602 - val_loss: 1279.6545\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1301.7622 - val_loss: 1256.5388\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1277.2531 - val_loss: 1232.6565\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 1251.9116 - val_loss: 1207.5979\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 1225.4781 - val_loss: 1181.9087\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1198.7106 - val_loss: 1154.8311\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1170.7396 - val_loss: 1128.1964\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1142.6813 - val_loss: 1100.9856\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1114.5283 - val_loss: 1071.6566\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1084.7336 - val_loss: 1043.2438\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1055.0005 - val_loss: 1014.5486\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1025.2146 - val_loss: 984.3853\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 994.3517 - val_loss: 954.4664\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 963.6271 - val_loss: 924.1892\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 932.5748 - val_loss: 893.7879\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 6ms/step - loss: 901.5952 - val_loss: 862.3705\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 869.9261 - val_loss: 832.6257\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 839.1022 - val_loss: 801.8456\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 808.1827 - val_loss: 771.7339\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 777.7123 - val_loss: 741.8444\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 6ms/step - loss: 747.4660 - val_loss: 712.3918\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 717.5761 - val_loss: 683.5818\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 688.3255 - val_loss: 655.4969\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 659.8341 - val_loss: 627.5765\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 631.8719 - val_loss: 600.7313\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 9ms/step - loss: 605.1136 - val_loss: 574.2620\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 7ms/step - loss: 578.8466 - val_loss: 549.7471\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 553.8266 - val_loss: 525.8322\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 6ms/step - loss: 529.8364 - val_loss: 502.5321\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 506.6926 - val_loss: 480.6856\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 484.8994 - val_loss: 459.2887\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 10ms/step - loss: 463.9816 - val_loss: 439.4659\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 444.4146 - val_loss: 420.4747\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 425.5182 - val_loss: 402.6908\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 407.9177 - val_loss: 386.2380\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 391.4375 - val_loss: 370.2147\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 6ms/step - loss: 375.6985 - val_loss: 355.9395\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 361.3651 - val_loss: 342.2095\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 347.9060 - val_loss: 329.0654\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 3ms/step - loss: 334.9586 - val_loss: 317.5549\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 323.3172 - val_loss: 306.6323\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 312.4172 - val_loss: 296.2750\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 302.1928 - val_loss: 286.8191\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 292.8248 - val_loss: 278.4125\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 284.1770 - val_loss: 270.1726\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 275.9661 - val_loss: 262.9323\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 268.5273 - val_loss: 256.2828\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 261.7019 - val_loss: 249.8489\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 255.2629 - val_loss: 244.1660\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 249.4206 - val_loss: 238.8778\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 243.9194 - val_loss: 234.1834\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 238.9456 - val_loss: 229.8182\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 234.3561 - val_loss: 225.8508\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 229.9418 - val_loss: 222.2272\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 226.0199 - val_loss: 218.7103\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 222.2324 - val_loss: 215.7409\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 218.6976 - val_loss: 212.8551\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 215.4440 - val_loss: 210.2272\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 212.4288 - val_loss: 207.6114\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 7ms/step - loss: 209.4192 - val_loss: 205.4272\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 206.6859 - val_loss: 203.3627\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 204.0766 - val_loss: 201.2042\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 201.5958 - val_loss: 199.3332\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 199.2078 - val_loss: 197.7718\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.0516 - val_loss: 196.1526\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.9304 - val_loss: 194.5569\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.9066 - val_loss: 193.1443\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.0118 - val_loss: 191.7651\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 189.1203 - val_loss: 190.4328\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.3012 - val_loss: 189.0885\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.5678 - val_loss: 187.7431\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.8450 - val_loss: 186.6337\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.1230 - val_loss: 185.4871\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 12ms/step - loss: 180.4780 - val_loss: 184.2695\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.8906 - val_loss: 183.1437\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.2937 - val_loss: 182.0459\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.6836 - val_loss: 180.9351\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.2548 - val_loss: 179.8270\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 3ms/step - loss: 172.7431 - val_loss: 178.6955\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 7ms/step - loss: 171.2550 - val_loss: 177.6745\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.8083 - val_loss: 176.6892\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.3878 - val_loss: 175.6772\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 166.9492 - val_loss: 174.6373\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.6351 - val_loss: 173.6603\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.2256 - val_loss: 172.5638\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.8445 - val_loss: 171.4949\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.4465 - val_loss: 170.4138\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 72ms/step - loss: 1513.6826 - val_loss: 1462.6732\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1495.7377 - val_loss: 1445.3107\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 3ms/step - loss: 1476.9778 - val_loss: 1427.4678\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1458.2175 - val_loss: 1408.6096\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 3ms/step - loss: 1438.3563 - val_loss: 1389.1650\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1417.7577 - val_loss: 1369.2288\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1396.5525 - val_loss: 1347.8369\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1373.9478 - val_loss: 1326.2310\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1350.7893 - val_loss: 1303.1241\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 3ms/step - loss: 1326.2841 - val_loss: 1279.4811\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1301.4233 - val_loss: 1254.4519\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1275.2205 - val_loss: 1228.4758\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1248.1509 - val_loss: 1201.5977\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 3ms/step - loss: 1219.9510 - val_loss: 1173.7438\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 1191.2201 - val_loss: 1145.4753\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 1161.7361 - val_loss: 1116.3240\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1131.8562 - val_loss: 1085.8555\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 3ms/step - loss: 1100.6342 - val_loss: 1055.7666\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1069.5206 - val_loss: 1024.6462\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1037.8674 - val_loss: 993.1124\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1005.9820 - val_loss: 961.4028\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 973.8358 - val_loss: 929.8854\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 941.7549 - val_loss: 898.2681\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 6ms/step - loss: 909.5421 - val_loss: 866.7123\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 877.4920 - val_loss: 834.7523\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 845.0545 - val_loss: 803.5942\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 813.4524 - val_loss: 771.5580\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 781.4451 - val_loss: 741.5580\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 6ms/step - loss: 751.1561 - val_loss: 710.9982\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 720.4906 - val_loss: 681.6637\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 690.8105 - val_loss: 652.9257\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 662.0940 - val_loss: 624.8638\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 633.8226 - val_loss: 597.3925\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 606.8184 - val_loss: 571.0023\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 580.3297 - val_loss: 545.5717\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 554.9529 - val_loss: 521.2497\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 530.6618 - val_loss: 497.6313\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 507.3955 - val_loss: 475.3976\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 485.2679 - val_loss: 454.5036\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 464.3437 - val_loss: 434.3331\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 9ms/step - loss: 444.2099 - val_loss: 415.3431\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 425.5612 - val_loss: 397.4320\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 407.5661 - val_loss: 381.1699\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 3ms/step - loss: 391.2944 - val_loss: 365.3085\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 375.3199 - val_loss: 351.1535\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 360.8701 - val_loss: 337.3904\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 347.0815 - val_loss: 324.5252\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 334.1125 - val_loss: 312.6310\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 322.0831 - val_loss: 301.7084\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 311.2921 - val_loss: 291.2683\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 300.6085 - val_loss: 282.1389\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 291.1632 - val_loss: 273.6012\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 282.2722 - val_loss: 265.7174\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 274.4453 - val_loss: 258.2467\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 266.8715 - val_loss: 251.7739\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 260.1216 - val_loss: 246.0372\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 254.3572 - val_loss: 239.9764\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 248.1410 - val_loss: 235.2425\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 3ms/step - loss: 243.1156 - val_loss: 230.5589\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 238.2583 - val_loss: 226.3126\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 233.8441 - val_loss: 222.2617\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 229.7220 - val_loss: 218.7449\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 226.0027 - val_loss: 215.2026\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 222.3203 - val_loss: 212.2321\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 219.1008 - val_loss: 209.3767\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 7ms/step - loss: 216.0470 - val_loss: 206.6527\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 7ms/step - loss: 213.1683 - val_loss: 203.9340\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 210.4255 - val_loss: 201.5106\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 207.6953 - val_loss: 199.3577\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.2704 - val_loss: 197.0511\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.9590 - val_loss: 195.1527\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.7473 - val_loss: 192.9397\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 6ms/step - loss: 198.4510 - val_loss: 191.0076\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 196.4378 - val_loss: 189.2119\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.4413 - val_loss: 187.4364\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 7ms/step - loss: 192.6059 - val_loss: 185.7366\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 190.8062 - val_loss: 184.1985\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 189.0685 - val_loss: 182.7216\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.3927 - val_loss: 181.2482\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 6ms/step - loss: 185.8251 - val_loss: 179.8939\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.3282 - val_loss: 178.3990\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 10ms/step - loss: 182.7853 - val_loss: 177.1493\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.3928 - val_loss: 175.8750\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.0227 - val_loss: 174.5720\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 3ms/step - loss: 178.7232 - val_loss: 173.2316\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.4725 - val_loss: 172.1622\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.2733 - val_loss: 171.0306\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 6ms/step - loss: 175.0724 - val_loss: 169.8852\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.9252 - val_loss: 168.6997\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.8054 - val_loss: 167.7345\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 171.6230 - val_loss: 166.7200\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.5697 - val_loss: 165.5948\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.5159 - val_loss: 164.6429\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 168.4957 - val_loss: 163.6885\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.4793 - val_loss: 162.8075\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.4593 - val_loss: 161.8142\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.5563 - val_loss: 160.8612\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 3ms/step - loss: 164.5726 - val_loss: 160.0735\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.6591 - val_loss: 159.2165\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.7167 - val_loss: 158.3219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 68ms/step - loss: 1490.2231 - val_loss: 1592.3474\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1473.9971 - val_loss: 1575.6112\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1457.4442 - val_loss: 1558.1024\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1440.1121 - val_loss: 1540.0437\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 6ms/step - loss: 1421.8179 - val_loss: 1521.2018\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1402.7449 - val_loss: 1500.7230\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1382.2330 - val_loss: 1479.2753\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1360.5701 - val_loss: 1456.3821\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 1337.6536 - val_loss: 1432.0532\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1313.0833 - val_loss: 1407.0769\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1287.9200 - val_loss: 1379.4482\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1260.6949 - val_loss: 1351.6528\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1232.7058 - val_loss: 1322.7649\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 6ms/step - loss: 1203.7987 - val_loss: 1291.6763\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 1173.3309 - val_loss: 1260.2721\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1142.5330 - val_loss: 1227.8040\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1110.4467 - val_loss: 1195.7169\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1078.5857 - val_loss: 1161.8594\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1045.7938 - val_loss: 1127.6410\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 1012.4439 - val_loss: 1092.6090\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 979.0963 - val_loss: 1057.8057\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 945.3431 - val_loss: 1023.0824\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 911.6339 - val_loss: 988.3052\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 877.9549 - val_loss: 953.5534\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 844.7015 - val_loss: 918.8419\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 812.0390 - val_loss: 883.6958\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 779.0712 - val_loss: 850.1161\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 747.3864 - val_loss: 816.7412\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 716.2884 - val_loss: 783.1357\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 685.4216 - val_loss: 751.8557\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 656.4398 - val_loss: 720.6354\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 627.7209 - val_loss: 690.6664\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 600.2868 - val_loss: 660.8844\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 573.6386 - val_loss: 631.8013\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 547.4976 - val_loss: 604.8779\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 523.0649 - val_loss: 578.1321\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 499.6199 - val_loss: 552.2396\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 477.1159 - val_loss: 527.8675\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 455.3922 - val_loss: 505.7010\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 435.2644 - val_loss: 483.3345\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 415.7632 - val_loss: 461.4209\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 7ms/step - loss: 397.3733 - val_loss: 440.7824\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 9ms/step - loss: 379.9312 - val_loss: 421.7579\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 363.5408 - val_loss: 404.1776\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 348.2746 - val_loss: 387.3901\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 334.2469 - val_loss: 370.8492\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 320.6261 - val_loss: 356.2680\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 308.3366 - val_loss: 341.7104\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 296.4802 - val_loss: 328.9064\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 286.0136 - val_loss: 316.0472\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 6ms/step - loss: 275.7721 - val_loss: 304.5948\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 3ms/step - loss: 266.2254 - val_loss: 294.5780\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 258.0260 - val_loss: 283.9426\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 6ms/step - loss: 249.8373 - val_loss: 274.7570\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 242.4939 - val_loss: 266.4276\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 9ms/step - loss: 235.7795 - val_loss: 258.5101\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 229.4900 - val_loss: 251.4018\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 223.7931 - val_loss: 244.7400\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 218.3894 - val_loss: 238.6082\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 213.5012 - val_loss: 233.0836\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 208.9724 - val_loss: 227.7823\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 204.9169 - val_loss: 222.9579\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 201.1160 - val_loss: 218.5297\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.5606 - val_loss: 214.6160\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.4555 - val_loss: 210.8984\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.4706 - val_loss: 207.5478\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 188.7223 - val_loss: 204.8826\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 7ms/step - loss: 186.2740 - val_loss: 202.0945\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.0660 - val_loss: 199.4152\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 181.8974 - val_loss: 197.1531\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.9867 - val_loss: 195.0060\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.1122 - val_loss: 193.0541\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.3552 - val_loss: 191.3532\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 7ms/step - loss: 174.8355 - val_loss: 189.4477\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.2218 - val_loss: 187.8220\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 171.8546 - val_loss: 186.3056\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.4413 - val_loss: 184.8142\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.1402 - val_loss: 183.3194\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 7ms/step - loss: 167.8913 - val_loss: 182.0155\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.5939 - val_loss: 180.8823\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 3ms/step - loss: 165.3519 - val_loss: 179.6869\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.1883 - val_loss: 178.3467\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.0252 - val_loss: 177.1576\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.9370 - val_loss: 175.8864\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 11ms/step - loss: 160.8294 - val_loss: 174.8125\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.8102 - val_loss: 173.6254\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 3ms/step - loss: 158.6953 - val_loss: 172.8241\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.7521 - val_loss: 171.7462\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.6888 - val_loss: 170.8481\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.6050 - val_loss: 169.8400\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 154.6120 - val_loss: 168.9253\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.6035 - val_loss: 167.9986\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.6034 - val_loss: 167.0825\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 7ms/step - loss: 151.6053 - val_loss: 166.1533\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.6579 - val_loss: 165.4148\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 7ms/step - loss: 149.6893 - val_loss: 164.5310\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 6ms/step - loss: 148.7216 - val_loss: 163.7415\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.8134 - val_loss: 162.7543\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 146.8330 - val_loss: 161.9446\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 145.9026 - val_loss: 161.2265\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 72ms/step - loss: 1565.1461 - val_loss: 1579.3430\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1547.0557 - val_loss: 1561.4932\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1529.7590 - val_loss: 1544.1519\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1513.0161 - val_loss: 1527.6346\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1496.8542 - val_loss: 1511.7406\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1481.1807 - val_loss: 1495.8021\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 1465.4108 - val_loss: 1479.9304\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1449.8179 - val_loss: 1464.1349\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1434.0885 - val_loss: 1448.1812\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1418.1859 - val_loss: 1432.1600\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1402.1010 - val_loss: 1415.9863\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1385.8004 - val_loss: 1399.3301\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1368.7864 - val_loss: 1382.4320\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1351.6514 - val_loss: 1364.8523\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 1334.0808 - val_loss: 1346.5552\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 3ms/step - loss: 1315.7507 - val_loss: 1327.8917\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 3ms/step - loss: 1296.8179 - val_loss: 1308.9670\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1277.3679 - val_loss: 1289.2877\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1257.2694 - val_loss: 1268.5095\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1236.5818 - val_loss: 1246.7467\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1214.8037 - val_loss: 1224.8920\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1192.5745 - val_loss: 1202.1106\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 1169.6272 - val_loss: 1178.8107\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 1146.1718 - val_loss: 1154.6949\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1121.9952 - val_loss: 1129.9377\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 1097.5426 - val_loss: 1104.4677\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 3ms/step - loss: 1071.9979 - val_loss: 1079.1111\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 1046.7272 - val_loss: 1052.9955\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 1021.1351 - val_loss: 1026.4452\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 994.7977 - val_loss: 1000.2426\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 969.0419 - val_loss: 973.0465\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 942.5054 - val_loss: 946.3719\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 6ms/step - loss: 916.1638 - val_loss: 919.4153\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 889.5047 - val_loss: 892.3334\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 862.3637 - val_loss: 865.1963\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 835.4139 - val_loss: 837.0954\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 807.7631 - val_loss: 809.0717\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 779.9368 - val_loss: 781.0892\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 752.4111 - val_loss: 753.0110\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 725.2473 - val_loss: 724.8466\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 697.7664 - val_loss: 697.6831\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 671.2451 - val_loss: 670.8848\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 645.3404 - val_loss: 644.3913\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 3ms/step - loss: 620.2518 - val_loss: 618.9279\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 595.6747 - val_loss: 595.0582\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 572.3524 - val_loss: 571.5613\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 11ms/step - loss: 549.6387 - val_loss: 549.2320\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 528.1580 - val_loss: 527.1593\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 507.2899 - val_loss: 506.6438\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 3ms/step - loss: 487.5913 - val_loss: 487.0297\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 468.7864 - val_loss: 468.2755\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 450.9336 - val_loss: 450.7930\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 434.0358 - val_loss: 434.4885\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 6ms/step - loss: 418.5782 - val_loss: 418.3777\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 3ms/step - loss: 403.4341 - val_loss: 403.6360\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 389.3141 - val_loss: 390.1749\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 376.3496 - val_loss: 377.1278\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 364.0375 - val_loss: 365.0465\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 352.6775 - val_loss: 353.2837\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 341.7503 - val_loss: 343.0026\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 332.0640 - val_loss: 332.6201\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 322.5369 - val_loss: 323.5114\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 313.9613 - val_loss: 314.6180\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 305.8151 - val_loss: 306.6044\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 298.3050 - val_loss: 299.2389\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 291.3479 - val_loss: 291.7358\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 284.6474 - val_loss: 285.4664\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 278.7029 - val_loss: 279.2014\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 273.0587 - val_loss: 273.3733\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 267.7475 - val_loss: 267.7475\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 262.5969 - val_loss: 262.6057\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 3ms/step - loss: 258.0602 - val_loss: 257.4719\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 253.4183 - val_loss: 253.2320\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 249.2715 - val_loss: 248.6924\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 245.2404 - val_loss: 244.5582\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 241.5179 - val_loss: 240.4943\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 237.8463 - val_loss: 236.6022\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 234.4007 - val_loss: 233.0364\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 231.1728 - val_loss: 229.4588\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 228.0321 - val_loss: 225.9571\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 3ms/step - loss: 224.9330 - val_loss: 223.0401\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 222.1725 - val_loss: 219.9272\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 219.4694 - val_loss: 216.9449\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 216.8614 - val_loss: 214.2435\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 214.2886 - val_loss: 211.2920\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 3ms/step - loss: 211.9357 - val_loss: 208.7130\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 209.5123 - val_loss: 206.3634\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 10ms/step - loss: 207.2958 - val_loss: 203.8102\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 205.0420 - val_loss: 201.2726\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 202.8320 - val_loss: 198.9456\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 7ms/step - loss: 200.5880 - val_loss: 196.6285\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 198.4348 - val_loss: 194.5339\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 196.3713 - val_loss: 192.2472\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.3226 - val_loss: 190.0448\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.3277 - val_loss: 188.1648\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.3643 - val_loss: 186.0426\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.4261 - val_loss: 184.0301\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.5953 - val_loss: 182.3263\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.7532 - val_loss: 180.3904\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.0078 - val_loss: 178.4031\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 64ms/step - loss: 1495.8138 - val_loss: 1534.3860\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1476.1761 - val_loss: 1514.8418\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1456.0865 - val_loss: 1494.9128\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1435.4570 - val_loss: 1474.5883\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1414.1913 - val_loss: 1453.6062\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 3ms/step - loss: 1392.2755 - val_loss: 1431.9269\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1369.5950 - val_loss: 1409.5070\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1346.3066 - val_loss: 1386.4637\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 1322.1969 - val_loss: 1362.7402\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 1297.2250 - val_loss: 1338.0045\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 3ms/step - loss: 1271.3293 - val_loss: 1312.4316\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1244.5120 - val_loss: 1286.0056\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 1216.4755 - val_loss: 1259.6464\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1188.3385 - val_loss: 1231.5280\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1158.9670 - val_loss: 1203.3251\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 3ms/step - loss: 1129.2793 - val_loss: 1174.3446\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 1099.3186 - val_loss: 1144.9139\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 3ms/step - loss: 1068.7391 - val_loss: 1115.0880\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1037.6589 - val_loss: 1084.8291\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1006.2867 - val_loss: 1054.1901\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 974.9584 - val_loss: 1023.0420\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 943.2764 - val_loss: 992.5627\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 911.9995 - val_loss: 961.4579\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 880.7178 - val_loss: 930.8362\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 849.5527 - val_loss: 900.0550\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 818.9870 - val_loss: 869.5616\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 788.4235 - val_loss: 840.3491\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 758.8608 - val_loss: 810.7351\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 729.3837 - val_loss: 781.5171\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 700.5193 - val_loss: 753.5134\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 672.7057 - val_loss: 725.4930\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 645.4022 - val_loss: 698.8704\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 619.3069 - val_loss: 672.6434\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 593.7697 - val_loss: 647.5875\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 569.2506 - val_loss: 623.2989\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 546.0245 - val_loss: 599.4283\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 523.3179 - val_loss: 576.9574\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 501.6878 - val_loss: 555.6289\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 7ms/step - loss: 481.5795 - val_loss: 534.4915\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 461.9163 - val_loss: 514.6277\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 443.5730 - val_loss: 496.1567\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 426.4143 - val_loss: 478.2545\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 10ms/step - loss: 410.4024 - val_loss: 460.8516\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 394.8232 - val_loss: 445.0445\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 380.5759 - val_loss: 430.0158\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 367.4846 - val_loss: 415.6193\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 354.9924 - val_loss: 402.7476\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 343.6431 - val_loss: 390.3134\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 333.1254 - val_loss: 378.4755\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 323.1893 - val_loss: 367.6149\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 313.9999 - val_loss: 357.5571\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 305.6606 - val_loss: 348.0308\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 6ms/step - loss: 297.9933 - val_loss: 339.0988\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 290.8685 - val_loss: 330.8611\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 9ms/step - loss: 284.2322 - val_loss: 323.3492\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 278.3681 - val_loss: 316.0033\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 6ms/step - loss: 272.8282 - val_loss: 309.4092\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 267.7050 - val_loss: 303.5134\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 262.9966 - val_loss: 297.4333\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 6ms/step - loss: 258.5599 - val_loss: 291.5065\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 254.2664 - val_loss: 286.6338\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 250.6346 - val_loss: 281.7064\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 247.0667 - val_loss: 277.2092\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 243.7605 - val_loss: 272.8504\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 240.7636 - val_loss: 268.6221\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 237.7645 - val_loss: 265.1115\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 234.9917 - val_loss: 261.4138\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 232.3470 - val_loss: 258.2304\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 229.8769 - val_loss: 254.5902\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 227.3566 - val_loss: 251.5636\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 225.0522 - val_loss: 248.2514\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 222.6439 - val_loss: 245.4087\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 220.4630 - val_loss: 242.6434\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 218.3293 - val_loss: 239.8376\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 216.1792 - val_loss: 237.1611\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 214.0692 - val_loss: 234.6640\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 212.0732 - val_loss: 231.9364\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 210.1764 - val_loss: 229.3613\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 208.1470 - val_loss: 227.0899\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.2209 - val_loss: 224.5566\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 204.2639 - val_loss: 222.1680\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 6ms/step - loss: 202.3911 - val_loss: 219.9167\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.4860 - val_loss: 217.5974\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 198.6003 - val_loss: 215.2814\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 11ms/step - loss: 196.7606 - val_loss: 213.2752\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 6ms/step - loss: 194.9324 - val_loss: 211.1830\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 193.1378 - val_loss: 208.8258\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.3176 - val_loss: 206.7929\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 6ms/step - loss: 189.5459 - val_loss: 204.5561\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.7522 - val_loss: 202.6797\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.0199 - val_loss: 200.5701\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.3343 - val_loss: 198.6453\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 182.5457 - val_loss: 196.7098\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.9119 - val_loss: 194.8350\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.1205 - val_loss: 192.8381\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.4917 - val_loss: 190.9690\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 175.7884 - val_loss: 189.0141\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.1335 - val_loss: 187.2633\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.4602 - val_loss: 185.3407\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.8027 - val_loss: 183.4674\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 75ms/step - loss: 1629.2252 - val_loss: 1440.3766\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1615.5782 - val_loss: 1427.7745\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1602.1229 - val_loss: 1415.0541\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1588.6678 - val_loss: 1402.0891\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1574.9690 - val_loss: 1388.9012\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1561.0149 - val_loss: 1375.1471\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1546.4457 - val_loss: 1360.9073\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1531.4324 - val_loss: 1345.8907\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1515.7509 - val_loss: 1330.4175\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 1499.3761 - val_loss: 1314.1339\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 1482.2678 - val_loss: 1297.0468\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1464.3197 - val_loss: 1279.0740\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1445.6044 - val_loss: 1260.1707\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1426.1290 - val_loss: 1240.4673\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1405.3804 - val_loss: 1220.2579\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1384.0454 - val_loss: 1198.4188\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 1361.3378 - val_loss: 1175.8750\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1337.4750 - val_loss: 1151.9537\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1312.1434 - val_loss: 1127.5178\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1285.5863 - val_loss: 1101.5320\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1257.0977 - val_loss: 1073.9897\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1226.3903 - val_loss: 1044.6932\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1193.7924 - val_loss: 1013.3456\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1158.9818 - val_loss: 981.1632\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 9ms/step - loss: 1122.5603 - val_loss: 948.5605\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 1085.0975 - val_loss: 914.7120\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 1046.1118 - val_loss: 880.4452\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 1006.4063 - val_loss: 845.8514\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 965.7681 - val_loss: 811.5667\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 925.3499 - val_loss: 776.8356\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 7ms/step - loss: 884.6926 - val_loss: 742.6080\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 844.5392 - val_loss: 708.6549\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 7ms/step - loss: 804.5983 - val_loss: 676.0814\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 765.9424 - val_loss: 643.8165\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 728.4698 - val_loss: 612.4064\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 691.3875 - val_loss: 582.7024\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 656.4391 - val_loss: 553.4075\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 622.5446 - val_loss: 525.3049\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 588.8351 - val_loss: 498.9486\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 557.2045 - val_loss: 473.3755\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 526.7917 - val_loss: 449.0898\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 498.0319 - val_loss: 425.5557\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 470.1625 - val_loss: 404.3600\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 444.7709 - val_loss: 383.3496\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 420.1424 - val_loss: 364.2263\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 10ms/step - loss: 397.5700 - val_loss: 346.3061\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 3ms/step - loss: 376.4138 - val_loss: 329.6673\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 6ms/step - loss: 356.8708 - val_loss: 314.2191\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 338.9176 - val_loss: 300.3590\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 322.9789 - val_loss: 287.2120\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 3ms/step - loss: 307.9179 - val_loss: 275.4345\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 294.4435 - val_loss: 264.9419\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 282.4681 - val_loss: 254.9482\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 271.4126 - val_loss: 246.2583\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 261.7589 - val_loss: 238.0068\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 3ms/step - loss: 252.5231 - val_loss: 230.9662\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 244.8617 - val_loss: 224.3221\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 237.3790 - val_loss: 218.4858\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 231.1173 - val_loss: 212.6775\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 225.0944 - val_loss: 207.6222\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 219.6975 - val_loss: 203.4560\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 215.1099 - val_loss: 199.1683\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 210.9312 - val_loss: 195.2145\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 206.8851 - val_loss: 192.2947\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 203.3204 - val_loss: 189.1458\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 199.9075 - val_loss: 186.3767\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 196.8909 - val_loss: 183.5845\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 3ms/step - loss: 194.0520 - val_loss: 180.7989\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 6ms/step - loss: 191.1962 - val_loss: 178.7246\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.5900 - val_loss: 176.6829\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.2460 - val_loss: 174.5367\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 3ms/step - loss: 183.8568 - val_loss: 172.6061\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 181.6999 - val_loss: 170.6415\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.5833 - val_loss: 168.8782\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 7ms/step - loss: 177.5746 - val_loss: 167.0038\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.7836 - val_loss: 165.3517\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.7934 - val_loss: 164.0014\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.0819 - val_loss: 162.6196\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.3439 - val_loss: 161.0952\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 168.6964 - val_loss: 159.9157\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 3ms/step - loss: 167.1477 - val_loss: 158.4289\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.4504 - val_loss: 157.0779\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.9559 - val_loss: 156.0751\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.4480 - val_loss: 154.8403\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.0508 - val_loss: 153.6485\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.6643 - val_loss: 152.6189\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 158.4133 - val_loss: 151.3979\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 10ms/step - loss: 157.0383 - val_loss: 150.3531\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.8572 - val_loss: 149.4861\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 6ms/step - loss: 154.5399 - val_loss: 148.5797\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.3255 - val_loss: 147.6160\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.1860 - val_loss: 146.6145\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 3ms/step - loss: 151.0638 - val_loss: 145.6566\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 149.9576 - val_loss: 144.6767\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 7ms/step - loss: 148.8291 - val_loss: 143.8956\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 147.8294 - val_loss: 143.2047\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 146.7028 - val_loss: 142.1283\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 145.5988 - val_loss: 141.2832\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 144.6707 - val_loss: 140.6033\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 143.5475 - val_loss: 139.6208\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 68ms/step - loss: 1576.5201 - val_loss: 1691.5035\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1561.2854 - val_loss: 1676.8850\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1546.8638 - val_loss: 1662.7527\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1533.0214 - val_loss: 1649.2068\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1519.6168 - val_loss: 1636.0386\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1506.5067 - val_loss: 1622.9926\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1493.4460 - val_loss: 1609.9515\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1480.2397 - val_loss: 1596.8093\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 7ms/step - loss: 1466.6934 - val_loss: 1583.3674\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1452.6396 - val_loss: 1569.5354\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1438.1321 - val_loss: 1554.9225\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 8ms/step - loss: 1422.6519 - val_loss: 1539.1755\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 1405.9554 - val_loss: 1522.8539\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1388.5546 - val_loss: 1504.8275\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1369.6400 - val_loss: 1486.3479\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1349.9562 - val_loss: 1466.3372\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 7ms/step - loss: 1329.0491 - val_loss: 1445.3019\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1307.0696 - val_loss: 1423.2002\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1283.8613 - val_loss: 1400.3523\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1260.1791 - val_loss: 1375.8988\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 6ms/step - loss: 1235.4559 - val_loss: 1351.4050\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1210.1354 - val_loss: 1325.7872\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1184.4636 - val_loss: 1299.2869\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1157.9541 - val_loss: 1272.6082\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1131.1510 - val_loss: 1245.3956\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 6ms/step - loss: 1104.1078 - val_loss: 1217.3744\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 1076.3716 - val_loss: 1189.3943\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 1048.8156 - val_loss: 1160.5228\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 1020.9828 - val_loss: 1131.3523\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 9ms/step - loss: 992.7120 - val_loss: 1101.6876\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 964.4923 - val_loss: 1071.8429\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 936.2667 - val_loss: 1041.3650\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 3ms/step - loss: 907.9371 - val_loss: 1011.4981\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 879.7172 - val_loss: 981.5861\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 851.9946 - val_loss: 950.3386\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 7ms/step - loss: 823.7599 - val_loss: 919.9673\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 796.0305 - val_loss: 890.1679\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 768.9880 - val_loss: 860.3867\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 742.3837 - val_loss: 830.7688\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 716.3915 - val_loss: 801.8307\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 9ms/step - loss: 690.6783 - val_loss: 773.6140\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 665.6064 - val_loss: 745.1534\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 641.1091 - val_loss: 717.2018\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 617.3713 - val_loss: 690.1464\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 10ms/step - loss: 594.1543 - val_loss: 663.8540\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 571.3832 - val_loss: 638.0347\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 549.1435 - val_loss: 613.5966\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 528.0238 - val_loss: 588.8384\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 507.3601 - val_loss: 565.0009\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 487.2093 - val_loss: 542.5565\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 468.0945 - val_loss: 520.7658\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 449.2842 - val_loss: 499.7333\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 431.4169 - val_loss: 478.7871\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 413.7558 - val_loss: 459.1904\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 396.9492 - val_loss: 441.4691\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 381.2866 - val_loss: 423.4928\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 365.9833 - val_loss: 406.3979\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 351.2068 - val_loss: 390.2042\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 337.4445 - val_loss: 374.3834\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 324.3254 - val_loss: 359.8092\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 311.9635 - val_loss: 346.2517\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 300.3669 - val_loss: 333.7223\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 289.4990 - val_loss: 321.8592\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 279.2480 - val_loss: 310.7347\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 269.9505 - val_loss: 300.0110\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 260.8075 - val_loss: 290.4065\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 252.4712 - val_loss: 281.5710\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 244.8006 - val_loss: 273.1704\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 237.7045 - val_loss: 265.4787\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 230.9350 - val_loss: 258.4040\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 224.8317 - val_loss: 251.9444\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 219.1623 - val_loss: 245.9740\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 214.0321 - val_loss: 240.5392\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 6ms/step - loss: 209.2330 - val_loss: 235.8696\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 204.9731 - val_loss: 231.1459\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.8592 - val_loss: 227.0454\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.1053 - val_loss: 223.5022\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 193.7199 - val_loss: 220.1043\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 190.6855 - val_loss: 216.8543\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.6917 - val_loss: 214.0572\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.1091 - val_loss: 211.2356\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.5763 - val_loss: 208.7473\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.3030 - val_loss: 206.5085\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.1593 - val_loss: 204.4520\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.1301 - val_loss: 202.2982\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.2445 - val_loss: 200.4686\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 12ms/step - loss: 172.4235 - val_loss: 198.7550\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.7369 - val_loss: 197.1556\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 3ms/step - loss: 169.2202 - val_loss: 195.5657\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 3ms/step - loss: 167.6191 - val_loss: 194.2089\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.2698 - val_loss: 192.8189\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.9323 - val_loss: 191.4574\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 6ms/step - loss: 163.5801 - val_loss: 190.1858\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.4296 - val_loss: 188.9534\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 3ms/step - loss: 161.1674 - val_loss: 187.7682\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.9616 - val_loss: 186.6378\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.8467 - val_loss: 185.5741\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.8079 - val_loss: 184.4289\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.7217 - val_loss: 183.3377\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.6724 - val_loss: 182.2977\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 85ms/step - loss: 1514.5863 - val_loss: 1644.8555\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 6ms/step - loss: 1498.0164 - val_loss: 1627.5664\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1481.4221 - val_loss: 1609.5902\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1464.6141 - val_loss: 1590.6437\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 3ms/step - loss: 1446.7875 - val_loss: 1571.0153\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1427.9912 - val_loss: 1549.6626\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1407.5596 - val_loss: 1527.4468\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1386.2938 - val_loss: 1502.8600\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1363.2148 - val_loss: 1477.3420\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1338.8767 - val_loss: 1450.4832\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1313.2173 - val_loss: 1422.1914\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1286.4341 - val_loss: 1392.4579\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1258.2400 - val_loss: 1361.6600\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1228.9919 - val_loss: 1329.3630\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 6ms/step - loss: 1198.7640 - val_loss: 1296.5109\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1167.5687 - val_loss: 1262.2296\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 3ms/step - loss: 1135.7266 - val_loss: 1227.3324\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1103.0760 - val_loss: 1191.9930\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1070.1670 - val_loss: 1156.0457\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1036.5181 - val_loss: 1121.0789\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1003.2815 - val_loss: 1085.4847\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 970.0106 - val_loss: 1047.8922\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 936.0704 - val_loss: 1011.6224\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 902.7982 - val_loss: 974.5923\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 869.3381 - val_loss: 938.3265\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 836.3068 - val_loss: 902.9860\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 3ms/step - loss: 804.1509 - val_loss: 866.9046\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 771.8821 - val_loss: 832.8655\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 740.7195 - val_loss: 798.6909\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 709.9866 - val_loss: 765.2720\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 680.4537 - val_loss: 732.8835\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 6ms/step - loss: 651.3392 - val_loss: 701.5143\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 623.7298 - val_loss: 670.8929\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 596.5234 - val_loss: 642.0187\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 571.0276 - val_loss: 613.3002\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 546.3468 - val_loss: 586.4110\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 522.8391 - val_loss: 560.6003\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 500.5305 - val_loss: 536.6680\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 8ms/step - loss: 479.6350 - val_loss: 513.5334\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 459.6217 - val_loss: 491.4295\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 440.4984 - val_loss: 470.6205\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 422.6394 - val_loss: 451.2663\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 405.8773 - val_loss: 432.9706\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 389.9837 - val_loss: 416.3392\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 375.6062 - val_loss: 400.2657\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 10ms/step - loss: 361.7473 - val_loss: 385.4294\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 11ms/step - loss: 348.8198 - val_loss: 372.0262\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 336.9307 - val_loss: 359.0783\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 325.8198 - val_loss: 346.9593\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 315.4160 - val_loss: 335.8145\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 305.6644 - val_loss: 325.7862\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 296.7639 - val_loss: 316.1520\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 288.3662 - val_loss: 307.4478\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 280.5609 - val_loss: 299.2247\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 273.3069 - val_loss: 291.5984\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 266.3030 - val_loss: 284.7016\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 260.1888 - val_loss: 278.1881\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 254.2441 - val_loss: 272.2800\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 248.9249 - val_loss: 266.4480\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 243.6312 - val_loss: 261.1855\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 238.7084 - val_loss: 256.2656\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 234.2383 - val_loss: 251.6646\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 229.8489 - val_loss: 247.2564\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 225.7554 - val_loss: 243.1683\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 221.9544 - val_loss: 239.5706\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 3ms/step - loss: 218.3308 - val_loss: 235.7043\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 214.7830 - val_loss: 232.1937\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 211.4681 - val_loss: 228.8740\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 208.2699 - val_loss: 225.8816\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 205.1991 - val_loss: 223.0205\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 202.2762 - val_loss: 220.2726\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 8ms/step - loss: 199.5206 - val_loss: 217.5413\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 196.8063 - val_loss: 214.9764\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.2924 - val_loss: 212.4156\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.8895 - val_loss: 209.9907\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 6ms/step - loss: 189.4172 - val_loss: 207.7682\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.1569 - val_loss: 205.5267\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.8739 - val_loss: 203.3123\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.6951 - val_loss: 201.1570\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.6179 - val_loss: 199.1678\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 6ms/step - loss: 178.6399 - val_loss: 197.1152\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.6926 - val_loss: 195.0355\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.7643 - val_loss: 193.1362\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.9096 - val_loss: 191.2003\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.1813 - val_loss: 189.4111\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.5069 - val_loss: 187.6449\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.7201 - val_loss: 185.9331\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 10ms/step - loss: 166.1185 - val_loss: 184.2444\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.6020 - val_loss: 182.6549\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.0117 - val_loss: 181.1876\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.6306 - val_loss: 179.7866\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.2431 - val_loss: 178.2392\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 158.9481 - val_loss: 176.8844\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.7863 - val_loss: 175.4488\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.5388 - val_loss: 174.2354\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.3677 - val_loss: 173.0448\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 154.2928 - val_loss: 171.8396\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.2297 - val_loss: 170.4948\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 3ms/step - loss: 152.1222 - val_loss: 169.2923\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 151.0471 - val_loss: 168.1194\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 63ms/step - loss: 1558.0383 - val_loss: 1696.0403\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 3ms/step - loss: 1541.8458 - val_loss: 1678.5521\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1526.3363 - val_loss: 1662.0149\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1511.8510 - val_loss: 1645.8893\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1497.6542 - val_loss: 1630.1373\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1483.6620 - val_loss: 1614.4030\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1469.9537 - val_loss: 1598.3345\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1455.8575 - val_loss: 1582.3524\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1441.5581 - val_loss: 1565.8295\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 1426.7206 - val_loss: 1548.8293\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1411.2788 - val_loss: 1530.7595\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1395.0930 - val_loss: 1511.7933\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1378.0995 - val_loss: 1491.6941\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1360.0214 - val_loss: 1471.1333\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 3ms/step - loss: 1341.2163 - val_loss: 1449.0439\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1321.1388 - val_loss: 1425.9772\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1300.2941 - val_loss: 1401.0210\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1277.9690 - val_loss: 1375.0659\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1254.1532 - val_loss: 1348.0897\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1229.1328 - val_loss: 1319.0555\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 9ms/step - loss: 1202.9052 - val_loss: 1288.3926\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 1174.7373 - val_loss: 1257.0880\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1145.8184 - val_loss: 1224.1992\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 6ms/step - loss: 1115.7552 - val_loss: 1190.3401\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1084.9666 - val_loss: 1155.6559\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 1053.4739 - val_loss: 1120.0260\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 1021.8099 - val_loss: 1083.8944\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 989.2443 - val_loss: 1049.0609\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 957.2731 - val_loss: 1013.7036\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 924.8873 - val_loss: 977.7386\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 892.6732 - val_loss: 942.3861\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 860.2993 - val_loss: 906.9912\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 828.5076 - val_loss: 872.4147\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 797.5292 - val_loss: 838.3536\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 6ms/step - loss: 766.9114 - val_loss: 804.7161\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 7ms/step - loss: 736.6902 - val_loss: 772.8043\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 707.4874 - val_loss: 741.3553\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 678.9798 - val_loss: 710.3842\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 650.9484 - val_loss: 681.1624\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 624.3504 - val_loss: 652.0862\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 6ms/step - loss: 598.0817 - val_loss: 624.2867\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 572.8463 - val_loss: 597.6504\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 3ms/step - loss: 548.4030 - val_loss: 572.4911\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 10ms/step - loss: 525.6049 - val_loss: 547.1754\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 502.9309 - val_loss: 523.6755\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 481.6101 - val_loss: 501.2478\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 461.3125 - val_loss: 479.7424\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 442.0896 - val_loss: 459.3516\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 423.5477 - val_loss: 439.9901\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 406.0371 - val_loss: 421.7590\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 389.5948 - val_loss: 404.3857\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 373.9702 - val_loss: 388.0070\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 359.1031 - val_loss: 372.8849\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 345.2580 - val_loss: 358.0728\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 332.5028 - val_loss: 343.9153\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 320.0515 - val_loss: 331.5748\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 308.7418 - val_loss: 319.7941\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 298.0801 - val_loss: 308.4936\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 287.9954 - val_loss: 298.1722\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 6ms/step - loss: 278.7161 - val_loss: 288.3877\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 269.8844 - val_loss: 279.1911\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 6ms/step - loss: 261.8306 - val_loss: 270.7339\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 254.3770 - val_loss: 262.4856\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 247.4316 - val_loss: 254.9887\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 240.8674 - val_loss: 248.1517\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 234.9732 - val_loss: 241.9261\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 229.5386 - val_loss: 235.9310\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 224.4875 - val_loss: 230.6382\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 219.8986 - val_loss: 225.6461\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.8144 - val_loss: 220.8022\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 211.7334 - val_loss: 216.6870\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 208.2607 - val_loss: 212.7722\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 204.9610 - val_loss: 209.1693\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 8ms/step - loss: 201.9252 - val_loss: 205.9324\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 199.1068 - val_loss: 202.8108\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 196.4923 - val_loss: 199.8870\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.0882 - val_loss: 197.2987\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.9447 - val_loss: 194.8690\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 189.9285 - val_loss: 192.6774\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 7ms/step - loss: 188.0000 - val_loss: 190.7590\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.2430 - val_loss: 188.7927\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.6463 - val_loss: 186.8008\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.0034 - val_loss: 185.1987\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 181.5502 - val_loss: 183.5888\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.2466 - val_loss: 182.0534\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 12ms/step - loss: 178.8666 - val_loss: 180.6556\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 3ms/step - loss: 177.6641 - val_loss: 179.2983\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.5004 - val_loss: 177.8745\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.3314 - val_loss: 176.6420\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.2620 - val_loss: 175.4823\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 3ms/step - loss: 173.2611 - val_loss: 174.3484\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.1944 - val_loss: 173.3382\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.2770 - val_loss: 172.1640\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.2963 - val_loss: 171.2329\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.5116 - val_loss: 170.2334\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 3ms/step - loss: 168.5377 - val_loss: 169.2963\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.6046 - val_loss: 168.4078\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.8120 - val_loss: 167.5617\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.9080 - val_loss: 166.6512\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.1288 - val_loss: 165.9785\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 1599.5337 - val_loss: 1389.7467\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1584.1554 - val_loss: 1375.8256\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 3ms/step - loss: 1568.8456 - val_loss: 1361.8223\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 3ms/step - loss: 1553.2148 - val_loss: 1347.4730\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 3ms/step - loss: 1537.1205 - val_loss: 1332.6410\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1520.3945 - val_loss: 1317.2928\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 1502.8593 - val_loss: 1301.5013\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 3ms/step - loss: 1484.5830 - val_loss: 1284.5986\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1464.9188 - val_loss: 1266.5574\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1443.9895 - val_loss: 1247.1736\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 3ms/step - loss: 1421.4064 - val_loss: 1226.5784\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 1397.0408 - val_loss: 1204.2025\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 1370.8861 - val_loss: 1180.2070\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1342.8464 - val_loss: 1155.0261\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 3ms/step - loss: 1312.7621 - val_loss: 1128.4576\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1281.5500 - val_loss: 1100.2660\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1248.7261 - val_loss: 1070.7736\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1214.0519 - val_loss: 1040.7091\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1178.7067 - val_loss: 1010.0632\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1142.7078 - val_loss: 978.5161\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 3ms/step - loss: 1105.5010 - val_loss: 946.6833\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1068.6670 - val_loss: 914.4316\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1030.6392 - val_loss: 882.0150\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 993.2218 - val_loss: 849.3292\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 955.1578 - val_loss: 817.1815\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 917.8006 - val_loss: 785.1617\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 880.5491 - val_loss: 753.2488\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 843.7872 - val_loss: 722.4332\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 807.8179 - val_loss: 691.5651\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 772.6982 - val_loss: 662.2347\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 3ms/step - loss: 739.0763 - val_loss: 632.8142\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 705.6812 - val_loss: 604.7178\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 673.3136 - val_loss: 577.8931\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 642.7114 - val_loss: 551.3204\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 612.8604 - val_loss: 526.6187\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 584.8869 - val_loss: 502.0751\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 557.5493 - val_loss: 479.3843\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 532.1511 - val_loss: 457.3727\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 507.5100 - val_loss: 436.8461\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 484.5907 - val_loss: 417.4557\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 463.2163 - val_loss: 399.1305\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 443.0042 - val_loss: 381.8656\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 423.9883 - val_loss: 365.9206\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 406.3693 - val_loss: 350.9017\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 389.6447 - val_loss: 337.0742\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 12ms/step - loss: 374.2139 - val_loss: 323.7764\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 359.6499 - val_loss: 311.5248\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 346.3643 - val_loss: 299.9458\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 333.6697 - val_loss: 289.6295\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 322.3882 - val_loss: 279.6025\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 311.3013 - val_loss: 270.7990\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 301.4209 - val_loss: 262.4286\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 291.9081 - val_loss: 254.6167\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 283.2479 - val_loss: 247.2702\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 275.0911 - val_loss: 240.5014\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 3ms/step - loss: 267.2026 - val_loss: 234.4417\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 260.2091 - val_loss: 228.4058\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 6ms/step - loss: 253.2651 - val_loss: 222.8017\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 246.7201 - val_loss: 217.8487\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 3ms/step - loss: 240.9823 - val_loss: 213.1880\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 235.2707 - val_loss: 209.1328\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 230.2032 - val_loss: 205.1418\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 225.4443 - val_loss: 201.5041\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 220.9163 - val_loss: 198.2989\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 216.8586 - val_loss: 195.4200\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 213.1842 - val_loss: 192.6757\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 209.5128 - val_loss: 190.2625\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 206.3584 - val_loss: 188.0479\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 3ms/step - loss: 203.2419 - val_loss: 186.0288\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 9ms/step - loss: 200.4635 - val_loss: 184.2119\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.7985 - val_loss: 182.5751\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 3ms/step - loss: 195.1562 - val_loss: 181.0273\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.8884 - val_loss: 179.5255\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 7ms/step - loss: 190.6466 - val_loss: 178.1547\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.6223 - val_loss: 177.0570\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.5878 - val_loss: 175.9081\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 7ms/step - loss: 184.7341 - val_loss: 174.8876\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.9670 - val_loss: 173.9392\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 3ms/step - loss: 181.2121 - val_loss: 173.0789\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.5382 - val_loss: 172.0968\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 3ms/step - loss: 177.9217 - val_loss: 171.3184\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.2814 - val_loss: 170.5329\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.8090 - val_loss: 169.6814\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 3ms/step - loss: 173.3303 - val_loss: 168.9117\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 171.8873 - val_loss: 168.1461\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.5119 - val_loss: 167.3339\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.1414 - val_loss: 166.5839\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 9ms/step - loss: 167.8572 - val_loss: 165.8743\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.6138 - val_loss: 165.2478\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.3461 - val_loss: 164.5552\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.2056 - val_loss: 163.9259\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.0968 - val_loss: 163.2931\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.0739 - val_loss: 162.7590\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.0390 - val_loss: 162.1498\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 6ms/step - loss: 160.1417 - val_loss: 161.5772\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.1618 - val_loss: 160.7986\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.1929 - val_loss: 160.1295\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 6ms/step - loss: 157.2565 - val_loss: 159.6883\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.3853 - val_loss: 159.1796\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.6361 - val_loss: 158.5539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 67ms/step - loss: 1559.5186 - val_loss: 1503.6420\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1541.8901 - val_loss: 1487.1776\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1525.3207 - val_loss: 1471.1047\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1509.0479 - val_loss: 1455.3607\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1492.9324 - val_loss: 1439.7460\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1476.8398 - val_loss: 1423.8379\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 7ms/step - loss: 1460.3007 - val_loss: 1407.8207\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1443.2194 - val_loss: 1391.1365\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 1425.4795 - val_loss: 1373.5839\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1406.6699 - val_loss: 1355.2814\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1387.3247 - val_loss: 1335.7445\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 1366.6001 - val_loss: 1315.3240\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1344.8850 - val_loss: 1294.0291\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 3ms/step - loss: 1322.2478 - val_loss: 1271.8511\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1298.6383 - val_loss: 1248.5192\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 1273.6759 - val_loss: 1224.3817\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 1247.8553 - val_loss: 1199.4193\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 3ms/step - loss: 1221.4221 - val_loss: 1173.0188\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 3ms/step - loss: 1193.3765 - val_loss: 1146.3589\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 3ms/step - loss: 1164.8799 - val_loss: 1118.9723\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1135.3792 - val_loss: 1090.5806\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 1105.1206 - val_loss: 1061.4885\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1074.5537 - val_loss: 1032.1279\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 1043.4688 - val_loss: 1002.5243\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1012.5236 - val_loss: 972.1667\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 3ms/step - loss: 980.9532 - val_loss: 941.9866\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 949.4471 - val_loss: 911.8407\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 917.7289 - val_loss: 881.5670\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 3ms/step - loss: 886.4041 - val_loss: 851.4135\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 3ms/step - loss: 855.3175 - val_loss: 821.5856\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 824.4356 - val_loss: 792.3041\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 794.2489 - val_loss: 763.1473\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 3ms/step - loss: 764.2775 - val_loss: 734.7457\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 734.8760 - val_loss: 706.7755\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 3ms/step - loss: 706.3972 - val_loss: 678.7699\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 678.3416 - val_loss: 651.5466\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 650.8652 - val_loss: 625.4877\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 3ms/step - loss: 624.6107 - val_loss: 599.8064\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 3ms/step - loss: 598.3507 - val_loss: 574.9804\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 573.6628 - val_loss: 550.2879\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 549.2808 - val_loss: 526.6851\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 10ms/step - loss: 525.7689 - val_loss: 503.6926\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 503.1533 - val_loss: 481.5999\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 481.5436 - val_loss: 459.7783\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 460.2077 - val_loss: 439.2806\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 439.9388 - val_loss: 419.0158\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 420.3532 - val_loss: 399.1338\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 401.2540 - val_loss: 380.8482\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 3ms/step - loss: 383.1597 - val_loss: 363.1189\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 3ms/step - loss: 366.0452 - val_loss: 345.6998\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 349.3409 - val_loss: 329.6027\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 3ms/step - loss: 333.8430 - val_loss: 314.2659\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 319.0703 - val_loss: 299.9737\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 305.2937 - val_loss: 286.3245\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 3ms/step - loss: 292.1702 - val_loss: 274.2433\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 3ms/step - loss: 280.3440 - val_loss: 262.6571\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 268.8752 - val_loss: 252.5129\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 258.6638 - val_loss: 242.7616\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 3ms/step - loss: 249.1111 - val_loss: 233.9528\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 240.6089 - val_loss: 225.6961\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 232.4419 - val_loss: 219.0154\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 225.3483 - val_loss: 212.3854\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 3ms/step - loss: 218.6420 - val_loss: 206.6357\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 212.6430 - val_loss: 201.3383\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 207.0866 - val_loss: 196.7192\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 3ms/step - loss: 202.0214 - val_loss: 192.6188\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.7178 - val_loss: 188.6592\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 3ms/step - loss: 193.5760 - val_loss: 185.5381\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 190.0155 - val_loss: 182.7054\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.6034 - val_loss: 180.0553\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 183.6055 - val_loss: 177.8785\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.7892 - val_loss: 175.8388\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.4178 - val_loss: 173.8986\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.8990 - val_loss: 172.2690\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 3ms/step - loss: 173.8457 - val_loss: 170.9095\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 9ms/step - loss: 171.7982 - val_loss: 169.4752\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.0388 - val_loss: 168.1962\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 3ms/step - loss: 168.2392 - val_loss: 166.9991\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.6673 - val_loss: 166.0600\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.2148 - val_loss: 165.0060\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.7577 - val_loss: 164.0315\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.4105 - val_loss: 163.2145\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.1238 - val_loss: 162.3854\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 11ms/step - loss: 159.8891 - val_loss: 161.5639\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 6ms/step - loss: 158.8025 - val_loss: 160.8806\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 3ms/step - loss: 157.7103 - val_loss: 160.0750\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.5772 - val_loss: 159.4121\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.5541 - val_loss: 158.7201\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 7ms/step - loss: 154.5502 - val_loss: 158.1402\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.6895 - val_loss: 157.4706\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.7118 - val_loss: 156.7811\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 151.7497 - val_loss: 156.0902\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.9287 - val_loss: 155.3853\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.0322 - val_loss: 154.8087\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 6ms/step - loss: 149.1962 - val_loss: 154.0638\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 148.3513 - val_loss: 153.5667\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 147.4557 - val_loss: 152.9176\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 146.5939 - val_loss: 152.3676\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 145.7305 - val_loss: 151.8246\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 144.8674 - val_loss: 151.2113\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 67ms/step - loss: 1568.1042 - val_loss: 1543.0474\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1551.9167 - val_loss: 1526.4761\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 1535.6323 - val_loss: 1510.3131\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 3ms/step - loss: 1519.7726 - val_loss: 1493.6549\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1503.3784 - val_loss: 1476.9058\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1486.4836 - val_loss: 1459.8181\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1469.0479 - val_loss: 1442.2355\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 3ms/step - loss: 1451.2388 - val_loss: 1423.5400\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1432.6608 - val_loss: 1404.5923\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 6ms/step - loss: 1413.4675 - val_loss: 1384.7889\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 6ms/step - loss: 1393.5863 - val_loss: 1364.2872\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 6ms/step - loss: 1372.4661 - val_loss: 1343.9487\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 6ms/step - loss: 1351.1000 - val_loss: 1321.4512\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1328.2245 - val_loss: 1298.8567\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 3ms/step - loss: 1304.7006 - val_loss: 1275.6001\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1280.1528 - val_loss: 1250.9215\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1254.7100 - val_loss: 1225.2349\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 6ms/step - loss: 1228.0135 - val_loss: 1199.1790\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 3ms/step - loss: 1200.6841 - val_loss: 1172.2230\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1172.3440 - val_loss: 1144.2686\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 3ms/step - loss: 1143.4601 - val_loss: 1115.5630\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1113.2441 - val_loss: 1086.0900\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 1082.2123 - val_loss: 1055.1886\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 6ms/step - loss: 1050.1326 - val_loss: 1024.0200\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1017.7964 - val_loss: 991.4893\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 984.2675 - val_loss: 959.2737\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 950.9688 - val_loss: 925.0826\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 3ms/step - loss: 915.9986 - val_loss: 891.5660\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 881.5801 - val_loss: 857.0014\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 846.4201 - val_loss: 822.4832\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 811.5212 - val_loss: 787.4021\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 776.1295 - val_loss: 753.8412\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 3ms/step - loss: 741.8051 - val_loss: 718.6525\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 707.4479 - val_loss: 685.0043\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 673.6031 - val_loss: 652.6027\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 640.8368 - val_loss: 620.9136\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 609.6995 - val_loss: 589.4219\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 7ms/step - loss: 578.9907 - val_loss: 560.1078\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 549.9451 - val_loss: 531.0822\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 521.9649 - val_loss: 503.7516\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 495.6624 - val_loss: 478.1014\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 470.9724 - val_loss: 453.6565\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 3ms/step - loss: 448.0658 - val_loss: 430.5048\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 426.0156 - val_loss: 409.9357\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 406.2328 - val_loss: 390.4830\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 12ms/step - loss: 387.7532 - val_loss: 372.0814\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 370.4979 - val_loss: 354.9024\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 354.8411 - val_loss: 339.2995\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 340.4550 - val_loss: 324.7581\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 327.2760 - val_loss: 311.8313\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 315.2579 - val_loss: 299.8885\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 304.2036 - val_loss: 288.7537\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 294.1240 - val_loss: 278.7105\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 285.0138 - val_loss: 269.4902\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 276.6162 - val_loss: 261.1425\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 269.1566 - val_loss: 253.0887\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 262.2078 - val_loss: 246.1332\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 3ms/step - loss: 255.8258 - val_loss: 239.7004\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 250.1266 - val_loss: 233.8930\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 6ms/step - loss: 244.7078 - val_loss: 228.7619\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 239.8641 - val_loss: 223.8803\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 3ms/step - loss: 235.4061 - val_loss: 219.2248\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 231.0988 - val_loss: 214.9059\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 227.0917 - val_loss: 211.3051\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 223.5778 - val_loss: 207.1650\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 219.9983 - val_loss: 204.0545\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 3ms/step - loss: 216.8896 - val_loss: 200.6841\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 213.8483 - val_loss: 197.8336\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 7ms/step - loss: 211.0852 - val_loss: 195.0431\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 208.4202 - val_loss: 192.4993\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 205.9239 - val_loss: 190.2614\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 3ms/step - loss: 203.5565 - val_loss: 187.8563\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 201.2738 - val_loss: 185.6306\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 199.1024 - val_loss: 183.6098\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 7ms/step - loss: 196.9098 - val_loss: 181.6302\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.9485 - val_loss: 179.6789\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.8324 - val_loss: 177.8603\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 190.9799 - val_loss: 176.1426\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 189.0892 - val_loss: 174.4857\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.3867 - val_loss: 172.8765\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.5566 - val_loss: 171.4371\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 183.9768 - val_loss: 169.9560\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.3035 - val_loss: 168.5658\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.6994 - val_loss: 167.1589\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.1502 - val_loss: 165.9460\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 3ms/step - loss: 177.7449 - val_loss: 164.7147\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 12ms/step - loss: 176.1338 - val_loss: 163.4558\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.6969 - val_loss: 162.3293\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.3474 - val_loss: 161.2840\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 171.8481 - val_loss: 159.9867\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.4573 - val_loss: 158.8197\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.1523 - val_loss: 157.8929\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.8740 - val_loss: 156.8045\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.6060 - val_loss: 155.6772\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.2362 - val_loss: 154.7576\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.0221 - val_loss: 153.8259\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.8308 - val_loss: 152.8292\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.6211 - val_loss: 151.8569\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 3ms/step - loss: 160.4404 - val_loss: 150.9238\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.3267 - val_loss: 150.1193\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 78ms/step - loss: 1521.1398 - val_loss: 1700.1167\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1503.7417 - val_loss: 1682.0453\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 3ms/step - loss: 1486.4095 - val_loss: 1664.5166\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1469.2117 - val_loss: 1646.7762\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1451.7744 - val_loss: 1629.2634\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 6ms/step - loss: 1434.3063 - val_loss: 1610.8806\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1416.1632 - val_loss: 1592.6907\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 3ms/step - loss: 1397.7369 - val_loss: 1573.6989\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1378.6321 - val_loss: 1553.7062\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1358.7405 - val_loss: 1533.2031\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1338.4828 - val_loss: 1511.6805\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 1317.1760 - val_loss: 1490.0685\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 1295.6774 - val_loss: 1467.3777\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1273.4309 - val_loss: 1443.9865\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1250.5282 - val_loss: 1420.5858\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1227.2190 - val_loss: 1396.1595\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1203.2990 - val_loss: 1370.8582\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1179.0060 - val_loss: 1345.1356\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1154.0756 - val_loss: 1319.1294\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 9ms/step - loss: 1128.9469 - val_loss: 1293.0768\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 1103.8787 - val_loss: 1265.6726\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1078.0468 - val_loss: 1238.3174\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 3ms/step - loss: 1051.9092 - val_loss: 1210.9543\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1025.8322 - val_loss: 1183.0768\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 3ms/step - loss: 999.6920 - val_loss: 1155.2498\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 973.5376 - val_loss: 1127.0848\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 947.4404 - val_loss: 1098.9796\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 921.1373 - val_loss: 1071.3610\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 6ms/step - loss: 895.2817 - val_loss: 1042.8871\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 3ms/step - loss: 868.9864 - val_loss: 1015.1164\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 843.3896 - val_loss: 986.8782\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 817.8428 - val_loss: 959.1852\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 792.6106 - val_loss: 932.4265\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 768.0049 - val_loss: 904.7253\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 3ms/step - loss: 742.9346 - val_loss: 877.9152\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 718.4957 - val_loss: 850.7823\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 694.1740 - val_loss: 823.2969\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 8ms/step - loss: 670.0242 - val_loss: 796.4509\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 646.3706 - val_loss: 769.3335\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 622.6675 - val_loss: 743.4183\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 599.9421 - val_loss: 716.6295\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 576.6924 - val_loss: 690.5517\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 6ms/step - loss: 554.3100 - val_loss: 664.5079\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 532.2971 - val_loss: 638.7948\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 510.8160 - val_loss: 613.8615\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 12ms/step - loss: 489.7244 - val_loss: 589.0729\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 469.2639 - val_loss: 565.4296\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 449.7414 - val_loss: 541.7050\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 430.6654 - val_loss: 519.0649\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 6ms/step - loss: 412.3742 - val_loss: 497.4809\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 394.8837 - val_loss: 476.9640\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 3ms/step - loss: 378.4905 - val_loss: 456.7254\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 362.6731 - val_loss: 437.4651\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 347.7856 - val_loss: 418.9655\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 8ms/step - loss: 333.8510 - val_loss: 401.7865\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 320.6401 - val_loss: 385.4626\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 308.4809 - val_loss: 369.7698\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 297.0726 - val_loss: 355.3328\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 286.5983 - val_loss: 341.9068\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 276.9642 - val_loss: 329.4251\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 267.9855 - val_loss: 318.0089\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 259.8976 - val_loss: 307.1521\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 252.5100 - val_loss: 296.9971\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 245.6451 - val_loss: 287.9679\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 239.5186 - val_loss: 279.6211\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 233.9012 - val_loss: 271.6182\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 228.7473 - val_loss: 264.1755\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 223.8737 - val_loss: 258.0915\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 219.8757 - val_loss: 251.7851\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 215.9891 - val_loss: 246.4425\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 212.4953 - val_loss: 241.4413\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 209.2487 - val_loss: 237.1581\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 206.3743 - val_loss: 233.0795\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 203.6821 - val_loss: 229.1023\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 201.1115 - val_loss: 225.1957\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 198.6774 - val_loss: 222.3296\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 196.5729 - val_loss: 218.9977\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.5765 - val_loss: 216.0393\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.4759 - val_loss: 213.7640\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 190.6958 - val_loss: 211.0218\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.9303 - val_loss: 208.6169\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.3543 - val_loss: 206.5294\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.8022 - val_loss: 204.4416\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.2896 - val_loss: 202.3129\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 7ms/step - loss: 182.8954 - val_loss: 200.7347\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 181.4081 - val_loss: 198.9125\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.1107 - val_loss: 197.2099\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 12ms/step - loss: 178.7775 - val_loss: 195.4921\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.4553 - val_loss: 193.8909\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.2014 - val_loss: 192.4521\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 6ms/step - loss: 174.9477 - val_loss: 190.9534\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.6817 - val_loss: 189.5703\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.4525 - val_loss: 188.1252\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 171.2187 - val_loss: 186.5700\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 6ms/step - loss: 169.9536 - val_loss: 185.3153\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.6826 - val_loss: 183.9693\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 9ms/step - loss: 167.4695 - val_loss: 182.4582\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.2600 - val_loss: 181.2262\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 6ms/step - loss: 164.9948 - val_loss: 179.6820\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.8456 - val_loss: 178.8302\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 68ms/step - loss: 1524.4717 - val_loss: 1565.8494\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1508.9001 - val_loss: 1550.9546\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1492.9370 - val_loss: 1535.5116\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1476.3417 - val_loss: 1519.6465\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1459.0829 - val_loss: 1503.0354\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1440.9862 - val_loss: 1485.5393\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1421.8717 - val_loss: 1467.3782\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1402.2773 - val_loss: 1447.3665\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1380.7373 - val_loss: 1427.4353\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1358.8533 - val_loss: 1405.8446\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 1335.5485 - val_loss: 1383.1724\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1311.4987 - val_loss: 1359.4580\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 1286.0292 - val_loss: 1335.0526\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1259.4723 - val_loss: 1309.6521\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1232.0348 - val_loss: 1282.7739\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 1203.4347 - val_loss: 1254.4761\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1173.3711 - val_loss: 1225.8148\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1142.6255 - val_loss: 1195.3741\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1110.6351 - val_loss: 1164.1704\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 1077.7064 - val_loss: 1132.7622\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 1044.5913 - val_loss: 1100.4661\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1010.9338 - val_loss: 1067.0317\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 976.0558 - val_loss: 1033.5698\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 941.2356 - val_loss: 999.9825\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 906.1136 - val_loss: 965.9498\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 870.9210 - val_loss: 931.4107\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 835.8761 - val_loss: 896.8301\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 800.6962 - val_loss: 863.0667\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 6ms/step - loss: 766.3075 - val_loss: 829.0740\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 7ms/step - loss: 731.9192 - val_loss: 795.4683\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 7ms/step - loss: 698.4223 - val_loss: 762.6042\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 665.5059 - val_loss: 730.1019\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 633.3272 - val_loss: 698.2958\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 7ms/step - loss: 601.6495 - val_loss: 668.0952\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 571.8006 - val_loss: 637.7572\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 542.4195 - val_loss: 609.0898\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 3ms/step - loss: 514.4974 - val_loss: 580.8157\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 487.4111 - val_loss: 554.5626\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 462.5249 - val_loss: 528.7111\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 438.1096 - val_loss: 505.4246\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 415.9594 - val_loss: 482.0809\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 394.6852 - val_loss: 461.1522\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 375.3316 - val_loss: 440.4149\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 356.9005 - val_loss: 421.9172\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 340.2871 - val_loss: 404.1991\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 324.7098 - val_loss: 388.4853\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 310.7924 - val_loss: 373.6240\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 12ms/step - loss: 297.9565 - val_loss: 359.3156\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 286.2655 - val_loss: 346.3471\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 275.5089 - val_loss: 334.7629\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 266.0927 - val_loss: 323.6842\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 257.2603 - val_loss: 313.8518\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 249.4310 - val_loss: 304.5318\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 242.2804 - val_loss: 296.3399\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 9ms/step - loss: 235.9237 - val_loss: 288.5731\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 230.1003 - val_loss: 281.6271\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 224.8923 - val_loss: 275.2698\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 220.3033 - val_loss: 269.3487\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 216.0777 - val_loss: 264.0287\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 212.3409 - val_loss: 258.8228\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 208.7045 - val_loss: 254.5045\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 205.5471 - val_loss: 250.2329\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 202.6561 - val_loss: 246.3274\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 200.0777 - val_loss: 242.3954\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.5283 - val_loss: 239.6893\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 195.1886 - val_loss: 236.3238\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 193.0754 - val_loss: 233.0968\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 190.9961 - val_loss: 230.6359\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.1846 - val_loss: 227.8665\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.4498 - val_loss: 225.5826\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.7797 - val_loss: 223.5103\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.2643 - val_loss: 221.4191\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 7ms/step - loss: 182.7798 - val_loss: 219.2496\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 181.3299 - val_loss: 217.3090\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.9481 - val_loss: 215.3657\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.6208 - val_loss: 213.6247\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.3011 - val_loss: 211.8043\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 3ms/step - loss: 176.1194 - val_loss: 210.1479\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 174.7960 - val_loss: 208.5904\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.5996 - val_loss: 207.0362\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 3ms/step - loss: 172.4844 - val_loss: 205.5838\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 171.3317 - val_loss: 203.8000\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.2538 - val_loss: 202.6160\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.2261 - val_loss: 201.3409\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.3064 - val_loss: 200.1475\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.2065 - val_loss: 198.4449\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.1846 - val_loss: 197.2193\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.1954 - val_loss: 195.8873\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.1779 - val_loss: 194.5899\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 10ms/step - loss: 163.2207 - val_loss: 193.3820\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.2265 - val_loss: 192.1901\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.3089 - val_loss: 190.8801\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.3521 - val_loss: 189.8610\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 3ms/step - loss: 159.5254 - val_loss: 188.7101\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.5548 - val_loss: 187.5656\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 3ms/step - loss: 157.6850 - val_loss: 186.3391\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.8222 - val_loss: 185.2808\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.0849 - val_loss: 184.1959\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.2101 - val_loss: 183.3647\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 3ms/step - loss: 154.4602 - val_loss: 182.1537\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 1476.4369 - val_loss: 1587.0974\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 17ms/step - loss: 1459.2944 - val_loss: 1568.2172\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1441.0419 - val_loss: 1548.5920\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1422.1528 - val_loss: 1527.4795\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1402.2167 - val_loss: 1504.9858\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 9ms/step - loss: 1380.9071 - val_loss: 1481.9153\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1359.0303 - val_loss: 1457.3405\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1336.1337 - val_loss: 1431.3784\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1311.9700 - val_loss: 1404.2780\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1286.2277 - val_loss: 1376.3160\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1259.8252 - val_loss: 1346.7751\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1232.1243 - val_loss: 1315.6075\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1202.8578 - val_loss: 1283.8606\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 3ms/step - loss: 1173.0715 - val_loss: 1250.5480\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1142.0925 - val_loss: 1215.6903\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1109.8807 - val_loss: 1180.5732\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1076.8555 - val_loss: 1144.5975\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1042.8318 - val_loss: 1108.5665\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1008.6133 - val_loss: 1070.7573\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 973.4893 - val_loss: 1032.9025\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 938.3637 - val_loss: 994.6307\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 902.4544 - val_loss: 956.9875\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 867.1707 - val_loss: 918.0287\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 831.5947 - val_loss: 879.5756\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 796.3337 - val_loss: 841.5731\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 761.2399 - val_loss: 804.1606\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 726.5605 - val_loss: 767.7375\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 692.8315 - val_loss: 731.3367\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 659.4110 - val_loss: 696.1742\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 3ms/step - loss: 627.0005 - val_loss: 661.9925\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 595.2978 - val_loss: 629.9165\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 565.2501 - val_loss: 598.1702\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 535.8763 - val_loss: 567.6949\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 508.0555 - val_loss: 538.8756\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 481.3432 - val_loss: 512.3769\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 456.4016 - val_loss: 487.3808\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 433.2549 - val_loss: 463.3659\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 410.9108 - val_loss: 441.3865\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 390.2106 - val_loss: 420.6817\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 370.7993 - val_loss: 401.6443\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 352.8893 - val_loss: 383.9728\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 336.0018 - val_loss: 367.7965\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 320.8010 - val_loss: 352.8062\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 306.4735 - val_loss: 339.4819\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 293.5719 - val_loss: 326.5762\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 281.5518 - val_loss: 314.7934\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 12ms/step - loss: 270.3282 - val_loss: 304.2905\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 260.2867 - val_loss: 294.6281\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 251.1246 - val_loss: 285.8690\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 7ms/step - loss: 242.8229 - val_loss: 277.8493\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 234.9978 - val_loss: 270.6172\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 228.0274 - val_loss: 263.8932\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 221.4078 - val_loss: 257.7394\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.4802 - val_loss: 251.8679\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 209.9850 - val_loss: 246.5892\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 204.9312 - val_loss: 241.9205\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.5087 - val_loss: 237.4191\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 196.2350 - val_loss: 233.5723\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.4689 - val_loss: 229.5567\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.7249 - val_loss: 226.0963\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.5316 - val_loss: 222.8003\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.5187 - val_loss: 219.7970\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.7490 - val_loss: 217.2553\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.2519 - val_loss: 214.5319\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.8474 - val_loss: 211.9949\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.6575 - val_loss: 209.7044\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.6205 - val_loss: 207.6037\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 168.7837 - val_loss: 205.5474\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.9486 - val_loss: 203.7859\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.3878 - val_loss: 201.7957\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.7836 - val_loss: 200.3301\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.3692 - val_loss: 198.5442\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.9718 - val_loss: 197.0483\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.6197 - val_loss: 195.4785\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.3993 - val_loss: 194.0440\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.2151 - val_loss: 192.7270\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 8ms/step - loss: 156.1186 - val_loss: 191.3465\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.0215 - val_loss: 190.3038\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 154.0109 - val_loss: 189.0639\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 3ms/step - loss: 153.0227 - val_loss: 187.9611\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.0371 - val_loss: 186.7970\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 3ms/step - loss: 151.1074 - val_loss: 185.7260\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 6ms/step - loss: 150.2061 - val_loss: 184.6158\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 149.5038 - val_loss: 183.9486\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 148.5981 - val_loss: 182.7607\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 147.8032 - val_loss: 181.8935\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 147.1378 - val_loss: 180.7599\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 7ms/step - loss: 146.3537 - val_loss: 179.9574\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 10ms/step - loss: 145.6473 - val_loss: 179.1151\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 144.9805 - val_loss: 178.2715\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 7ms/step - loss: 144.3431 - val_loss: 177.5958\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 143.7486 - val_loss: 176.8183\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 143.0424 - val_loss: 176.1385\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 142.5285 - val_loss: 175.4465\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 6ms/step - loss: 141.8800 - val_loss: 174.6340\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.3390 - val_loss: 173.8967\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 3ms/step - loss: 140.7652 - val_loss: 173.2607\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 140.3350 - val_loss: 172.7692\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 139.7066 - val_loss: 172.2630\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 139.1404 - val_loss: 171.7348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 73ms/step - loss: 1541.9906 - val_loss: 1490.4200\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1527.0912 - val_loss: 1475.8458\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 1512.2388 - val_loss: 1460.5618\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1496.5870 - val_loss: 1444.5594\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1479.7992 - val_loss: 1427.5477\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1462.0199 - val_loss: 1408.7969\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1442.4631 - val_loss: 1389.0723\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1422.1011 - val_loss: 1367.5461\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1399.6096 - val_loss: 1345.1277\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1376.0294 - val_loss: 1320.9205\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 8ms/step - loss: 1350.7292 - val_loss: 1295.7660\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 6ms/step - loss: 1324.3557 - val_loss: 1268.8845\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1296.3872 - val_loss: 1241.3835\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 6ms/step - loss: 1267.7063 - val_loss: 1212.3069\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1237.5902 - val_loss: 1182.3281\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1206.3247 - val_loss: 1151.8942\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 6ms/step - loss: 1174.5338 - val_loss: 1119.9666\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1141.6875 - val_loss: 1087.6742\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1107.9424 - val_loss: 1054.9769\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 1073.8491 - val_loss: 1021.2451\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1039.1793 - val_loss: 988.5585\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1005.0854 - val_loss: 954.6333\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 970.3102 - val_loss: 921.0151\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 935.5446 - val_loss: 887.5635\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 901.0720 - val_loss: 854.3618\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 6ms/step - loss: 866.5508 - val_loss: 821.9709\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 832.3649 - val_loss: 789.3304\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 3ms/step - loss: 798.9352 - val_loss: 757.0637\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 765.7782 - val_loss: 726.0143\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 6ms/step - loss: 733.6605 - val_loss: 695.5394\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 701.9980 - val_loss: 666.2678\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 3ms/step - loss: 671.5038 - val_loss: 637.3597\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 641.7710 - val_loss: 609.8484\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 612.9033 - val_loss: 583.5590\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 6ms/step - loss: 585.4146 - val_loss: 557.6473\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 3ms/step - loss: 558.7848 - val_loss: 533.1384\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 533.2230 - val_loss: 509.7454\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 508.9843 - val_loss: 487.7786\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 486.0780 - val_loss: 466.5646\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 464.2048 - val_loss: 446.8521\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 443.5177 - val_loss: 428.0967\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 423.9232 - val_loss: 410.5472\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 405.1789 - val_loss: 394.3861\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 11ms/step - loss: 388.4208 - val_loss: 378.3321\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 371.8538 - val_loss: 364.7878\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 357.1540 - val_loss: 351.2340\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 342.9482 - val_loss: 339.0156\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 329.8610 - val_loss: 327.3932\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 317.5206 - val_loss: 316.8167\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 306.4209 - val_loss: 306.5502\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 295.9415 - val_loss: 297.5492\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 286.3248 - val_loss: 289.2710\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 277.4447 - val_loss: 281.5266\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 269.2954 - val_loss: 274.2234\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 261.4833 - val_loss: 267.8065\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 254.7812 - val_loss: 261.5428\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 248.2268 - val_loss: 256.0559\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 242.4307 - val_loss: 251.0348\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 237.2114 - val_loss: 246.0994\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 232.0582 - val_loss: 241.8806\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 3ms/step - loss: 227.5740 - val_loss: 237.6860\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 223.1395 - val_loss: 234.0495\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 219.3595 - val_loss: 230.2982\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 215.6158 - val_loss: 226.9624\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 212.2312 - val_loss: 223.9351\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 209.0309 - val_loss: 221.2616\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 206.1738 - val_loss: 218.7363\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 203.6480 - val_loss: 216.2825\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 201.1955 - val_loss: 214.0237\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 198.8318 - val_loss: 211.9959\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.8305 - val_loss: 209.9544\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.7545 - val_loss: 208.1164\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.8510 - val_loss: 206.3863\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.0394 - val_loss: 204.7541\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 189.4191 - val_loss: 203.1182\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.9094 - val_loss: 201.6097\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.2540 - val_loss: 200.2247\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.8677 - val_loss: 198.7554\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.4427 - val_loss: 197.4294\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.1201 - val_loss: 196.0255\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.7693 - val_loss: 194.7432\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 179.4699 - val_loss: 193.5501\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.2695 - val_loss: 192.3609\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.0018 - val_loss: 191.1137\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 9ms/step - loss: 175.8496 - val_loss: 190.0135\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.7251 - val_loss: 188.8685\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 6ms/step - loss: 173.6700 - val_loss: 187.6843\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.5638 - val_loss: 186.5157\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 171.4625 - val_loss: 185.5293\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.4651 - val_loss: 184.4386\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.4762 - val_loss: 183.4299\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.6100 - val_loss: 182.4101\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.5744 - val_loss: 181.4651\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.6631 - val_loss: 180.4919\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.7670 - val_loss: 179.5818\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.9810 - val_loss: 178.8498\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.1165 - val_loss: 178.0212\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 3ms/step - loss: 163.3951 - val_loss: 177.2535\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.6279 - val_loss: 176.5219\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.8616 - val_loss: 175.6154\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 67ms/step - loss: 1553.0516 - val_loss: 1489.9945\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1536.0789 - val_loss: 1473.3889\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1518.6617 - val_loss: 1455.9774\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1500.4401 - val_loss: 1437.9445\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1481.1117 - val_loss: 1419.4156\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1461.0696 - val_loss: 1399.6772\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1439.8973 - val_loss: 1378.9141\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1417.4541 - val_loss: 1357.3190\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 1394.3086 - val_loss: 1334.6129\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1369.6368 - val_loss: 1310.8071\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1343.9742 - val_loss: 1286.3313\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 3ms/step - loss: 1317.5723 - val_loss: 1261.0262\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1289.9640 - val_loss: 1234.7019\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1261.7235 - val_loss: 1206.9332\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 1231.7360 - val_loss: 1179.1481\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1201.5981 - val_loss: 1150.2137\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1170.2893 - val_loss: 1120.6984\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1138.4840 - val_loss: 1091.1803\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1106.7876 - val_loss: 1061.0409\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1074.3811 - val_loss: 1030.6685\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 1041.7560 - val_loss: 1000.3722\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 8ms/step - loss: 1009.0059 - val_loss: 969.6489\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 975.8754 - val_loss: 939.6392\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 942.9415 - val_loss: 908.2642\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 909.3820 - val_loss: 877.6607\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 876.1452 - val_loss: 846.7131\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 843.0300 - val_loss: 815.6607\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 809.7092 - val_loss: 785.2155\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 777.2143 - val_loss: 754.3999\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 744.6185 - val_loss: 724.6036\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 3ms/step - loss: 712.6763 - val_loss: 695.2386\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 681.5562 - val_loss: 666.8545\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 651.8579 - val_loss: 638.4126\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 622.2700 - val_loss: 612.2484\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 594.5474 - val_loss: 586.4657\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 567.3019 - val_loss: 562.2726\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 541.7891 - val_loss: 538.4453\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 517.2810 - val_loss: 515.2817\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 493.3415 - val_loss: 494.3026\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 471.2102 - val_loss: 473.7979\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 449.7419 - val_loss: 454.4787\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 429.7269 - val_loss: 435.6052\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 410.3866 - val_loss: 418.0742\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 392.0893 - val_loss: 401.5276\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 11ms/step - loss: 375.1845 - val_loss: 385.3814\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 359.0683 - val_loss: 370.2285\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 343.7259 - val_loss: 356.2584\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 329.8826 - val_loss: 342.9492\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 6ms/step - loss: 316.7382 - val_loss: 330.5710\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 304.5865 - val_loss: 319.1790\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 293.2884 - val_loss: 308.3526\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 282.6906 - val_loss: 298.1176\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 272.9361 - val_loss: 288.4497\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 7ms/step - loss: 263.6581 - val_loss: 279.8608\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 255.3578 - val_loss: 271.1620\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 247.4206 - val_loss: 263.4645\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 240.1728 - val_loss: 256.2874\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 233.4533 - val_loss: 249.9248\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 227.3545 - val_loss: 243.6096\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 221.4540 - val_loss: 237.7318\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 216.0587 - val_loss: 232.0929\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 211.0533 - val_loss: 226.8635\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 7ms/step - loss: 206.3649 - val_loss: 222.4558\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 202.2283 - val_loss: 217.9410\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 198.2836 - val_loss: 213.8341\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.7310 - val_loss: 209.7332\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.1303 - val_loss: 206.2662\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.9557 - val_loss: 202.8534\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.0668 - val_loss: 199.5696\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.1920 - val_loss: 196.5667\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.5367 - val_loss: 193.7771\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.1401 - val_loss: 191.0253\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 174.8104 - val_loss: 188.4627\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 6ms/step - loss: 172.6721 - val_loss: 186.0469\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.6407 - val_loss: 183.8686\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.7330 - val_loss: 181.4801\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.8073 - val_loss: 179.6191\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 3ms/step - loss: 165.1098 - val_loss: 177.7327\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.6017 - val_loss: 175.8421\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.0236 - val_loss: 174.3173\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.6544 - val_loss: 172.4735\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 159.2450 - val_loss: 170.8841\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.9179 - val_loss: 169.5005\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.7099 - val_loss: 168.0670\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.5539 - val_loss: 166.5702\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 154.3461 - val_loss: 165.1996\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 11ms/step - loss: 153.2287 - val_loss: 163.8715\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 6ms/step - loss: 152.2481 - val_loss: 162.5424\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.1754 - val_loss: 161.5716\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.2796 - val_loss: 160.4331\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 6ms/step - loss: 149.3155 - val_loss: 159.5126\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 3ms/step - loss: 148.3626 - val_loss: 158.3052\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.6788 - val_loss: 156.9608\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 3ms/step - loss: 146.5376 - val_loss: 156.1256\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 3ms/step - loss: 145.7629 - val_loss: 155.3150\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.0098 - val_loss: 154.4975\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.1723 - val_loss: 153.6314\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 143.3755 - val_loss: 152.6778\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.7416 - val_loss: 151.8319\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 141.9704 - val_loss: 151.0139\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 1604.2574 - val_loss: 1512.4879\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 14ms/step - loss: 1587.7968 - val_loss: 1497.1204\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1572.2355 - val_loss: 1482.3000\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1557.2732 - val_loss: 1468.1030\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1542.7010 - val_loss: 1454.2898\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1528.3572 - val_loss: 1440.7504\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1513.9912 - val_loss: 1426.6090\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1498.9625 - val_loss: 1412.2070\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1483.3478 - val_loss: 1396.9802\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 3ms/step - loss: 1466.9044 - val_loss: 1380.3667\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 3ms/step - loss: 1449.0433 - val_loss: 1363.4492\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 1430.6350 - val_loss: 1344.7865\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 7ms/step - loss: 1410.2654 - val_loss: 1325.4329\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1388.9752 - val_loss: 1304.6727\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1366.5109 - val_loss: 1282.4418\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1342.1729 - val_loss: 1259.5752\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1317.2006 - val_loss: 1234.7090\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1290.5339 - val_loss: 1208.8937\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 3ms/step - loss: 1262.5215 - val_loss: 1181.7467\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1233.4998 - val_loss: 1153.5576\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 1203.5149 - val_loss: 1124.5693\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1172.3940 - val_loss: 1095.4213\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 1140.9792 - val_loss: 1064.5952\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 1108.5780 - val_loss: 1033.6487\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1075.7428 - val_loss: 1002.8327\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 1042.6410 - val_loss: 971.9479\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 1009.8755 - val_loss: 940.2629\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 976.3398 - val_loss: 908.8329\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 3ms/step - loss: 943.0813 - val_loss: 877.3243\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 909.6864 - val_loss: 845.8596\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 7ms/step - loss: 876.3218 - val_loss: 814.9669\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 843.1469 - val_loss: 783.8373\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 809.9780 - val_loss: 752.8546\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 776.3404 - val_loss: 723.0612\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 744.3565 - val_loss: 692.8730\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 712.1599 - val_loss: 664.1194\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 681.1035 - val_loss: 635.8522\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 650.8555 - val_loss: 608.6063\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 621.9926 - val_loss: 582.6516\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 594.1370 - val_loss: 558.2540\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 567.5983 - val_loss: 534.5480\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 542.2062 - val_loss: 511.7283\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 10ms/step - loss: 518.0765 - val_loss: 490.0509\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 494.9712 - val_loss: 469.4934\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 472.9761 - val_loss: 450.7222\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 452.8409 - val_loss: 432.4400\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 433.3296 - val_loss: 415.8385\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 415.5645 - val_loss: 399.8358\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 398.4837 - val_loss: 384.9123\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 382.7130 - val_loss: 371.2685\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 368.0764 - val_loss: 358.4632\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 354.1766 - val_loss: 346.7087\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 341.5645 - val_loss: 335.2592\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 329.2734 - val_loss: 324.9153\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 318.3671 - val_loss: 315.4153\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 308.3996 - val_loss: 306.3180\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 298.8397 - val_loss: 298.4186\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 290.2075 - val_loss: 290.6866\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 282.1513 - val_loss: 283.7176\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 274.6565 - val_loss: 277.1707\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 267.8983 - val_loss: 271.1158\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 261.4232 - val_loss: 265.8807\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 255.6427 - val_loss: 260.6352\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 250.1180 - val_loss: 255.6495\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 245.1103 - val_loss: 250.9437\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 240.2519 - val_loss: 246.9219\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 235.7761 - val_loss: 242.9266\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 231.6848 - val_loss: 239.2083\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 3ms/step - loss: 227.8013 - val_loss: 235.6473\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 224.0795 - val_loss: 232.3113\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 220.6048 - val_loss: 229.0817\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 217.2669 - val_loss: 226.0379\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 3ms/step - loss: 214.1589 - val_loss: 223.1379\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 6ms/step - loss: 211.0318 - val_loss: 220.4208\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 208.2893 - val_loss: 217.6785\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 205.4016 - val_loss: 215.1190\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 202.7822 - val_loss: 212.5375\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.1739 - val_loss: 210.1728\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.6257 - val_loss: 207.8251\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 195.2086 - val_loss: 205.5596\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.9527 - val_loss: 203.3449\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.5951 - val_loss: 201.2572\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.3910 - val_loss: 199.0255\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.1725 - val_loss: 196.9333\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 12ms/step - loss: 184.1490 - val_loss: 194.9431\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.1377 - val_loss: 192.7490\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 3ms/step - loss: 179.9578 - val_loss: 190.9120\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.0748 - val_loss: 188.8384\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.1093 - val_loss: 187.0757\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 174.2614 - val_loss: 185.2332\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 6ms/step - loss: 172.3600 - val_loss: 183.5135\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.5581 - val_loss: 181.9000\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.7286 - val_loss: 180.0091\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.8841 - val_loss: 178.3499\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.1704 - val_loss: 176.7851\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.6075 - val_loss: 175.1463\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.8948 - val_loss: 173.5828\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 3ms/step - loss: 160.2090 - val_loss: 172.1535\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.6802 - val_loss: 170.5656\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.0998 - val_loss: 169.1295\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 63ms/step - loss: 1515.6084 - val_loss: 1521.5717\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1496.9098 - val_loss: 1502.5713\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 6ms/step - loss: 1478.0302 - val_loss: 1483.0782\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1458.7183 - val_loss: 1462.8522\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 8ms/step - loss: 1438.5920 - val_loss: 1441.7865\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 3ms/step - loss: 1417.6478 - val_loss: 1420.0159\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 1395.6381 - val_loss: 1397.0780\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1372.3632 - val_loss: 1373.1692\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1347.9380 - val_loss: 1347.6960\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1322.5603 - val_loss: 1321.0439\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1295.7161 - val_loss: 1293.8503\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 1268.1819 - val_loss: 1265.1570\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1239.1523 - val_loss: 1235.9692\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1209.4260 - val_loss: 1205.8002\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1179.0852 - val_loss: 1174.1252\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1147.4690 - val_loss: 1142.3923\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 9ms/step - loss: 1115.3798 - val_loss: 1109.5898\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 6ms/step - loss: 1082.7549 - val_loss: 1076.2097\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1049.0884 - val_loss: 1043.0033\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1015.8103 - val_loss: 1008.3014\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 7ms/step - loss: 981.5784 - val_loss: 974.1027\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 947.2081 - val_loss: 939.7009\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 913.0117 - val_loss: 904.8528\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 878.3354 - val_loss: 870.9621\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 844.5802 - val_loss: 836.2571\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 810.6332 - val_loss: 802.3214\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 777.4854 - val_loss: 768.5397\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 744.5473 - val_loss: 736.1371\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 712.1566 - val_loss: 704.4853\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 680.5409 - val_loss: 672.8701\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 649.9005 - val_loss: 642.4404\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 620.0023 - val_loss: 613.2189\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 591.0642 - val_loss: 584.9389\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 563.4604 - val_loss: 557.8444\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 536.6346 - val_loss: 531.4814\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 511.0696 - val_loss: 506.2624\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 486.6614 - val_loss: 482.5965\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 463.6242 - val_loss: 459.9059\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 441.4831 - val_loss: 438.7514\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 420.5681 - val_loss: 419.3631\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 401.5421 - val_loss: 399.8183\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 382.9673 - val_loss: 382.4979\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 366.0622 - val_loss: 366.3022\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 9ms/step - loss: 350.1383 - val_loss: 351.1145\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 335.4325 - val_loss: 336.8748\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 3ms/step - loss: 321.5421 - val_loss: 324.1017\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 308.7948 - val_loss: 312.6674\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 297.4503 - val_loss: 301.0101\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 286.8167 - val_loss: 290.8298\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 276.7232 - val_loss: 282.3743\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 268.3658 - val_loss: 273.5709\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 259.9779 - val_loss: 266.2524\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 3ms/step - loss: 252.9334 - val_loss: 259.1963\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 8ms/step - loss: 246.1955 - val_loss: 253.2870\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 240.3419 - val_loss: 247.6416\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 234.9633 - val_loss: 242.5800\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 230.0055 - val_loss: 238.0345\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 7ms/step - loss: 225.4941 - val_loss: 234.1701\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 8ms/step - loss: 221.4702 - val_loss: 230.4209\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 217.7189 - val_loss: 226.6879\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 6ms/step - loss: 214.1917 - val_loss: 223.5500\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 211.0923 - val_loss: 220.3587\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 6ms/step - loss: 208.1301 - val_loss: 217.5958\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 15ms/step - loss: 205.3855 - val_loss: 215.1025\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.9102 - val_loss: 212.6643\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.5002 - val_loss: 210.5594\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 198.3702 - val_loss: 208.3285\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 196.1985 - val_loss: 206.3857\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 194.2785 - val_loss: 204.5769\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 6ms/step - loss: 192.4639 - val_loss: 202.7177\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 190.6594 - val_loss: 201.0260\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 3ms/step - loss: 188.9012 - val_loss: 199.4611\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 187.3424 - val_loss: 197.7635\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 3ms/step - loss: 185.6331 - val_loss: 196.2647\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.1975 - val_loss: 194.8569\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 7ms/step - loss: 182.6207 - val_loss: 193.4236\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 6ms/step - loss: 181.1548 - val_loss: 191.9705\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.6850 - val_loss: 190.5351\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.2167 - val_loss: 189.1578\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 7ms/step - loss: 176.8312 - val_loss: 187.7385\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 6ms/step - loss: 175.4239 - val_loss: 186.4456\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 12ms/step - loss: 173.9640 - val_loss: 185.0034\n",
      "Epoch 83/100\n",
      "23/23 - 1s - 24ms/step - loss: 172.6478 - val_loss: 183.6151\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 13ms/step - loss: 171.1531 - val_loss: 182.0893\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 12ms/step - loss: 169.6671 - val_loss: 180.7139\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 15ms/step - loss: 168.2803 - val_loss: 179.3455\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 11ms/step - loss: 166.8109 - val_loss: 178.0087\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 11ms/step - loss: 165.5323 - val_loss: 176.7220\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 9ms/step - loss: 164.0334 - val_loss: 175.4811\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 15ms/step - loss: 162.6221 - val_loss: 174.0919\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 8ms/step - loss: 161.3239 - val_loss: 172.6895\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 15ms/step - loss: 159.9391 - val_loss: 171.4588\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 15ms/step - loss: 158.5332 - val_loss: 170.0341\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 12ms/step - loss: 157.1626 - val_loss: 168.7985\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 8ms/step - loss: 155.8495 - val_loss: 167.5117\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 6ms/step - loss: 154.4885 - val_loss: 166.3333\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.1281 - val_loss: 164.9382\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 8ms/step - loss: 151.7942 - val_loss: 163.7190\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 13ms/step - loss: 150.4698 - val_loss: 162.5179\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 7ms/step - loss: 149.1547 - val_loss: 161.2591\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 4s - 156ms/step - loss: 1537.8213 - val_loss: 1490.3994\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 6ms/step - loss: 1521.2947 - val_loss: 1473.6163\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 6ms/step - loss: 1503.9877 - val_loss: 1455.9384\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 7ms/step - loss: 1485.4714 - val_loss: 1437.3855\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 6ms/step - loss: 1465.5417 - val_loss: 1417.6383\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1444.5504 - val_loss: 1396.4861\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 9ms/step - loss: 1421.9152 - val_loss: 1374.4769\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1398.1527 - val_loss: 1350.8003\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 1372.6942 - val_loss: 1326.0433\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 7ms/step - loss: 1345.8315 - val_loss: 1300.1285\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 8ms/step - loss: 1317.8755 - val_loss: 1273.2113\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 16ms/step - loss: 1288.2234 - val_loss: 1245.2590\n",
      "Epoch 13/100\n",
      "23/23 - 1s - 25ms/step - loss: 1257.9269 - val_loss: 1216.1378\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 8ms/step - loss: 1226.1304 - val_loss: 1186.4943\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 9ms/step - loss: 1193.7068 - val_loss: 1156.2454\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 7ms/step - loss: 1160.5345 - val_loss: 1125.5244\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 16ms/step - loss: 1127.1243 - val_loss: 1093.9659\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 13ms/step - loss: 1093.2875 - val_loss: 1061.8947\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1059.0546 - val_loss: 1030.2296\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 6ms/step - loss: 1024.6816 - val_loss: 998.1998\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 6ms/step - loss: 990.3879 - val_loss: 966.1798\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 6ms/step - loss: 956.2476 - val_loss: 934.4567\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 11ms/step - loss: 922.4084 - val_loss: 902.9055\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 6ms/step - loss: 889.0054 - val_loss: 871.8484\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 7ms/step - loss: 855.7768 - val_loss: 841.4420\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 823.5732 - val_loss: 810.9315\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 791.9148 - val_loss: 781.3524\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 6ms/step - loss: 761.5808 - val_loss: 752.5662\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 8ms/step - loss: 732.2180 - val_loss: 724.2598\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 6ms/step - loss: 703.3845 - val_loss: 697.4421\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 675.9227 - val_loss: 671.2335\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 649.5018 - val_loss: 645.1775\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 623.5967 - val_loss: 620.2067\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 598.4744 - val_loss: 596.1847\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 575.0862 - val_loss: 572.4495\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 3ms/step - loss: 552.4128 - val_loss: 549.3654\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 3ms/step - loss: 530.0927 - val_loss: 528.0043\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 509.3826 - val_loss: 506.6753\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 489.4480 - val_loss: 486.1948\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 470.2274 - val_loss: 465.9617\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 451.7667 - val_loss: 447.1151\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 434.3041 - val_loss: 428.3567\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 3ms/step - loss: 417.2740 - val_loss: 410.7347\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 3ms/step - loss: 401.5009 - val_loss: 393.0326\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 12ms/step - loss: 385.9774 - val_loss: 376.6350\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 371.3810 - val_loss: 360.4765\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 357.3586 - val_loss: 345.2806\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 3ms/step - loss: 344.1393 - val_loss: 330.8861\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 331.5815 - val_loss: 316.7108\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 319.2422 - val_loss: 303.7079\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 307.8463 - val_loss: 290.9706\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 296.5955 - val_loss: 279.0029\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 286.2029 - val_loss: 267.2008\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 275.9082 - val_loss: 256.1734\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 266.6522 - val_loss: 245.5658\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 3ms/step - loss: 257.3935 - val_loss: 235.9583\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 249.0466 - val_loss: 226.8623\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 241.0543 - val_loss: 218.4491\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 233.6551 - val_loss: 210.5834\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 226.7951 - val_loss: 203.2473\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 220.5693 - val_loss: 196.7666\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 3ms/step - loss: 214.6631 - val_loss: 190.7213\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 209.4223 - val_loss: 185.1139\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 204.3728 - val_loss: 180.2483\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 199.9780 - val_loss: 175.6898\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 195.8106 - val_loss: 171.8313\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.0404 - val_loss: 168.2082\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.6841 - val_loss: 164.8320\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.5894 - val_loss: 161.8161\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 182.7541 - val_loss: 159.4223\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.2474 - val_loss: 157.2110\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 3ms/step - loss: 177.9818 - val_loss: 155.2347\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.9108 - val_loss: 153.3629\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 3ms/step - loss: 174.0265 - val_loss: 151.9797\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.2103 - val_loss: 150.7179\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.6829 - val_loss: 149.4563\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.2236 - val_loss: 148.5889\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.9608 - val_loss: 147.5112\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 3ms/step - loss: 166.7014 - val_loss: 146.7112\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.5456 - val_loss: 146.0690\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.5987 - val_loss: 145.2849\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.5420 - val_loss: 144.7729\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.6924 - val_loss: 144.2625\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.8024 - val_loss: 143.8010\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 13ms/step - loss: 160.9927 - val_loss: 143.4171\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.2496 - val_loss: 143.0432\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.4167 - val_loss: 142.6429\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.7356 - val_loss: 142.2317\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.0940 - val_loss: 141.7758\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.4243 - val_loss: 141.5543\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 3ms/step - loss: 156.8001 - val_loss: 141.1471\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 8ms/step - loss: 156.1799 - val_loss: 140.7165\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 3ms/step - loss: 155.6406 - val_loss: 140.4734\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 10ms/step - loss: 155.0136 - val_loss: 140.1382\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.5690 - val_loss: 139.9494\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.9997 - val_loss: 139.4257\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 7ms/step - loss: 153.4489 - val_loss: 139.1462\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.9008 - val_loss: 138.7424\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.4546 - val_loss: 138.5422\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 3ms/step - loss: 151.8702 - val_loss: 138.1824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 5s - 205ms/step - loss: 1527.6985 - val_loss: 1504.0270\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1509.4236 - val_loss: 1485.3464\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 7ms/step - loss: 1490.8003 - val_loss: 1464.9797\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1470.9303 - val_loss: 1443.6494\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1449.9454 - val_loss: 1421.5742\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 8ms/step - loss: 1427.9740 - val_loss: 1398.3519\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 7ms/step - loss: 1404.9254 - val_loss: 1373.8748\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 6ms/step - loss: 1380.8510 - val_loss: 1347.9861\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1355.3247 - val_loss: 1321.4983\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 8ms/step - loss: 1329.0975 - val_loss: 1293.4347\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 6ms/step - loss: 1301.5538 - val_loss: 1264.6442\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 8ms/step - loss: 1272.9799 - val_loss: 1234.9402\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 15ms/step - loss: 1243.7260 - val_loss: 1204.2175\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 1213.2041 - val_loss: 1173.0226\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 1181.9503 - val_loss: 1141.3623\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 6ms/step - loss: 1150.3811 - val_loss: 1108.7454\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 6ms/step - loss: 1117.8844 - val_loss: 1076.0743\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1084.9772 - val_loss: 1042.4668\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 3ms/step - loss: 1051.4142 - val_loss: 1008.4909\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 1017.6746 - val_loss: 974.0594\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 983.5542 - val_loss: 940.3793\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 3ms/step - loss: 949.7840 - val_loss: 906.4860\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 3ms/step - loss: 916.0464 - val_loss: 873.1116\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 3ms/step - loss: 882.5330 - val_loss: 839.4207\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 6ms/step - loss: 848.7728 - val_loss: 806.8806\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 6ms/step - loss: 816.2060 - val_loss: 774.1299\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 783.3422 - val_loss: 742.2540\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 751.3336 - val_loss: 711.5443\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 720.3433 - val_loss: 680.8536\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 6ms/step - loss: 689.9585 - val_loss: 651.2294\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 9ms/step - loss: 660.3726 - val_loss: 622.7478\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 15ms/step - loss: 631.9157 - val_loss: 594.9415\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 21ms/step - loss: 603.5967 - val_loss: 568.9374\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 8ms/step - loss: 576.7544 - val_loss: 543.0450\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 3ms/step - loss: 550.6149 - val_loss: 518.4390\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 525.4348 - val_loss: 494.6128\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 7ms/step - loss: 501.0951 - val_loss: 472.2129\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 477.9702 - val_loss: 450.6925\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 6ms/step - loss: 455.8034 - val_loss: 430.1704\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 7ms/step - loss: 434.8310 - val_loss: 410.5917\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 6ms/step - loss: 414.8629 - val_loss: 391.5864\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 395.8207 - val_loss: 373.9135\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 6ms/step - loss: 378.0125 - val_loss: 357.3863\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 7ms/step - loss: 361.2764 - val_loss: 341.8836\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 345.4326 - val_loss: 327.4045\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 330.7045 - val_loss: 313.8609\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 6ms/step - loss: 317.0653 - val_loss: 300.9286\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 6ms/step - loss: 303.9922 - val_loss: 289.0487\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 3ms/step - loss: 291.9629 - val_loss: 277.9212\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 3ms/step - loss: 280.6452 - val_loss: 267.8304\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 16ms/step - loss: 270.5121 - val_loss: 258.0785\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 260.9815 - val_loss: 249.0868\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 10ms/step - loss: 252.0113 - val_loss: 240.9641\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 11ms/step - loss: 243.9139 - val_loss: 233.5516\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 236.3724 - val_loss: 226.7415\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 229.5690 - val_loss: 220.3375\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 13ms/step - loss: 223.1756 - val_loss: 214.5402\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 9ms/step - loss: 217.3642 - val_loss: 209.0437\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 8ms/step - loss: 212.0637 - val_loss: 204.1986\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 8ms/step - loss: 207.3659 - val_loss: 199.6739\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 7ms/step - loss: 202.8007 - val_loss: 195.8491\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 7ms/step - loss: 198.9005 - val_loss: 192.1115\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 6ms/step - loss: 195.2170 - val_loss: 188.8290\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 10ms/step - loss: 192.0093 - val_loss: 185.8468\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 188.8207 - val_loss: 182.9477\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.1134 - val_loss: 180.6678\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 183.4472 - val_loss: 178.4207\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 6ms/step - loss: 181.1982 - val_loss: 176.2340\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.0805 - val_loss: 174.4026\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 3ms/step - loss: 177.0809 - val_loss: 172.6972\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 175.3336 - val_loss: 171.2182\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.7178 - val_loss: 169.7176\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.1725 - val_loss: 168.5316\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 9ms/step - loss: 170.7449 - val_loss: 167.3061\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 6ms/step - loss: 169.3996 - val_loss: 166.2539\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.2597 - val_loss: 165.2996\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 3ms/step - loss: 167.0589 - val_loss: 164.3966\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.0215 - val_loss: 163.4437\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.8855 - val_loss: 162.6656\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 7ms/step - loss: 163.9886 - val_loss: 161.8405\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.0569 - val_loss: 161.0849\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.1720 - val_loss: 160.4384\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 3ms/step - loss: 161.3981 - val_loss: 159.5832\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 3ms/step - loss: 160.6480 - val_loss: 159.1862\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 159.8551 - val_loss: 158.5100\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.0554 - val_loss: 157.8214\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 3ms/step - loss: 158.3984 - val_loss: 157.3795\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.6437 - val_loss: 156.8452\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.9817 - val_loss: 156.1670\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.3126 - val_loss: 155.7899\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.6539 - val_loss: 155.0589\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 155.0098 - val_loss: 154.5827\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 10ms/step - loss: 154.3813 - val_loss: 154.0865\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.7226 - val_loss: 153.6345\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.0959 - val_loss: 153.0915\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.5383 - val_loss: 152.5398\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 6ms/step - loss: 152.0056 - val_loss: 151.7444\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 151.3441 - val_loss: 151.4646\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.6803 - val_loss: 151.0081\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.0485 - val_loss: 150.4497\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 83ms/step - loss: 1487.9851 - val_loss: 1549.6775\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1470.6642 - val_loss: 1530.5691\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1453.3613 - val_loss: 1511.1261\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1435.5760 - val_loss: 1491.4967\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 3ms/step - loss: 1417.2924 - val_loss: 1471.2673\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1398.3706 - val_loss: 1449.9308\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 6ms/step - loss: 1378.5582 - val_loss: 1428.0377\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1358.0851 - val_loss: 1405.2533\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1336.8304 - val_loss: 1381.4437\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 3ms/step - loss: 1314.7570 - val_loss: 1357.0935\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1291.9619 - val_loss: 1331.3779\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 7ms/step - loss: 1267.9067 - val_loss: 1305.2146\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1243.3920 - val_loss: 1277.7748\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1217.9562 - val_loss: 1249.9083\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 1191.8247 - val_loss: 1221.1783\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 1165.3805 - val_loss: 1191.5647\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 1137.6449 - val_loss: 1161.9935\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 6ms/step - loss: 1109.9374 - val_loss: 1131.0319\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 6ms/step - loss: 1081.2600 - val_loss: 1099.5297\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1051.9580 - val_loss: 1067.4125\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 7ms/step - loss: 1022.1216 - val_loss: 1034.9128\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 15ms/step - loss: 991.7192 - val_loss: 1001.5991\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 960.9163 - val_loss: 967.5939\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 7ms/step - loss: 929.5347 - val_loss: 933.5103\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 898.0237 - val_loss: 898.8598\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 6ms/step - loss: 866.2960 - val_loss: 864.3137\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 834.4393 - val_loss: 829.6140\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 13ms/step - loss: 802.8994 - val_loss: 795.0464\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 771.3911 - val_loss: 761.0777\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 6ms/step - loss: 740.3375 - val_loss: 727.9932\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 710.2121 - val_loss: 694.7621\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 680.4814 - val_loss: 662.8029\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 651.8238 - val_loss: 631.7275\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 7ms/step - loss: 623.8945 - val_loss: 601.4809\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 8ms/step - loss: 596.8870 - val_loss: 572.6172\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 7ms/step - loss: 570.9680 - val_loss: 545.2172\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 7ms/step - loss: 546.2129 - val_loss: 519.1973\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 14ms/step - loss: 522.7440 - val_loss: 493.3962\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 6ms/step - loss: 500.0113 - val_loss: 469.1394\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 6ms/step - loss: 478.2600 - val_loss: 446.6156\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 7ms/step - loss: 457.8446 - val_loss: 424.7502\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 438.6889 - val_loss: 404.1787\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 420.2983 - val_loss: 385.8970\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 403.6067 - val_loss: 368.1335\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 9ms/step - loss: 387.6651 - val_loss: 351.3020\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 372.6256 - val_loss: 336.1386\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 358.5727 - val_loss: 321.6770\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 345.4059 - val_loss: 308.3831\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 14ms/step - loss: 333.3094 - val_loss: 295.9678\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 321.8646 - val_loss: 284.7399\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 311.3656 - val_loss: 274.6320\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 301.7817 - val_loss: 265.0923\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 8ms/step - loss: 292.8366 - val_loss: 256.4673\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 284.2743 - val_loss: 248.5502\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 276.2910 - val_loss: 241.2663\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 269.0935 - val_loss: 234.5210\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 262.4402 - val_loss: 228.1167\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 6ms/step - loss: 256.1036 - val_loss: 222.5225\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 250.2815 - val_loss: 217.8573\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 8ms/step - loss: 245.0664 - val_loss: 213.1927\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 6ms/step - loss: 240.1546 - val_loss: 208.9775\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 235.5063 - val_loss: 204.9540\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 6ms/step - loss: 231.0321 - val_loss: 201.3947\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 6ms/step - loss: 227.0111 - val_loss: 198.2449\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 223.1721 - val_loss: 195.1762\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 7ms/step - loss: 219.5604 - val_loss: 192.3648\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 216.0389 - val_loss: 189.7411\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 212.8496 - val_loss: 187.1850\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 8ms/step - loss: 209.7730 - val_loss: 184.8235\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.8211 - val_loss: 182.6816\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 204.1322 - val_loss: 180.5706\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 201.4456 - val_loss: 178.5950\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 198.9292 - val_loss: 176.7743\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.5768 - val_loss: 175.1160\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 8ms/step - loss: 194.3951 - val_loss: 173.4534\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 6ms/step - loss: 192.1685 - val_loss: 171.8256\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 6ms/step - loss: 190.0489 - val_loss: 170.4105\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 7ms/step - loss: 187.9571 - val_loss: 168.8999\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 6ms/step - loss: 185.9980 - val_loss: 167.4759\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 7ms/step - loss: 184.0803 - val_loss: 166.2260\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 182.2050 - val_loss: 164.7615\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.3688 - val_loss: 163.5317\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.5238 - val_loss: 162.3288\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.9228 - val_loss: 161.1778\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 12ms/step - loss: 175.2068 - val_loss: 160.0816\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 6ms/step - loss: 173.6910 - val_loss: 158.9609\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 13ms/step - loss: 172.0802 - val_loss: 157.9376\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 6ms/step - loss: 170.5781 - val_loss: 156.8934\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.0994 - val_loss: 155.9415\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.6193 - val_loss: 154.8328\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 11ms/step - loss: 166.1905 - val_loss: 153.8315\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 10ms/step - loss: 164.7504 - val_loss: 152.9288\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 14ms/step - loss: 163.3813 - val_loss: 151.8922\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 7ms/step - loss: 161.9963 - val_loss: 151.0593\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 9ms/step - loss: 160.7326 - val_loss: 150.0970\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 10ms/step - loss: 159.3089 - val_loss: 149.1564\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 10ms/step - loss: 157.9308 - val_loss: 148.3349\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 3ms/step - loss: 156.6297 - val_loss: 147.2615\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.3579 - val_loss: 146.3827\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 6ms/step - loss: 154.0402 - val_loss: 145.4590\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 82ms/step - loss: 1508.2026 - val_loss: 1688.7438\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1495.0016 - val_loss: 1674.1251\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 6ms/step - loss: 1481.8130 - val_loss: 1659.4838\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1468.5115 - val_loss: 1644.5338\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 9ms/step - loss: 1454.9559 - val_loss: 1629.0194\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1440.7424 - val_loss: 1613.0875\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1425.9487 - val_loss: 1596.2432\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 1410.4600 - val_loss: 1578.1802\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 8ms/step - loss: 1394.0061 - val_loss: 1559.1212\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 8ms/step - loss: 1376.4933 - val_loss: 1538.8618\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1357.8453 - val_loss: 1517.4449\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 6ms/step - loss: 1338.2029 - val_loss: 1493.8008\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1316.7848 - val_loss: 1469.6306\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1294.4495 - val_loss: 1443.3480\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 7ms/step - loss: 1270.2994 - val_loss: 1415.9039\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1245.1111 - val_loss: 1386.0466\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 10ms/step - loss: 1218.0978 - val_loss: 1354.6885\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1189.8635 - val_loss: 1322.3765\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1160.2449 - val_loss: 1287.9667\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 8ms/step - loss: 1129.2549 - val_loss: 1251.2850\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1096.0443 - val_loss: 1213.9241\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1062.3608 - val_loss: 1173.9200\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 8ms/step - loss: 1026.8043 - val_loss: 1134.1648\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 990.9788 - val_loss: 1092.6195\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 954.3647 - val_loss: 1050.6042\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 916.9414 - val_loss: 1009.1250\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 6ms/step - loss: 879.6233 - val_loss: 966.0933\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 842.0038 - val_loss: 923.2476\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 804.6371 - val_loss: 880.8674\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 9ms/step - loss: 767.5919 - val_loss: 839.3099\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 6ms/step - loss: 731.0161 - val_loss: 798.6215\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 695.6505 - val_loss: 758.0805\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 660.8235 - val_loss: 719.8026\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 627.1572 - val_loss: 683.3049\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 595.1945 - val_loss: 647.3636\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 6ms/step - loss: 564.2321 - val_loss: 613.5612\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 534.7882 - val_loss: 581.2204\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 506.7153 - val_loss: 550.0874\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 11ms/step - loss: 480.3086 - val_loss: 520.7999\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 6ms/step - loss: 454.8442 - val_loss: 493.9680\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 431.2262 - val_loss: 468.5305\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 409.3737 - val_loss: 444.6104\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 8ms/step - loss: 388.6755 - val_loss: 423.3636\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 370.0270 - val_loss: 402.3315\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 352.2652 - val_loss: 383.7594\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 6ms/step - loss: 336.3150 - val_loss: 366.4524\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 321.3005 - val_loss: 351.2817\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 307.9488 - val_loss: 337.1257\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 295.6245 - val_loss: 323.8398\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 8ms/step - loss: 284.3011 - val_loss: 312.3301\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 274.2203 - val_loss: 301.9605\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 10ms/step - loss: 264.9921 - val_loss: 292.1827\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 7ms/step - loss: 256.7894 - val_loss: 283.5033\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 249.3290 - val_loss: 275.7112\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 6ms/step - loss: 242.5250 - val_loss: 268.7382\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 236.6310 - val_loss: 262.2501\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 9ms/step - loss: 230.9323 - val_loss: 256.2190\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 225.8008 - val_loss: 251.0891\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 221.2877 - val_loss: 246.0719\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 217.0248 - val_loss: 241.7978\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 213.3633 - val_loss: 237.8197\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 6ms/step - loss: 209.8610 - val_loss: 233.8956\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.6072 - val_loss: 230.6177\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 7ms/step - loss: 203.7476 - val_loss: 227.2754\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 6ms/step - loss: 200.9594 - val_loss: 224.2866\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 8ms/step - loss: 198.3184 - val_loss: 221.5249\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 14ms/step - loss: 195.9939 - val_loss: 218.6144\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 6ms/step - loss: 193.6139 - val_loss: 216.1010\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.4758 - val_loss: 213.6792\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 7ms/step - loss: 189.4660 - val_loss: 211.4072\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.5564 - val_loss: 209.1687\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 8ms/step - loss: 185.7873 - val_loss: 206.8613\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.9473 - val_loss: 204.8590\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 7ms/step - loss: 182.3483 - val_loss: 203.0419\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.6887 - val_loss: 201.1561\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 15ms/step - loss: 179.1242 - val_loss: 199.1450\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 16ms/step - loss: 177.5829 - val_loss: 197.2785\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.1541 - val_loss: 195.3521\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 9ms/step - loss: 174.7349 - val_loss: 193.6618\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 6ms/step - loss: 173.3570 - val_loss: 191.9987\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.0414 - val_loss: 190.4980\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.7042 - val_loss: 188.8152\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 7ms/step - loss: 169.4505 - val_loss: 187.1733\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 6ms/step - loss: 168.2005 - val_loss: 185.7123\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 6ms/step - loss: 167.0181 - val_loss: 184.0583\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.7440 - val_loss: 182.6210\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.6943 - val_loss: 181.1675\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.5121 - val_loss: 179.7343\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 6ms/step - loss: 162.3920 - val_loss: 178.3765\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.2971 - val_loss: 176.8873\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 6ms/step - loss: 160.2322 - val_loss: 175.4889\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.1380 - val_loss: 174.2487\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.0859 - val_loss: 172.8014\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.0031 - val_loss: 171.4594\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.0106 - val_loss: 170.0961\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 154.9619 - val_loss: 168.9054\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 154.0067 - val_loss: 167.5835\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.9612 - val_loss: 166.1862\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 12ms/step - loss: 151.9082 - val_loss: 164.9951\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 6ms/step - loss: 150.9698 - val_loss: 163.7057\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 75ms/step - loss: 1604.6271 - val_loss: 1584.2679\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 6ms/step - loss: 1589.4370 - val_loss: 1568.7104\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 1574.7708 - val_loss: 1553.4879\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1560.1473 - val_loss: 1538.9758\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1545.7870 - val_loss: 1524.2084\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 6ms/step - loss: 1531.4011 - val_loss: 1509.0089\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 3ms/step - loss: 1516.6113 - val_loss: 1493.7622\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 3ms/step - loss: 1501.6437 - val_loss: 1477.8684\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 1486.2786 - val_loss: 1461.7579\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 9ms/step - loss: 1470.5806 - val_loss: 1445.2998\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 1454.5663 - val_loss: 1427.9928\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1437.7979 - val_loss: 1410.0566\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 1420.4490 - val_loss: 1391.6337\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 1402.6721 - val_loss: 1372.6317\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 7ms/step - loss: 1384.1665 - val_loss: 1353.1500\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1365.3461 - val_loss: 1332.4856\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1345.3939 - val_loss: 1311.5840\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 1325.3073 - val_loss: 1290.1014\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1304.7888 - val_loss: 1267.6959\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 6ms/step - loss: 1283.3761 - val_loss: 1245.0519\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 1261.3049 - val_loss: 1221.6261\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 3ms/step - loss: 1238.7405 - val_loss: 1197.4224\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 1215.3807 - val_loss: 1172.4431\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 6ms/step - loss: 1191.6174 - val_loss: 1146.3562\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 3ms/step - loss: 1166.8322 - val_loss: 1119.7567\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 1141.7550 - val_loss: 1092.2257\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 1115.8066 - val_loss: 1064.3402\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 1089.8799 - val_loss: 1035.5353\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 1062.7916 - val_loss: 1007.8268\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 1036.0690 - val_loss: 978.8339\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 3ms/step - loss: 1009.1188 - val_loss: 949.8317\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 982.3727 - val_loss: 921.4103\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 955.9185 - val_loss: 893.5803\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 930.0799 - val_loss: 865.1724\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 3ms/step - loss: 904.2622 - val_loss: 838.3475\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 879.1417 - val_loss: 812.2620\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 854.6363 - val_loss: 787.1738\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 831.0592 - val_loss: 762.0185\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 807.6505 - val_loss: 737.8459\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 11ms/step - loss: 784.9340 - val_loss: 714.8401\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 763.2110 - val_loss: 692.3585\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 741.8032 - val_loss: 670.8585\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 721.4787 - val_loss: 650.4403\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 701.7004 - val_loss: 630.9179\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 682.9072 - val_loss: 612.1863\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 664.9274 - val_loss: 593.8824\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 647.0952 - val_loss: 577.2538\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 3ms/step - loss: 630.5983 - val_loss: 560.4273\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 614.0541 - val_loss: 545.2291\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 599.0092 - val_loss: 529.9330\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 584.0187 - val_loss: 516.1492\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 569.7622 - val_loss: 503.2099\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 556.3330 - val_loss: 490.1824\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 543.0542 - val_loss: 478.2439\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 530.4822 - val_loss: 466.8559\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 518.3665 - val_loss: 455.9756\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 506.6257 - val_loss: 445.5870\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 495.4998 - val_loss: 435.6655\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 484.6831 - val_loss: 426.8620\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 474.4971 - val_loss: 417.8636\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 464.4697 - val_loss: 409.6342\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 454.7202 - val_loss: 401.6466\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 445.6949 - val_loss: 393.6889\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 436.4656 - val_loss: 386.7124\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 427.9565 - val_loss: 379.5243\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 419.5384 - val_loss: 372.6023\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 411.2279 - val_loss: 366.1115\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 3ms/step - loss: 403.2875 - val_loss: 359.8431\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 395.4490 - val_loss: 354.0932\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 388.1368 - val_loss: 348.2998\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 380.9729 - val_loss: 342.8701\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 373.9662 - val_loss: 337.4135\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 367.1632 - val_loss: 332.4183\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 360.6395 - val_loss: 327.3890\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 354.0110 - val_loss: 322.7265\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 347.6887 - val_loss: 317.9159\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 341.4133 - val_loss: 313.3551\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 335.4074 - val_loss: 308.6771\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 329.5421 - val_loss: 304.1379\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 323.6467 - val_loss: 299.8988\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 3ms/step - loss: 318.1860 - val_loss: 295.5095\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 312.6170 - val_loss: 291.3653\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 307.2315 - val_loss: 287.1702\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 10ms/step - loss: 301.7842 - val_loss: 282.9832\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 296.5126 - val_loss: 278.9376\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 6ms/step - loss: 291.2664 - val_loss: 274.9381\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 286.2510 - val_loss: 270.9167\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 281.3528 - val_loss: 267.0225\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 8ms/step - loss: 276.2607 - val_loss: 263.2358\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 271.3923 - val_loss: 259.3737\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 266.5354 - val_loss: 255.5889\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 261.6953 - val_loss: 252.0706\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 257.1228 - val_loss: 248.3595\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 252.5501 - val_loss: 244.7815\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 248.0848 - val_loss: 241.3170\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 6ms/step - loss: 243.6357 - val_loss: 237.8531\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 239.3205 - val_loss: 234.4679\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 3ms/step - loss: 235.1385 - val_loss: 231.1335\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 231.0446 - val_loss: 227.8751\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 226.9529 - val_loss: 224.6198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 74ms/step - loss: 1608.0731 - val_loss: 1563.6554\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1590.4452 - val_loss: 1546.6493\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1573.8647 - val_loss: 1530.4094\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 3ms/step - loss: 1558.1711 - val_loss: 1514.9019\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1543.1831 - val_loss: 1499.7981\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1528.5923 - val_loss: 1485.3500\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 1514.5574 - val_loss: 1470.7096\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1500.3375 - val_loss: 1456.2651\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 3ms/step - loss: 1486.1670 - val_loss: 1441.9781\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1471.8143 - val_loss: 1427.5050\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 3ms/step - loss: 1457.1064 - val_loss: 1412.8446\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1441.9553 - val_loss: 1397.7660\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 3ms/step - loss: 1426.2090 - val_loss: 1382.4490\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 1410.0962 - val_loss: 1366.3746\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 6ms/step - loss: 1393.1385 - val_loss: 1350.0734\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 7ms/step - loss: 1375.6594 - val_loss: 1332.9856\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 1357.5908 - val_loss: 1315.0698\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 1338.2074 - val_loss: 1296.8757\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1318.3291 - val_loss: 1277.4788\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 3ms/step - loss: 1297.0659 - val_loss: 1257.6047\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1275.1915 - val_loss: 1236.8871\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1252.2834 - val_loss: 1215.1149\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 6ms/step - loss: 1228.2230 - val_loss: 1192.6511\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1203.2097 - val_loss: 1169.2876\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1176.5928 - val_loss: 1145.4570\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 1149.0978 - val_loss: 1120.1859\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 1120.3086 - val_loss: 1093.7927\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 1089.7826 - val_loss: 1066.7615\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 1057.7871 - val_loss: 1038.6730\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 3ms/step - loss: 1024.6774 - val_loss: 1010.4892\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 991.3663 - val_loss: 980.9852\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 957.1636 - val_loss: 952.1486\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 923.1658 - val_loss: 923.9020\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 889.5864 - val_loss: 895.4646\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 856.0242 - val_loss: 868.0251\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 823.6485 - val_loss: 840.4973\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 8ms/step - loss: 792.0120 - val_loss: 813.0933\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 760.9570 - val_loss: 787.2122\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 3ms/step - loss: 731.2459 - val_loss: 762.1091\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 702.6847 - val_loss: 738.1931\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 675.0363 - val_loss: 714.9848\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 649.2009 - val_loss: 692.7254\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 3ms/step - loss: 623.8076 - val_loss: 671.3634\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 600.1648 - val_loss: 650.6751\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 577.3171 - val_loss: 630.7451\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 11ms/step - loss: 555.8383 - val_loss: 611.7971\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 535.4012 - val_loss: 594.0825\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 516.1190 - val_loss: 576.7852\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 6ms/step - loss: 497.7199 - val_loss: 560.3914\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 18ms/step - loss: 480.2509 - val_loss: 543.9500\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 463.4044 - val_loss: 528.2773\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 6ms/step - loss: 447.4118 - val_loss: 512.9399\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 432.0172 - val_loss: 497.9435\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 417.3105 - val_loss: 483.3782\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 9ms/step - loss: 402.9751 - val_loss: 468.7157\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 8ms/step - loss: 389.0081 - val_loss: 454.8373\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 15ms/step - loss: 375.3677 - val_loss: 440.5965\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 13ms/step - loss: 362.2211 - val_loss: 425.8812\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 9ms/step - loss: 349.2582 - val_loss: 412.1812\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 336.9537 - val_loss: 398.5136\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 8ms/step - loss: 324.9985 - val_loss: 385.4449\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 6ms/step - loss: 313.3702 - val_loss: 373.0179\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 6ms/step - loss: 302.4072 - val_loss: 360.7932\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 291.8420 - val_loss: 349.0986\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 7ms/step - loss: 281.8333 - val_loss: 338.1345\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 9ms/step - loss: 272.4346 - val_loss: 327.5175\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 7ms/step - loss: 263.4308 - val_loss: 317.5674\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 255.0297 - val_loss: 308.0974\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 247.0668 - val_loss: 299.0901\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 6ms/step - loss: 239.6180 - val_loss: 290.8335\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 232.5880 - val_loss: 283.0963\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 6ms/step - loss: 226.0976 - val_loss: 275.8141\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 6ms/step - loss: 219.9388 - val_loss: 269.2769\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 214.5105 - val_loss: 262.8271\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 209.0787 - val_loss: 257.1494\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 204.3670 - val_loss: 251.5571\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 199.7312 - val_loss: 246.6066\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 195.7342 - val_loss: 241.6855\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 7ms/step - loss: 191.7591 - val_loss: 237.7117\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.1875 - val_loss: 233.6301\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.8923 - val_loss: 229.9180\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 6ms/step - loss: 181.7997 - val_loss: 226.3596\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 7ms/step - loss: 178.8358 - val_loss: 223.0720\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 6ms/step - loss: 176.1678 - val_loss: 219.9353\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 7ms/step - loss: 173.7788 - val_loss: 216.8286\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 7ms/step - loss: 171.5166 - val_loss: 214.2133\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 6ms/step - loss: 169.2306 - val_loss: 211.4067\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.1879 - val_loss: 208.9035\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 8ms/step - loss: 165.1608 - val_loss: 206.5004\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 14ms/step - loss: 163.3806 - val_loss: 204.2266\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 6ms/step - loss: 161.5348 - val_loss: 202.2588\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 6ms/step - loss: 159.9992 - val_loss: 200.0921\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 7ms/step - loss: 158.3241 - val_loss: 198.2183\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 12ms/step - loss: 156.8880 - val_loss: 196.5680\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 12ms/step - loss: 155.4586 - val_loss: 194.8689\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 14ms/step - loss: 154.2148 - val_loss: 193.1907\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.8206 - val_loss: 191.4169\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 6ms/step - loss: 151.4953 - val_loss: 189.9987\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.3015 - val_loss: 188.3964\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 149.1735 - val_loss: 186.9291\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 101ms/step - loss: 1592.0635 - val_loss: 1446.9033\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 19ms/step - loss: 1578.9744 - val_loss: 1434.5592\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 6ms/step - loss: 1565.9457 - val_loss: 1422.3528\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 6ms/step - loss: 1552.8452 - val_loss: 1409.5469\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 6ms/step - loss: 1539.1437 - val_loss: 1396.4865\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 6ms/step - loss: 1524.9846 - val_loss: 1382.5284\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1509.9385 - val_loss: 1367.8522\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 3ms/step - loss: 1493.7722 - val_loss: 1352.2247\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1476.5499 - val_loss: 1335.2638\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 7ms/step - loss: 1457.7694 - val_loss: 1317.0366\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1437.6147 - val_loss: 1297.1685\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 6ms/step - loss: 1415.9209 - val_loss: 1275.7867\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 12ms/step - loss: 1392.4431 - val_loss: 1252.9843\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 6ms/step - loss: 1367.6918 - val_loss: 1228.9637\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 11ms/step - loss: 1341.4340 - val_loss: 1203.4354\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 1314.1000 - val_loss: 1176.8971\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 9ms/step - loss: 1285.0839 - val_loss: 1149.3215\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 14ms/step - loss: 1255.2809 - val_loss: 1120.6487\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1224.5634 - val_loss: 1091.3717\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 1192.7332 - val_loss: 1061.3901\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 8ms/step - loss: 1159.9407 - val_loss: 1030.0632\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1125.7762 - val_loss: 998.0378\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 6ms/step - loss: 1091.3490 - val_loss: 965.0274\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 9ms/step - loss: 1055.8489 - val_loss: 932.1741\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 12ms/step - loss: 1019.9983 - val_loss: 899.0135\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 7ms/step - loss: 983.7614 - val_loss: 865.2848\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 947.3511 - val_loss: 831.1921\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 910.9701 - val_loss: 797.0585\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 873.6409 - val_loss: 763.9694\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 9ms/step - loss: 837.3036 - val_loss: 730.0150\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 800.5489 - val_loss: 697.0874\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 8ms/step - loss: 764.4691 - val_loss: 664.7065\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 728.9625 - val_loss: 633.2699\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 8ms/step - loss: 693.9116 - val_loss: 603.2073\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 660.1212 - val_loss: 573.7775\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 8ms/step - loss: 627.1355 - val_loss: 544.4905\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 594.9926 - val_loss: 516.5297\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 6ms/step - loss: 563.8266 - val_loss: 490.3136\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 533.8387 - val_loss: 465.4455\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 505.2254 - val_loss: 441.8069\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 6ms/step - loss: 478.0190 - val_loss: 419.2020\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 451.8714 - val_loss: 398.4055\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 10ms/step - loss: 427.3247 - val_loss: 379.2175\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 404.2860 - val_loss: 361.0089\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 12ms/step - loss: 382.6766 - val_loss: 343.9454\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 6ms/step - loss: 362.3804 - val_loss: 328.7335\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 11ms/step - loss: 343.9064 - val_loss: 314.5069\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 326.6830 - val_loss: 302.0818\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 311.1413 - val_loss: 290.4287\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 8ms/step - loss: 296.5243 - val_loss: 280.5571\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 283.6500 - val_loss: 271.1190\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 8ms/step - loss: 271.5595 - val_loss: 263.1161\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 7ms/step - loss: 260.9378 - val_loss: 255.7701\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 13ms/step - loss: 251.4002 - val_loss: 249.0214\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 242.4772 - val_loss: 243.4387\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 234.8056 - val_loss: 238.2982\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 6ms/step - loss: 227.8503 - val_loss: 233.7882\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.6115 - val_loss: 230.1700\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 216.2290 - val_loss: 226.5809\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 6ms/step - loss: 211.2365 - val_loss: 223.3826\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 15ms/step - loss: 206.7711 - val_loss: 220.8305\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 12ms/step - loss: 202.8870 - val_loss: 218.1870\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 8ms/step - loss: 199.2736 - val_loss: 215.7969\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 18ms/step - loss: 196.0898 - val_loss: 213.6425\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 8ms/step - loss: 193.0269 - val_loss: 211.6731\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 7ms/step - loss: 190.3672 - val_loss: 209.8937\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 16ms/step - loss: 187.8573 - val_loss: 207.9600\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 7ms/step - loss: 185.5293 - val_loss: 206.2351\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 8ms/step - loss: 183.3992 - val_loss: 204.7652\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 8ms/step - loss: 181.5392 - val_loss: 203.1382\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 179.5798 - val_loss: 201.3993\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 7ms/step - loss: 177.7881 - val_loss: 200.0315\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.0679 - val_loss: 198.8300\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 6ms/step - loss: 174.4896 - val_loss: 197.3743\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 7ms/step - loss: 172.9075 - val_loss: 195.8986\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.4469 - val_loss: 194.4785\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 7ms/step - loss: 169.9805 - val_loss: 193.3628\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.6280 - val_loss: 191.9456\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.3061 - val_loss: 190.6289\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 7ms/step - loss: 165.9590 - val_loss: 189.2677\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 6ms/step - loss: 164.7525 - val_loss: 188.0108\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.4700 - val_loss: 186.8778\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 8ms/step - loss: 162.2236 - val_loss: 185.7719\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 6ms/step - loss: 161.1595 - val_loss: 184.7552\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.1013 - val_loss: 183.4630\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 10ms/step - loss: 159.0446 - val_loss: 182.6080\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 16ms/step - loss: 158.0620 - val_loss: 181.5956\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.1172 - val_loss: 180.5084\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.2428 - val_loss: 179.6386\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.3607 - val_loss: 178.7692\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 154.5616 - val_loss: 177.9730\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.7576 - val_loss: 176.9573\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 6ms/step - loss: 152.9097 - val_loss: 176.1834\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.1707 - val_loss: 175.2922\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 151.3283 - val_loss: 174.5646\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 9ms/step - loss: 150.5814 - val_loss: 173.9090\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 8ms/step - loss: 149.8485 - val_loss: 173.2058\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 149.2094 - val_loss: 172.6236\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 148.4685 - val_loss: 171.7096\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.7648 - val_loss: 171.0934\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 - 3s - 118ms/step - loss: 1467.1906 - val_loss: 1617.1674\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 17ms/step - loss: 1453.6604 - val_loss: 1602.9352\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 6ms/step - loss: 1440.4879 - val_loss: 1588.5997\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 6ms/step - loss: 1427.0106 - val_loss: 1573.5421\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 8ms/step - loss: 1412.4003 - val_loss: 1557.5240\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 6ms/step - loss: 1396.6641 - val_loss: 1539.4773\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 6ms/step - loss: 1379.1934 - val_loss: 1519.3558\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 7ms/step - loss: 1359.7814 - val_loss: 1497.3014\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 15ms/step - loss: 1338.2035 - val_loss: 1473.1648\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 6ms/step - loss: 1314.6123 - val_loss: 1446.5820\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 7ms/step - loss: 1289.1129 - val_loss: 1417.3158\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 13ms/step - loss: 1261.2760 - val_loss: 1386.7083\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 7ms/step - loss: 1231.7798 - val_loss: 1353.0900\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 8ms/step - loss: 1199.7114 - val_loss: 1318.0969\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 14ms/step - loss: 1165.8979 - val_loss: 1280.9460\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 7ms/step - loss: 1130.1694 - val_loss: 1242.2467\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 6ms/step - loss: 1093.1346 - val_loss: 1201.5219\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 7ms/step - loss: 1054.7017 - val_loss: 1159.5730\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 6ms/step - loss: 1015.4000 - val_loss: 1116.3479\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 9ms/step - loss: 975.0428 - val_loss: 1072.9064\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 7ms/step - loss: 934.6533 - val_loss: 1029.8944\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 894.4373 - val_loss: 986.9888\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 854.5272 - val_loss: 943.7306\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 8ms/step - loss: 814.4349 - val_loss: 901.9412\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 775.2615 - val_loss: 860.5305\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 6ms/step - loss: 737.0663 - val_loss: 819.0941\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 7ms/step - loss: 699.4492 - val_loss: 779.8708\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 663.4600 - val_loss: 741.6093\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 7ms/step - loss: 628.6851 - val_loss: 705.2404\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 10ms/step - loss: 595.5539 - val_loss: 670.4390\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 13ms/step - loss: 564.1021 - val_loss: 636.7001\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 7ms/step - loss: 533.9525 - val_loss: 605.3901\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 6ms/step - loss: 505.8448 - val_loss: 575.7620\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 479.5164 - val_loss: 547.4625\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 7ms/step - loss: 454.4107 - val_loss: 521.6425\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 431.5654 - val_loss: 497.7448\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 410.3712 - val_loss: 475.5004\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 390.5610 - val_loss: 454.9182\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 372.6721 - val_loss: 435.8928\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 7ms/step - loss: 356.0479 - val_loss: 418.3723\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 341.1270 - val_loss: 401.9453\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 14ms/step - loss: 327.0204 - val_loss: 387.8824\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 6ms/step - loss: 314.5166 - val_loss: 374.6913\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 303.0237 - val_loss: 362.5052\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 292.7363 - val_loss: 351.3640\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 6ms/step - loss: 283.1925 - val_loss: 341.3485\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 274.7112 - val_loss: 332.0524\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 266.8941 - val_loss: 323.8892\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 259.7890 - val_loss: 316.2298\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 253.3041 - val_loss: 309.5579\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 247.7471 - val_loss: 302.8396\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 242.2370 - val_loss: 297.2894\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 237.3290 - val_loss: 292.1539\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 232.9858 - val_loss: 287.0845\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 3ms/step - loss: 228.8925 - val_loss: 282.4334\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 225.0958 - val_loss: 278.4996\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 6ms/step - loss: 221.7567 - val_loss: 274.7167\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 8ms/step - loss: 218.2930 - val_loss: 271.3101\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.4475 - val_loss: 267.7744\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 9ms/step - loss: 212.4297 - val_loss: 264.5502\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 6ms/step - loss: 209.7795 - val_loss: 261.3820\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 207.2083 - val_loss: 258.7057\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 6ms/step - loss: 204.8453 - val_loss: 256.0310\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 202.5987 - val_loss: 253.3577\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.4355 - val_loss: 250.7397\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 6ms/step - loss: 198.4642 - val_loss: 248.3486\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.4712 - val_loss: 246.2130\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.5952 - val_loss: 243.9368\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.8999 - val_loss: 241.8737\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 6ms/step - loss: 191.2033 - val_loss: 240.0574\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 189.6400 - val_loss: 237.8006\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.0306 - val_loss: 235.9138\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 186.6061 - val_loss: 233.9944\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 6ms/step - loss: 185.2721 - val_loss: 232.4379\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.7478 - val_loss: 230.5267\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.3914 - val_loss: 229.0399\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 181.0031 - val_loss: 227.2997\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 7ms/step - loss: 179.6733 - val_loss: 225.6163\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.2983 - val_loss: 224.0073\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.1094 - val_loss: 222.3135\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.8420 - val_loss: 220.9851\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 174.6864 - val_loss: 219.5411\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.5435 - val_loss: 218.0202\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.2588 - val_loss: 216.6628\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 6ms/step - loss: 171.1984 - val_loss: 214.9666\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.0144 - val_loss: 213.6830\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 7ms/step - loss: 168.8723 - val_loss: 212.2110\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 14ms/step - loss: 167.8124 - val_loss: 210.6730\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.7439 - val_loss: 209.3624\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.6689 - val_loss: 208.2662\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.6618 - val_loss: 206.9067\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 6ms/step - loss: 163.6279 - val_loss: 205.4109\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 6ms/step - loss: 162.7017 - val_loss: 204.1502\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 7ms/step - loss: 161.6272 - val_loss: 202.9156\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 8ms/step - loss: 160.6192 - val_loss: 201.5190\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 15ms/step - loss: 159.6929 - val_loss: 200.2857\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 7ms/step - loss: 158.6904 - val_loss: 199.0956\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.7774 - val_loss: 197.8203\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.8194 - val_loss: 196.4154\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 6ms/step - loss: 155.8716 - val_loss: 195.3295\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 112ms/step - loss: 1592.7648 - val_loss: 1567.8375\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 6ms/step - loss: 1575.3564 - val_loss: 1551.8959\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1558.4277 - val_loss: 1536.6866\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1541.9468 - val_loss: 1521.5090\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 6ms/step - loss: 1525.7675 - val_loss: 1506.1254\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1509.3193 - val_loss: 1490.9313\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 9ms/step - loss: 1493.0494 - val_loss: 1475.7566\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 15ms/step - loss: 1476.6200 - val_loss: 1460.2913\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 8ms/step - loss: 1459.9459 - val_loss: 1444.2686\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 7ms/step - loss: 1442.9292 - val_loss: 1428.1163\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 7ms/step - loss: 1425.7059 - val_loss: 1411.1974\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 6ms/step - loss: 1407.5718 - val_loss: 1394.0006\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 6ms/step - loss: 1389.2520 - val_loss: 1375.8663\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 6ms/step - loss: 1369.9678 - val_loss: 1357.1515\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 7ms/step - loss: 1350.1630 - val_loss: 1337.6825\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 7ms/step - loss: 1329.2504 - val_loss: 1317.3508\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 1307.3857 - val_loss: 1296.0829\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 1284.3467 - val_loss: 1273.3640\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 8ms/step - loss: 1259.9358 - val_loss: 1249.6898\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 13ms/step - loss: 1234.2451 - val_loss: 1225.4255\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 7ms/step - loss: 1208.1484 - val_loss: 1199.4874\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 8ms/step - loss: 1180.3916 - val_loss: 1172.9268\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 12ms/step - loss: 1151.8928 - val_loss: 1145.4479\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 1122.1051 - val_loss: 1117.5930\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 6ms/step - loss: 1091.8737 - val_loss: 1088.8973\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 7ms/step - loss: 1060.8893 - val_loss: 1059.1183\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 8ms/step - loss: 1029.3162 - val_loss: 1029.4110\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 6ms/step - loss: 997.2103 - val_loss: 998.9774\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 9ms/step - loss: 965.0710 - val_loss: 968.5248\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 8ms/step - loss: 932.5994 - val_loss: 937.6978\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 900.3278 - val_loss: 907.1504\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 6ms/step - loss: 868.1149 - val_loss: 876.5070\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 11ms/step - loss: 836.1642 - val_loss: 846.2845\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 7ms/step - loss: 804.5732 - val_loss: 815.9289\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 773.2001 - val_loss: 786.2726\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 742.3391 - val_loss: 756.5596\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 6ms/step - loss: 712.5126 - val_loss: 727.6304\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 8ms/step - loss: 682.7995 - val_loss: 699.5169\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 12ms/step - loss: 654.1493 - val_loss: 671.7086\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 626.4032 - val_loss: 644.6357\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 599.1955 - val_loss: 618.6779\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 573.3996 - val_loss: 592.8701\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 6ms/step - loss: 548.2883 - val_loss: 568.3840\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 524.3524 - val_loss: 544.7575\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 501.6195 - val_loss: 521.6938\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 479.5667 - val_loss: 499.7750\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 8ms/step - loss: 458.7510 - val_loss: 478.6238\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 439.0233 - val_loss: 457.9713\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 419.9440 - val_loss: 438.9040\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 8ms/step - loss: 402.3088 - val_loss: 420.5979\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 8ms/step - loss: 385.6791 - val_loss: 403.0520\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 6ms/step - loss: 369.7062 - val_loss: 386.7491\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 6ms/step - loss: 354.9078 - val_loss: 370.5733\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 340.8162 - val_loss: 355.2113\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 8ms/step - loss: 327.4009 - val_loss: 341.1803\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 6ms/step - loss: 315.3460 - val_loss: 327.4898\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 303.9476 - val_loss: 315.0270\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 20ms/step - loss: 293.3462 - val_loss: 303.2210\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 6ms/step - loss: 283.5043 - val_loss: 291.9655\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 6ms/step - loss: 274.3144 - val_loss: 281.7318\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 7ms/step - loss: 265.8734 - val_loss: 271.7853\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 15ms/step - loss: 257.9868 - val_loss: 262.5616\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 250.5787 - val_loss: 254.3456\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 10ms/step - loss: 243.8742 - val_loss: 246.5189\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 237.6132 - val_loss: 239.5269\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 232.0240 - val_loss: 232.6038\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 6ms/step - loss: 226.5789 - val_loss: 226.3321\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.7719 - val_loss: 220.1746\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 7ms/step - loss: 217.0596 - val_loss: 214.8667\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 7ms/step - loss: 212.9908 - val_loss: 209.3430\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 9ms/step - loss: 208.9388 - val_loss: 204.8744\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 14ms/step - loss: 205.5304 - val_loss: 200.1315\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 6ms/step - loss: 202.0227 - val_loss: 196.0092\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 8ms/step - loss: 198.9905 - val_loss: 192.1873\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 6ms/step - loss: 196.1461 - val_loss: 188.5175\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 193.4111 - val_loss: 185.3526\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.1552 - val_loss: 181.9717\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 8ms/step - loss: 188.6801 - val_loss: 179.3332\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.6131 - val_loss: 176.5773\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 13ms/step - loss: 184.6323 - val_loss: 173.9325\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 8ms/step - loss: 182.7025 - val_loss: 171.4135\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 10ms/step - loss: 180.8836 - val_loss: 169.2222\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 8ms/step - loss: 179.2421 - val_loss: 167.1296\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 6ms/step - loss: 177.7559 - val_loss: 165.0182\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 8ms/step - loss: 176.2804 - val_loss: 163.1986\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 8ms/step - loss: 174.8596 - val_loss: 161.4176\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 14ms/step - loss: 173.5178 - val_loss: 159.6243\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 6ms/step - loss: 172.1553 - val_loss: 157.8711\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 7ms/step - loss: 170.9225 - val_loss: 156.2477\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 14ms/step - loss: 169.7594 - val_loss: 154.6631\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 7ms/step - loss: 168.6431 - val_loss: 153.3772\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.5958 - val_loss: 152.0191\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 3ms/step - loss: 166.5415 - val_loss: 150.8191\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 6ms/step - loss: 165.5629 - val_loss: 149.5749\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 12ms/step - loss: 164.6169 - val_loss: 148.4221\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.6309 - val_loss: 147.3810\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 6ms/step - loss: 162.7636 - val_loss: 146.0508\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.8334 - val_loss: 144.9466\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.9687 - val_loss: 143.9223\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.0941 - val_loss: 143.0742\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 79ms/step - loss: 1549.4834 - val_loss: 1531.2161\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1534.8899 - val_loss: 1516.9150\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1519.8004 - val_loss: 1501.9498\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 7ms/step - loss: 1503.6538 - val_loss: 1486.2235\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1486.5953 - val_loss: 1468.7720\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 7ms/step - loss: 1467.9663 - val_loss: 1449.9076\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 6ms/step - loss: 1447.7343 - val_loss: 1430.1808\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 6ms/step - loss: 1426.3124 - val_loss: 1408.5674\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 8ms/step - loss: 1403.2860 - val_loss: 1384.8408\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 3ms/step - loss: 1377.9325 - val_loss: 1360.2389\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 1351.4072 - val_loss: 1334.0468\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 1323.1200 - val_loss: 1305.6973\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 3ms/step - loss: 1293.0292 - val_loss: 1276.9395\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 1262.6880 - val_loss: 1246.1427\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 6ms/step - loss: 1230.1581 - val_loss: 1215.3574\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 1197.5884 - val_loss: 1183.4225\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 1164.2648 - val_loss: 1150.5579\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1130.2385 - val_loss: 1117.3617\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1095.3302 - val_loss: 1084.3558\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 1060.7111 - val_loss: 1050.7592\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1026.3962 - val_loss: 1016.4662\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 991.4156 - val_loss: 983.5775\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 957.7770 - val_loss: 949.8465\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 923.9269 - val_loss: 917.4986\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 6ms/step - loss: 891.0093 - val_loss: 885.4230\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 7ms/step - loss: 858.8187 - val_loss: 854.1454\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 827.8181 - val_loss: 823.1583\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 797.0715 - val_loss: 793.7304\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 767.6099 - val_loss: 764.4249\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 7ms/step - loss: 738.8342 - val_loss: 735.7779\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 710.9694 - val_loss: 707.2277\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 683.4805 - val_loss: 679.8554\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 3ms/step - loss: 657.0885 - val_loss: 653.6726\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 631.6674 - val_loss: 628.1298\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 3ms/step - loss: 607.0799 - val_loss: 602.4535\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 583.1040 - val_loss: 577.5746\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 7ms/step - loss: 559.8343 - val_loss: 554.1656\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 537.5471 - val_loss: 531.3128\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 516.3852 - val_loss: 509.0496\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 7ms/step - loss: 495.6805 - val_loss: 488.0120\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 476.0053 - val_loss: 467.6671\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 457.4789 - val_loss: 447.2890\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 7ms/step - loss: 438.8586 - val_loss: 428.5375\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 14ms/step - loss: 421.5479 - val_loss: 410.4315\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 10ms/step - loss: 404.8765 - val_loss: 392.5240\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 388.7787 - val_loss: 375.4887\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 8ms/step - loss: 373.2928 - val_loss: 359.5183\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 3ms/step - loss: 358.9674 - val_loss: 344.0574\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 7ms/step - loss: 344.9410 - val_loss: 329.0284\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 331.4240 - val_loss: 315.1743\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 318.9579 - val_loss: 302.0188\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 307.0187 - val_loss: 289.4564\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 295.5281 - val_loss: 277.6003\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 284.7593 - val_loss: 266.2535\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 274.5950 - val_loss: 255.4814\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 264.9435 - val_loss: 245.4312\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 255.8394 - val_loss: 236.2850\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 247.5416 - val_loss: 227.7192\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 239.5824 - val_loss: 219.7525\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 232.3748 - val_loss: 212.1997\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 225.5281 - val_loss: 205.2832\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 219.1077 - val_loss: 199.0142\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 213.2051 - val_loss: 193.1916\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 207.7072 - val_loss: 187.9026\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 7ms/step - loss: 202.6958 - val_loss: 183.0342\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 6ms/step - loss: 198.0971 - val_loss: 178.6222\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 193.8504 - val_loss: 175.2673\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 190.1160 - val_loss: 171.3430\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.3699 - val_loss: 168.3142\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.1935 - val_loss: 165.2902\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.0866 - val_loss: 162.8343\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 6ms/step - loss: 177.4391 - val_loss: 160.4640\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.0674 - val_loss: 158.3536\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 3ms/step - loss: 172.7445 - val_loss: 156.5535\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.8023 - val_loss: 154.8688\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.8947 - val_loss: 153.2607\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.1092 - val_loss: 151.9505\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.6147 - val_loss: 150.6241\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 164.2223 - val_loss: 149.5175\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.8536 - val_loss: 148.6000\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.7192 - val_loss: 147.5883\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.5497 - val_loss: 146.7935\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 159.5200 - val_loss: 146.0453\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 3ms/step - loss: 158.5730 - val_loss: 145.3302\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.7588 - val_loss: 144.6526\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 14ms/step - loss: 156.8192 - val_loss: 144.1865\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 6ms/step - loss: 156.1290 - val_loss: 143.7657\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 155.1594 - val_loss: 143.1595\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 6ms/step - loss: 154.4629 - val_loss: 142.7178\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.8265 - val_loss: 142.2932\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.0952 - val_loss: 141.6607\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.5239 - val_loss: 141.2182\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.8445 - val_loss: 140.7128\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 9ms/step - loss: 151.1880 - val_loss: 140.1921\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.5936 - val_loss: 139.7273\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.0386 - val_loss: 139.2370\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 149.4344 - val_loss: 138.8085\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 148.8098 - val_loss: 138.3863\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 148.2157 - val_loss: 137.9515\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 6ms/step - loss: 147.6575 - val_loss: 137.3635\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 66ms/step - loss: 1575.1617 - val_loss: 1534.6241\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 16ms/step - loss: 1558.2355 - val_loss: 1518.7699\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1541.6948 - val_loss: 1503.1300\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 1525.2550 - val_loss: 1487.5775\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 1508.9717 - val_loss: 1471.3636\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 1492.0706 - val_loss: 1454.9993\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 3ms/step - loss: 1474.8357 - val_loss: 1437.9554\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1456.6836 - val_loss: 1420.6299\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 1438.0471 - val_loss: 1402.0300\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1418.3591 - val_loss: 1382.6302\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 1397.6150 - val_loss: 1362.5581\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 1376.0254 - val_loss: 1341.6013\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 8ms/step - loss: 1353.4548 - val_loss: 1319.4738\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 1329.7604 - val_loss: 1296.5588\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 1304.7556 - val_loss: 1272.7787\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 9ms/step - loss: 1279.0894 - val_loss: 1247.8933\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 1251.7563 - val_loss: 1222.0010\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 8ms/step - loss: 1223.3584 - val_loss: 1195.1848\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 17ms/step - loss: 1193.8345 - val_loss: 1166.9130\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 7ms/step - loss: 1163.1121 - val_loss: 1138.1763\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 7ms/step - loss: 1131.8444 - val_loss: 1108.3514\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 17ms/step - loss: 1099.8125 - val_loss: 1077.5681\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 6ms/step - loss: 1066.7101 - val_loss: 1046.9955\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 1033.4330 - val_loss: 1014.7913\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 14ms/step - loss: 999.0210 - val_loss: 982.7960\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 19ms/step - loss: 964.7686 - val_loss: 949.7114\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 929.7335 - val_loss: 916.6178\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 894.5058 - val_loss: 882.8546\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 10ms/step - loss: 858.5219 - val_loss: 849.6600\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 822.9570 - val_loss: 816.0805\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 9ms/step - loss: 788.0309 - val_loss: 782.1976\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 752.8508 - val_loss: 749.4350\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 718.5684 - val_loss: 717.2387\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 685.5116 - val_loss: 684.9054\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 652.5846 - val_loss: 654.2653\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 621.2574 - val_loss: 624.3022\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 591.3611 - val_loss: 594.8763\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 562.1830 - val_loss: 567.5438\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 535.2004 - val_loss: 540.6776\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 6ms/step - loss: 509.1882 - val_loss: 515.6422\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 484.7168 - val_loss: 492.0492\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 461.5347 - val_loss: 469.6353\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 8ms/step - loss: 439.9660 - val_loss: 448.1150\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 419.5023 - val_loss: 428.2821\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 6ms/step - loss: 400.8320 - val_loss: 409.4258\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 383.2936 - val_loss: 391.8583\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 6ms/step - loss: 367.1969 - val_loss: 375.4054\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 352.3204 - val_loss: 360.0717\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 7ms/step - loss: 338.4916 - val_loss: 345.9426\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 6ms/step - loss: 325.9777 - val_loss: 333.0172\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 314.5677 - val_loss: 320.7130\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 7ms/step - loss: 303.8712 - val_loss: 309.6253\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 7ms/step - loss: 294.2323 - val_loss: 299.1204\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 19ms/step - loss: 285.2902 - val_loss: 289.5755\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 11ms/step - loss: 277.2270 - val_loss: 280.9109\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 9ms/step - loss: 270.1072 - val_loss: 272.2182\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 7ms/step - loss: 262.9801 - val_loss: 265.0569\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 14ms/step - loss: 256.9789 - val_loss: 257.9857\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 251.3181 - val_loss: 251.0937\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 245.9596 - val_loss: 245.0965\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 9ms/step - loss: 241.2408 - val_loss: 239.6243\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 236.8275 - val_loss: 234.1897\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 6ms/step - loss: 232.6364 - val_loss: 229.4879\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 228.8585 - val_loss: 225.1328\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 18ms/step - loss: 225.3419 - val_loss: 220.9855\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 10ms/step - loss: 222.0175 - val_loss: 217.1673\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 10ms/step - loss: 218.9531 - val_loss: 213.4268\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 15ms/step - loss: 215.9438 - val_loss: 210.3976\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 6ms/step - loss: 213.2333 - val_loss: 206.8093\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 210.5279 - val_loss: 203.9695\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 7ms/step - loss: 208.0731 - val_loss: 201.1121\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 14ms/step - loss: 205.7870 - val_loss: 198.4435\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 6ms/step - loss: 203.5892 - val_loss: 195.9500\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 7ms/step - loss: 201.5851 - val_loss: 193.6365\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.6467 - val_loss: 191.5283\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 8ms/step - loss: 197.7625 - val_loss: 189.4277\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 7ms/step - loss: 196.0339 - val_loss: 187.5451\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 11ms/step - loss: 194.3412 - val_loss: 185.5754\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 9ms/step - loss: 192.6318 - val_loss: 183.8042\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 21ms/step - loss: 191.0937 - val_loss: 182.0580\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 9ms/step - loss: 189.5457 - val_loss: 180.2995\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 15ms/step - loss: 188.0022 - val_loss: 178.8375\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 17ms/step - loss: 186.6205 - val_loss: 177.2041\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 11ms/step - loss: 185.2537 - val_loss: 175.8510\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 7ms/step - loss: 184.0168 - val_loss: 174.3979\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 7ms/step - loss: 182.6994 - val_loss: 173.1842\n",
      "Epoch 87/100\n",
      "23/23 - 1s - 30ms/step - loss: 181.5044 - val_loss: 171.9248\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 10ms/step - loss: 180.2800 - val_loss: 170.7476\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 20ms/step - loss: 179.2785 - val_loss: 169.5036\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 14ms/step - loss: 178.0270 - val_loss: 168.2928\n",
      "Epoch 91/100\n",
      "23/23 - 1s - 43ms/step - loss: 176.9174 - val_loss: 167.4689\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 15ms/step - loss: 175.8764 - val_loss: 166.2300\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 13ms/step - loss: 174.8611 - val_loss: 165.1804\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 13ms/step - loss: 173.8671 - val_loss: 164.3943\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 12ms/step - loss: 172.9691 - val_loss: 163.4476\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 11ms/step - loss: 171.9883 - val_loss: 162.6627\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 7ms/step - loss: 171.1136 - val_loss: 161.7432\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 15ms/step - loss: 170.2137 - val_loss: 160.9581\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 6ms/step - loss: 169.4559 - val_loss: 160.0287\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 168.5814 - val_loss: 159.3541\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 122ms/step - loss: 1601.8593 - val_loss: 1545.9343\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 22ms/step - loss: 1586.2864 - val_loss: 1531.2791\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 6ms/step - loss: 1571.6522 - val_loss: 1517.1989\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 8ms/step - loss: 1557.3566 - val_loss: 1503.5186\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 7ms/step - loss: 1543.5358 - val_loss: 1490.1760\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 6ms/step - loss: 1529.9553 - val_loss: 1476.9089\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 7ms/step - loss: 1516.3804 - val_loss: 1463.6211\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 7ms/step - loss: 1502.8000 - val_loss: 1450.1725\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 6ms/step - loss: 1488.9934 - val_loss: 1436.6348\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 7ms/step - loss: 1475.0284 - val_loss: 1422.7031\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 8ms/step - loss: 1460.7334 - val_loss: 1408.6287\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 6ms/step - loss: 1446.2286 - val_loss: 1393.6494\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 7ms/step - loss: 1430.9211 - val_loss: 1378.3210\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 7ms/step - loss: 1415.0585 - val_loss: 1362.1672\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 7ms/step - loss: 1398.3113 - val_loss: 1345.1943\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 7ms/step - loss: 1380.9174 - val_loss: 1326.8027\n",
      "Epoch 17/100\n",
      "23/23 - 1s - 23ms/step - loss: 1362.5305 - val_loss: 1307.5148\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 8ms/step - loss: 1342.8895 - val_loss: 1287.2849\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 6ms/step - loss: 1322.3138 - val_loss: 1265.8518\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 1300.5176 - val_loss: 1242.9968\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 1277.3273 - val_loss: 1218.6466\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 1252.8127 - val_loss: 1193.1693\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 6ms/step - loss: 1226.9912 - val_loss: 1166.4419\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 7ms/step - loss: 1199.8840 - val_loss: 1138.6156\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1171.8710 - val_loss: 1109.5255\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 8ms/step - loss: 1142.9403 - val_loss: 1079.4181\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 1113.0724 - val_loss: 1048.7166\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 9ms/step - loss: 1082.8778 - val_loss: 1017.5631\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 12ms/step - loss: 1052.1273 - val_loss: 986.1547\n",
      "Epoch 30/100\n",
      "23/23 - 1s - 56ms/step - loss: 1021.0814 - val_loss: 954.6838\n",
      "Epoch 31/100\n",
      "23/23 - 1s - 34ms/step - loss: 989.6737 - val_loss: 923.0562\n",
      "Epoch 32/100\n",
      "23/23 - 1s - 31ms/step - loss: 958.6270 - val_loss: 891.4096\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 7ms/step - loss: 927.5817 - val_loss: 859.9152\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 18ms/step - loss: 896.5463 - val_loss: 829.3433\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 8ms/step - loss: 866.1931 - val_loss: 798.5742\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 8ms/step - loss: 835.4231 - val_loss: 769.0253\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 8ms/step - loss: 805.8558 - val_loss: 738.6337\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 775.5812 - val_loss: 709.9854\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 6ms/step - loss: 746.2754 - val_loss: 680.8516\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 6ms/step - loss: 717.0742 - val_loss: 652.0697\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 688.1854 - val_loss: 623.5276\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 9ms/step - loss: 659.3204 - val_loss: 595.9345\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 14ms/step - loss: 630.9877 - val_loss: 568.3480\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 12ms/step - loss: 602.9854 - val_loss: 541.7023\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 18ms/step - loss: 575.5591 - val_loss: 515.9518\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 9ms/step - loss: 548.9951 - val_loss: 490.7424\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 10ms/step - loss: 522.8481 - val_loss: 467.0036\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 18ms/step - loss: 498.2321 - val_loss: 443.9409\n",
      "Epoch 49/100\n",
      "23/23 - 1s - 25ms/step - loss: 474.4365 - val_loss: 422.7667\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 452.2005 - val_loss: 402.8896\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 431.1965 - val_loss: 384.0677\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 411.2122 - val_loss: 367.1367\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 7ms/step - loss: 392.6399 - val_loss: 351.4110\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 9ms/step - loss: 375.4240 - val_loss: 337.2048\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 6ms/step - loss: 359.3768 - val_loss: 324.2246\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 8ms/step - loss: 344.6455 - val_loss: 312.3724\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 14ms/step - loss: 331.0804 - val_loss: 301.1040\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 14ms/step - loss: 318.3936 - val_loss: 291.0703\n",
      "Epoch 59/100\n",
      "23/23 - 1s - 23ms/step - loss: 306.5449 - val_loss: 282.4482\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 296.0688 - val_loss: 274.5060\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 6ms/step - loss: 286.5049 - val_loss: 267.2341\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 6ms/step - loss: 277.4723 - val_loss: 260.9331\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 269.5450 - val_loss: 255.0717\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 10ms/step - loss: 262.2957 - val_loss: 250.0027\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 255.7663 - val_loss: 245.4103\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 249.8137 - val_loss: 241.1087\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 244.0996 - val_loss: 237.5469\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 6ms/step - loss: 239.1774 - val_loss: 234.1828\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 15ms/step - loss: 234.6696 - val_loss: 231.0421\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 230.5880 - val_loss: 228.1629\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 7ms/step - loss: 226.6051 - val_loss: 225.5697\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 6ms/step - loss: 223.0322 - val_loss: 223.2562\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 219.7386 - val_loss: 220.9462\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 9ms/step - loss: 216.6830 - val_loss: 218.8435\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 6ms/step - loss: 213.7640 - val_loss: 216.6992\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 211.0999 - val_loss: 214.8408\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 208.5918 - val_loss: 212.9431\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.1896 - val_loss: 211.1154\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 203.9815 - val_loss: 209.3823\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 8ms/step - loss: 201.6776 - val_loss: 207.7096\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.6108 - val_loss: 205.9153\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 8ms/step - loss: 197.6279 - val_loss: 204.1266\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 6ms/step - loss: 195.7063 - val_loss: 202.3807\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.7127 - val_loss: 200.8359\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 7ms/step - loss: 191.9880 - val_loss: 199.2248\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.1289 - val_loss: 197.5216\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 7ms/step - loss: 188.3918 - val_loss: 195.9893\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 186.6938 - val_loss: 194.2859\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 8ms/step - loss: 185.0797 - val_loss: 192.7116\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 6ms/step - loss: 183.4220 - val_loss: 191.0432\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 6ms/step - loss: 181.9242 - val_loss: 189.7405\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.3158 - val_loss: 188.0497\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 9ms/step - loss: 178.8542 - val_loss: 186.5316\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 8ms/step - loss: 177.3630 - val_loss: 185.1536\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 7ms/step - loss: 175.9376 - val_loss: 183.4762\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 14ms/step - loss: 174.5158 - val_loss: 181.9822\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.0824 - val_loss: 180.4614\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 7ms/step - loss: 171.6887 - val_loss: 179.0007\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 15ms/step - loss: 170.2880 - val_loss: 177.7214\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.0134 - val_loss: 176.2552\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 104ms/step - loss: 1596.4678 - val_loss: 1544.0859\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 15ms/step - loss: 1580.2280 - val_loss: 1528.7809\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 6ms/step - loss: 1564.7042 - val_loss: 1513.8831\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 7ms/step - loss: 1549.5553 - val_loss: 1498.9880\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1534.4469 - val_loss: 1483.8479\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1519.0161 - val_loss: 1468.3412\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 9ms/step - loss: 1503.3186 - val_loss: 1452.4266\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1487.0145 - val_loss: 1436.2883\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 1470.4906 - val_loss: 1419.1854\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 8ms/step - loss: 1453.1943 - val_loss: 1401.5764\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 7ms/step - loss: 1435.2175 - val_loss: 1383.6404\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 6ms/step - loss: 1416.8947 - val_loss: 1364.6106\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 1397.8899 - val_loss: 1345.1384\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 1378.2791 - val_loss: 1325.3153\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 7ms/step - loss: 1357.7876 - val_loss: 1305.2472\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 1336.8257 - val_loss: 1284.3130\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 1315.3765 - val_loss: 1262.3352\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 1292.9927 - val_loss: 1239.8705\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 1270.0160 - val_loss: 1216.8085\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 6ms/step - loss: 1246.1680 - val_loss: 1193.2739\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 1221.9562 - val_loss: 1168.7542\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 1196.7325 - val_loss: 1143.8016\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 1170.8892 - val_loss: 1117.8958\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 1144.0309 - val_loss: 1091.3700\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 8ms/step - loss: 1116.4429 - val_loss: 1065.1388\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 1088.8073 - val_loss: 1037.5315\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 1060.6381 - val_loss: 1009.6690\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 11ms/step - loss: 1031.9009 - val_loss: 981.8393\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 1002.8165 - val_loss: 954.0289\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 6ms/step - loss: 973.9117 - val_loss: 926.0707\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 944.9230 - val_loss: 898.1650\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 6ms/step - loss: 915.9014 - val_loss: 870.7878\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 9ms/step - loss: 887.4521 - val_loss: 842.6724\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 858.3210 - val_loss: 815.8088\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 830.0034 - val_loss: 789.3927\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 6ms/step - loss: 802.0145 - val_loss: 762.9389\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 6ms/step - loss: 774.1512 - val_loss: 737.2914\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 8ms/step - loss: 747.1213 - val_loss: 711.8480\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 7ms/step - loss: 720.0870 - val_loss: 687.2814\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 693.8445 - val_loss: 663.1357\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 667.9877 - val_loss: 639.4611\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 6ms/step - loss: 642.7098 - val_loss: 616.5207\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 6ms/step - loss: 618.0275 - val_loss: 594.4406\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 6ms/step - loss: 593.7743 - val_loss: 573.1534\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 6ms/step - loss: 570.2343 - val_loss: 551.8309\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 8ms/step - loss: 547.0680 - val_loss: 531.3328\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 524.6776 - val_loss: 511.1564\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 502.5725 - val_loss: 492.5753\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 482.0204 - val_loss: 473.9775\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 461.8466 - val_loss: 456.6084\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 7ms/step - loss: 442.6157 - val_loss: 440.1422\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 424.2891 - val_loss: 424.6109\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 6ms/step - loss: 406.7141 - val_loss: 409.6493\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 390.3239 - val_loss: 395.0975\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 9ms/step - loss: 374.2033 - val_loss: 382.0833\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 359.5966 - val_loss: 369.3087\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 345.5789 - val_loss: 357.6172\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 332.5388 - val_loss: 346.4357\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 10ms/step - loss: 320.0785 - val_loss: 336.4715\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 6ms/step - loss: 308.6786 - val_loss: 326.9153\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 298.0155 - val_loss: 317.9148\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 8ms/step - loss: 288.2295 - val_loss: 309.3351\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 278.7074 - val_loss: 301.7905\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 14ms/step - loss: 270.1074 - val_loss: 294.5182\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 6ms/step - loss: 261.9012 - val_loss: 287.6241\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 7ms/step - loss: 254.2885 - val_loss: 281.3312\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 6ms/step - loss: 247.3602 - val_loss: 275.4276\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 240.8351 - val_loss: 269.9051\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 8ms/step - loss: 234.8342 - val_loss: 264.5349\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 229.2719 - val_loss: 259.6821\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 6ms/step - loss: 224.0002 - val_loss: 255.1466\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 7ms/step - loss: 219.1898 - val_loss: 250.9665\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 6ms/step - loss: 214.7026 - val_loss: 246.9365\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 7ms/step - loss: 210.6317 - val_loss: 243.2115\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.6967 - val_loss: 239.8325\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 9ms/step - loss: 203.1814 - val_loss: 236.6224\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 7ms/step - loss: 199.9270 - val_loss: 233.4666\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.8558 - val_loss: 230.6707\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.9791 - val_loss: 228.2331\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 6ms/step - loss: 191.3182 - val_loss: 225.4896\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 9ms/step - loss: 188.8267 - val_loss: 223.0306\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 13ms/step - loss: 186.4020 - val_loss: 220.8540\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 10ms/step - loss: 184.2088 - val_loss: 218.3135\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 182.0267 - val_loss: 216.2766\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.0262 - val_loss: 214.2357\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.1908 - val_loss: 212.1748\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 7ms/step - loss: 176.4173 - val_loss: 210.2629\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 174.8191 - val_loss: 208.2444\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.1093 - val_loss: 206.5620\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 7ms/step - loss: 171.5804 - val_loss: 204.7435\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 8ms/step - loss: 170.1102 - val_loss: 202.8256\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 6ms/step - loss: 168.6590 - val_loss: 200.9608\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 7ms/step - loss: 167.2631 - val_loss: 199.3094\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.9241 - val_loss: 197.7361\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 8ms/step - loss: 164.7436 - val_loss: 196.4371\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 8ms/step - loss: 163.3131 - val_loss: 194.2695\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 6ms/step - loss: 162.0054 - val_loss: 192.7193\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 8ms/step - loss: 160.7772 - val_loss: 191.3430\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 159.5732 - val_loss: 189.8710\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 8ms/step - loss: 158.2949 - val_loss: 188.3149\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Mean MSE with Normalized Data and 100 Epochs: 169.02386475491716\n",
      "Standard Deviation of MSE with Normalized Data and 100 Epochs: 18.66219906409647\n"
     ]
    }
   ],
   "source": [
    "# Store mean squared errors for 50 repetitions with 100 epochs\n",
    "mse_list_normalized_epochs = []\n",
    "\n",
    "for _ in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized, target, test_size=0.3, random_state=None)\n",
    "\n",
    "    # Build and train the model\n",
    "    model = regression_model(n_cols)\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=2)\n",
    "    \n",
    "    # Predict and calculate mean squared error\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list_normalized_epochs.append(mse)\n",
    "\n",
    "# Compute mean and standard deviation of the mean squared errors\n",
    "mean_mse_normalized_epochs = np.mean(mse_list_normalized_epochs)\n",
    "std_mse_normalized_epochs = np.std(mse_list_normalized_epochs)\n",
    "\n",
    "print(f'Mean MSE with Normalized Data and 100 Epochs: {mean_mse_normalized_epochs}')\n",
    "print(f'Standard Deviation of MSE with Normalized Data and 100 Epochs: {std_mse_normalized_epochs}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step D: Increase the number of hidden layers\n",
    "\n",
    "Repeat Step B but use a neural network with three hidden layers, each of 10 nodes and ReLU activation functions.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 3s - 126ms/step - loss: 1557.7328 - val_loss: 1666.5938\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1531.8289 - val_loss: 1644.8162\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1510.5758 - val_loss: 1623.2800\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1485.7734 - val_loss: 1595.2339\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1449.9451 - val_loss: 1550.6359\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1390.5719 - val_loss: 1474.0276\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 1290.7269 - val_loss: 1347.9346\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1134.4464 - val_loss: 1160.3452\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 916.5978 - val_loss: 904.9565\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 656.9376 - val_loss: 628.7718\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 425.4612 - val_loss: 429.9951\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 19ms/step - loss: 300.4482 - val_loss: 330.2072\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 250.6057 - val_loss: 287.6191\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 226.3378 - val_loss: 263.9034\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 10ms/step - loss: 210.5630 - val_loss: 243.6854\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 15ms/step - loss: 198.9827 - val_loss: 230.0036\n",
      "Epoch 17/50\n",
      "23/23 - 1s - 28ms/step - loss: 190.9242 - val_loss: 220.6376\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 10ms/step - loss: 184.3007 - val_loss: 210.2914\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 13ms/step - loss: 179.2057 - val_loss: 203.2511\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 174.7137 - val_loss: 196.2390\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 8ms/step - loss: 171.3154 - val_loss: 191.5463\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 167.8425 - val_loss: 186.7423\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 164.5646 - val_loss: 183.0071\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 161.9453 - val_loss: 180.0515\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 159.3447 - val_loss: 175.4501\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 156.8742 - val_loss: 173.4876\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.5850 - val_loss: 170.5438\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 152.6496 - val_loss: 165.2539\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.8188 - val_loss: 163.6716\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.7508 - val_loss: 164.2492\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 6ms/step - loss: 147.1739 - val_loss: 161.2925\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 145.5142 - val_loss: 158.6737\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 143.7242 - val_loss: 156.4700\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 142.1553 - val_loss: 154.0295\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 8ms/step - loss: 140.9664 - val_loss: 153.4426\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 14ms/step - loss: 139.2437 - val_loss: 149.5548\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 11ms/step - loss: 137.4138 - val_loss: 150.1865\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.1060 - val_loss: 147.6465\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 18ms/step - loss: 135.1047 - val_loss: 146.4998\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 11ms/step - loss: 133.6974 - val_loss: 144.3604\n",
      "Epoch 41/50\n",
      "23/23 - 1s - 24ms/step - loss: 132.1799 - val_loss: 143.1959\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 8ms/step - loss: 130.6894 - val_loss: 140.9560\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 129.5827 - val_loss: 140.8431\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 8ms/step - loss: 128.7086 - val_loss: 138.1951\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 7ms/step - loss: 127.6358 - val_loss: 136.9866\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 9ms/step - loss: 125.9991 - val_loss: 137.0497\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 11ms/step - loss: 124.6798 - val_loss: 134.7629\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 15ms/step - loss: 123.8309 - val_loss: 134.3552\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 8ms/step - loss: 122.8240 - val_loss: 132.2814\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 16ms/step - loss: 121.5257 - val_loss: 130.5885\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 4s - 159ms/step - loss: 1567.7059 - val_loss: 1597.2478\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 18ms/step - loss: 1551.3932 - val_loss: 1584.6736\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1541.3392 - val_loss: 1575.7606\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 8ms/step - loss: 1532.1257 - val_loss: 1565.5883\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 15ms/step - loss: 1519.3949 - val_loss: 1549.7285\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 8ms/step - loss: 1497.1855 - val_loss: 1520.1821\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 8ms/step - loss: 1454.2045 - val_loss: 1463.0919\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 6ms/step - loss: 1376.0349 - val_loss: 1358.9908\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 7ms/step - loss: 1237.3544 - val_loss: 1183.4302\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 15ms/step - loss: 1020.4080 - val_loss: 926.0573\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 741.0279 - val_loss: 637.8086\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 7ms/step - loss: 473.4846 - val_loss: 422.5653\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 314.8629 - val_loss: 329.9901\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 7ms/step - loss: 264.1388 - val_loss: 300.2823\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 6ms/step - loss: 241.0137 - val_loss: 278.1982\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 224.8524 - val_loss: 261.3930\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 6ms/step - loss: 212.7453 - val_loss: 248.4675\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 7ms/step - loss: 202.9536 - val_loss: 238.9660\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 195.3435 - val_loss: 228.7139\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 7ms/step - loss: 188.6459 - val_loss: 221.4973\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 14ms/step - loss: 183.1753 - val_loss: 213.9342\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 178.0572 - val_loss: 208.0903\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 7ms/step - loss: 173.9250 - val_loss: 203.0139\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 170.1346 - val_loss: 197.9785\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 166.5519 - val_loss: 194.1776\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 163.4922 - val_loss: 191.1368\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 7ms/step - loss: 160.4369 - val_loss: 187.2648\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 7ms/step - loss: 157.7817 - val_loss: 184.3738\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 155.3843 - val_loss: 181.4010\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 153.3405 - val_loss: 179.0361\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 6ms/step - loss: 151.0130 - val_loss: 176.1717\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 149.0222 - val_loss: 174.1205\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 147.1689 - val_loss: 172.1976\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 145.2735 - val_loss: 169.8156\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 7ms/step - loss: 143.5781 - val_loss: 167.9716\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 142.2352 - val_loss: 165.9794\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 140.8985 - val_loss: 164.6514\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 139.9299 - val_loss: 162.6514\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 13ms/step - loss: 138.1254 - val_loss: 162.0332\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 7ms/step - loss: 136.8464 - val_loss: 160.0267\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 135.9571 - val_loss: 158.1706\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 134.5783 - val_loss: 156.6819\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 7ms/step - loss: 133.6357 - val_loss: 155.6308\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 8ms/step - loss: 132.2584 - val_loss: 154.0910\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 131.0577 - val_loss: 152.8218\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 8ms/step - loss: 130.0329 - val_loss: 151.7537\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 128.9066 - val_loss: 150.1179\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 7ms/step - loss: 127.9385 - val_loss: 148.9933\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 127.3406 - val_loss: 148.0262\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 126.1009 - val_loss: 146.8609\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 4s - 153ms/step - loss: 1538.5317 - val_loss: 1546.9985\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 21ms/step - loss: 1512.4261 - val_loss: 1516.9131\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 8ms/step - loss: 1475.5151 - val_loss: 1472.1763\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 18ms/step - loss: 1420.9556 - val_loss: 1404.6317\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 20ms/step - loss: 1338.9467 - val_loss: 1305.6776\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 9ms/step - loss: 1220.6730 - val_loss: 1168.6932\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1063.3456 - val_loss: 991.2857\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 869.8240 - val_loss: 783.7086\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 656.7034 - val_loss: 570.5842\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 456.8333 - val_loss: 393.3559\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 320.2893 - val_loss: 289.3164\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 6ms/step - loss: 254.2148 - val_loss: 247.2012\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 228.8303 - val_loss: 231.9122\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 215.8984 - val_loss: 223.6025\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 7ms/step - loss: 206.9076 - val_loss: 216.0849\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 7ms/step - loss: 199.6822 - val_loss: 209.5230\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 193.4091 - val_loss: 203.9165\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 187.6875 - val_loss: 198.0462\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 182.8895 - val_loss: 193.2400\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 177.7683 - val_loss: 188.3990\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 173.4770 - val_loss: 184.3878\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.0959 - val_loss: 179.1871\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 165.2395 - val_loss: 175.4512\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 160.9408 - val_loss: 170.7529\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.2226 - val_loss: 167.2754\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 153.3515 - val_loss: 163.0994\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 16ms/step - loss: 149.9265 - val_loss: 159.6348\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 7ms/step - loss: 146.5998 - val_loss: 156.2032\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 143.2317 - val_loss: 153.1601\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 140.6431 - val_loss: 150.0662\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 8ms/step - loss: 137.6624 - val_loss: 146.7069\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 135.1071 - val_loss: 143.6530\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 132.3345 - val_loss: 141.1696\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 130.0686 - val_loss: 138.7471\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 127.6631 - val_loss: 136.2526\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 10ms/step - loss: 125.3359 - val_loss: 133.8847\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 11ms/step - loss: 123.5888 - val_loss: 130.9554\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 12ms/step - loss: 121.4917 - val_loss: 129.4814\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 6ms/step - loss: 119.6249 - val_loss: 127.1236\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 16ms/step - loss: 117.1041 - val_loss: 125.7371\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 115.4946 - val_loss: 123.0120\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 7ms/step - loss: 113.9888 - val_loss: 121.8900\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 7ms/step - loss: 111.9822 - val_loss: 119.4641\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.4044 - val_loss: 118.1971\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 8ms/step - loss: 108.8526 - val_loss: 116.2530\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 107.4844 - val_loss: 114.4445\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 105.9239 - val_loss: 113.1585\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 9ms/step - loss: 104.5750 - val_loss: 111.8284\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 8ms/step - loss: 103.3931 - val_loss: 109.9335\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 101.7883 - val_loss: 108.8377\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 144ms/step - loss: 1578.2247 - val_loss: 1567.5187\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 6ms/step - loss: 1566.0223 - val_loss: 1556.1578\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1555.1210 - val_loss: 1544.1229\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 8ms/step - loss: 1542.1981 - val_loss: 1528.3434\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 9ms/step - loss: 1524.3317 - val_loss: 1506.2260\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 1497.6847 - val_loss: 1469.8270\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 1455.4702 - val_loss: 1414.0476\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 8ms/step - loss: 1391.4396 - val_loss: 1332.3787\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 1299.2206 - val_loss: 1214.3934\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 1164.4194 - val_loss: 1048.1431\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 977.1537 - val_loss: 829.7719\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 751.0693 - val_loss: 583.4482\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 515.1552 - val_loss: 374.3179\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 342.5756 - val_loss: 264.2870\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 9ms/step - loss: 259.9323 - val_loss: 229.6749\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 230.8409 - val_loss: 217.9636\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 9ms/step - loss: 217.4416 - val_loss: 209.6989\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 13ms/step - loss: 207.9983 - val_loss: 203.6922\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 12ms/step - loss: 200.8576 - val_loss: 198.6028\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 7ms/step - loss: 194.7558 - val_loss: 193.9212\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 189.7104 - val_loss: 189.3286\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 184.0611 - val_loss: 186.0458\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 8ms/step - loss: 179.0419 - val_loss: 181.5220\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 15ms/step - loss: 174.6037 - val_loss: 177.0169\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 170.5365 - val_loss: 173.2483\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.8954 - val_loss: 169.9058\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 162.0739 - val_loss: 166.0711\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 10ms/step - loss: 158.1506 - val_loss: 163.4426\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 7ms/step - loss: 154.4452 - val_loss: 158.9337\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 18ms/step - loss: 150.8557 - val_loss: 155.8738\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 8ms/step - loss: 147.6026 - val_loss: 153.7345\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 17ms/step - loss: 144.3686 - val_loss: 149.9735\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 141.1057 - val_loss: 147.2838\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 9ms/step - loss: 138.0835 - val_loss: 144.5763\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 13ms/step - loss: 134.9742 - val_loss: 141.7317\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 8ms/step - loss: 132.2873 - val_loss: 138.8551\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 129.4995 - val_loss: 137.0744\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 14ms/step - loss: 126.7366 - val_loss: 133.6994\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 6ms/step - loss: 124.3048 - val_loss: 131.7215\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 121.8022 - val_loss: 129.8946\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 10ms/step - loss: 119.4428 - val_loss: 127.2714\n",
      "Epoch 42/50\n",
      "23/23 - 1s - 23ms/step - loss: 117.3380 - val_loss: 124.8258\n",
      "Epoch 43/50\n",
      "23/23 - 1s - 22ms/step - loss: 115.3345 - val_loss: 122.9745\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 9ms/step - loss: 113.1141 - val_loss: 120.5480\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 15ms/step - loss: 110.9535 - val_loss: 118.5254\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 15ms/step - loss: 109.1770 - val_loss: 116.1254\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 8ms/step - loss: 107.1993 - val_loss: 114.4347\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 11ms/step - loss: 105.6143 - val_loss: 111.9652\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 8ms/step - loss: 103.6257 - val_loss: 110.9479\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 11ms/step - loss: 102.1488 - val_loss: 108.1725\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 9s - 392ms/step - loss: 1554.7897 - val_loss: 1524.2806\n",
      "Epoch 2/50\n",
      "23/23 - 1s - 34ms/step - loss: 1521.7169 - val_loss: 1487.7458\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1480.7443 - val_loss: 1440.2740\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 8ms/step - loss: 1426.0507 - val_loss: 1376.5354\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 14ms/step - loss: 1354.2250 - val_loss: 1293.1803\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 8ms/step - loss: 1260.4760 - val_loss: 1183.8643\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 14ms/step - loss: 1138.7108 - val_loss: 1042.5476\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 15ms/step - loss: 981.9241 - val_loss: 870.6019\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 16ms/step - loss: 799.6252 - val_loss: 674.0546\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 12ms/step - loss: 606.2751 - val_loss: 489.2300\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 16ms/step - loss: 439.0280 - val_loss: 356.5842\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 12ms/step - loss: 332.6374 - val_loss: 287.4865\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 12ms/step - loss: 277.7532 - val_loss: 261.3446\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 7ms/step - loss: 251.5471 - val_loss: 249.6624\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 6ms/step - loss: 236.6273 - val_loss: 239.9731\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 7ms/step - loss: 225.7708 - val_loss: 232.6767\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 8ms/step - loss: 217.1271 - val_loss: 224.8822\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 13ms/step - loss: 209.0934 - val_loss: 218.3752\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 7ms/step - loss: 202.5258 - val_loss: 212.0412\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 14ms/step - loss: 196.9407 - val_loss: 207.4029\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 192.1829 - val_loss: 200.9441\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 7ms/step - loss: 186.3319 - val_loss: 197.2138\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 7ms/step - loss: 182.2225 - val_loss: 192.1953\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 178.2247 - val_loss: 187.9908\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 174.5456 - val_loss: 183.3366\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 170.8622 - val_loss: 179.7845\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 167.3318 - val_loss: 176.3379\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 7ms/step - loss: 164.5380 - val_loss: 173.3173\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 8ms/step - loss: 161.0628 - val_loss: 168.5848\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 158.2993 - val_loss: 165.3562\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 7ms/step - loss: 155.8313 - val_loss: 163.2751\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 153.1662 - val_loss: 160.5025\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 7ms/step - loss: 150.4851 - val_loss: 157.2930\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 7ms/step - loss: 148.1211 - val_loss: 155.1211\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 145.6652 - val_loss: 152.9561\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 7ms/step - loss: 143.4127 - val_loss: 149.6661\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 141.3213 - val_loss: 147.6015\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 8ms/step - loss: 138.8161 - val_loss: 145.6590\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 7ms/step - loss: 136.8742 - val_loss: 143.0155\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 15ms/step - loss: 134.9914 - val_loss: 140.8691\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 12ms/step - loss: 132.7363 - val_loss: 138.4693\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 7ms/step - loss: 130.8411 - val_loss: 136.0741\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 14ms/step - loss: 128.9351 - val_loss: 133.7080\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 7ms/step - loss: 127.1139 - val_loss: 131.9758\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 9ms/step - loss: 125.3468 - val_loss: 130.0408\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 123.4243 - val_loss: 127.8881\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 121.6904 - val_loss: 126.3826\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 7ms/step - loss: 120.1480 - val_loss: 124.1907\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 8ms/step - loss: 118.6712 - val_loss: 122.5489\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 7ms/step - loss: 117.0995 - val_loss: 120.5128\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 4s - 166ms/step - loss: 1492.4988 - val_loss: 1563.3206\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 8ms/step - loss: 1449.9005 - val_loss: 1505.3027\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1384.5857 - val_loss: 1417.1259\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 7ms/step - loss: 1284.0940 - val_loss: 1282.6240\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1141.0435 - val_loss: 1099.3286\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 955.9312 - val_loss: 874.3796\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 7ms/step - loss: 738.1694 - val_loss: 633.8198\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 7ms/step - loss: 523.9131 - val_loss: 422.4770\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 356.6175 - val_loss: 290.0359\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 264.5065 - val_loss: 236.1947\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 225.5246 - val_loss: 218.6828\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 7ms/step - loss: 206.1428 - val_loss: 209.0020\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 9ms/step - loss: 193.6765 - val_loss: 201.7875\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 184.7878 - val_loss: 197.6707\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 9ms/step - loss: 177.9939 - val_loss: 193.5460\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 171.5256 - val_loss: 190.7212\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 10ms/step - loss: 167.2349 - val_loss: 188.0379\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 163.6299 - val_loss: 185.8589\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 160.4113 - val_loss: 183.8075\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.8634 - val_loss: 181.9856\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 155.4130 - val_loss: 180.1837\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.4965 - val_loss: 178.6094\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.7942 - val_loss: 176.7204\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 150.7069 - val_loss: 175.6216\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 148.8304 - val_loss: 174.0440\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 147.6857 - val_loss: 173.5336\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.4001 - val_loss: 172.7598\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 145.8413 - val_loss: 172.3472\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 7ms/step - loss: 144.2892 - val_loss: 171.3086\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 8ms/step - loss: 143.4352 - val_loss: 169.7138\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.5582 - val_loss: 169.3382\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 141.6520 - val_loss: 168.4054\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 8ms/step - loss: 140.4368 - val_loss: 167.1289\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.7794 - val_loss: 166.4972\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 138.8781 - val_loss: 165.4445\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.9515 - val_loss: 164.9975\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.2914 - val_loss: 164.5386\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.3563 - val_loss: 163.7277\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 12ms/step - loss: 135.4556 - val_loss: 163.1933\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.6947 - val_loss: 161.2218\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 134.1149 - val_loss: 161.3954\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 133.6037 - val_loss: 160.6710\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 132.8044 - val_loss: 159.2516\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 7ms/step - loss: 132.0423 - val_loss: 158.9904\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 131.5448 - val_loss: 157.6887\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 9ms/step - loss: 130.9268 - val_loss: 157.4917\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 130.3631 - val_loss: 157.3462\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.3098 - val_loss: 155.8582\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 129.1356 - val_loss: 155.6104\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 3ms/step - loss: 128.2936 - val_loss: 154.7595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 111ms/step - loss: 1553.7427 - val_loss: 1622.5619\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 7ms/step - loss: 1523.4492 - val_loss: 1593.8864\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1492.6151 - val_loss: 1560.4934\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1455.0437 - val_loss: 1517.5150\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1405.1598 - val_loss: 1462.3833\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1341.2784 - val_loss: 1390.9131\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1257.5928 - val_loss: 1300.2335\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 7ms/step - loss: 1150.3632 - val_loss: 1182.5707\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1015.9101 - val_loss: 1039.1119\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 856.7850 - val_loss: 879.1956\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 10ms/step - loss: 688.4075 - val_loss: 721.8395\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 545.5029 - val_loss: 587.5491\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 439.5951 - val_loss: 490.2749\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 10ms/step - loss: 369.5055 - val_loss: 412.2932\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 317.8688 - val_loss: 353.0514\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 280.0264 - val_loss: 312.6944\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 253.3860 - val_loss: 283.5063\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 235.1806 - val_loss: 260.2311\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 219.9972 - val_loss: 246.0755\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 14ms/step - loss: 208.4785 - val_loss: 232.0449\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 198.8666 - val_loss: 221.3159\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.5013 - val_loss: 211.7651\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 184.4297 - val_loss: 205.4976\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 179.0493 - val_loss: 199.8898\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 174.5612 - val_loss: 195.0969\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 170.5385 - val_loss: 190.2891\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 166.7646 - val_loss: 187.2260\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.5444 - val_loss: 183.4798\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 160.8527 - val_loss: 180.1314\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 157.6361 - val_loss: 177.0608\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 155.3180 - val_loss: 174.5360\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 152.9161 - val_loss: 171.9574\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.7972 - val_loss: 169.4746\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.7406 - val_loss: 167.1660\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 8ms/step - loss: 146.9746 - val_loss: 165.6357\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.6812 - val_loss: 163.4027\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 143.8792 - val_loss: 162.1719\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.5571 - val_loss: 160.2444\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 12ms/step - loss: 141.0151 - val_loss: 158.6878\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 139.5859 - val_loss: 157.1497\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 138.2209 - val_loss: 155.9504\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 137.3792 - val_loss: 154.7937\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 135.9681 - val_loss: 153.4565\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.5721 - val_loss: 152.3086\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.2834 - val_loss: 151.4827\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 131.9817 - val_loss: 149.7297\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 130.9999 - val_loss: 148.9187\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 129.7994 - val_loss: 148.4452\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.8000 - val_loss: 146.8621\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 127.6859 - val_loss: 146.2340\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 114ms/step - loss: 1545.5348 - val_loss: 1518.1759\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 8ms/step - loss: 1516.3516 - val_loss: 1486.1001\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1475.8516 - val_loss: 1438.0488\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1415.7501 - val_loss: 1367.2673\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1329.8984 - val_loss: 1267.1996\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 8ms/step - loss: 1211.7814 - val_loss: 1128.4697\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 1050.7693 - val_loss: 944.5319\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 849.3192 - val_loss: 730.5375\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 628.6207 - val_loss: 524.7450\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 437.3088 - val_loss: 368.6684\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 315.6031 - val_loss: 288.5997\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 255.8945 - val_loss: 251.9766\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 226.9806 - val_loss: 230.9657\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 208.4129 - val_loss: 215.0142\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 193.7017 - val_loss: 201.6171\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 8ms/step - loss: 182.3629 - val_loss: 190.7508\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 174.0486 - val_loss: 182.7065\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 166.8940 - val_loss: 177.4859\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 161.9653 - val_loss: 172.3215\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 158.5411 - val_loss: 168.7217\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 154.8257 - val_loss: 164.6520\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 151.7350 - val_loss: 162.1810\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 149.0188 - val_loss: 159.7820\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 147.3029 - val_loss: 156.7617\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 144.6302 - val_loss: 155.6864\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 143.1016 - val_loss: 152.8143\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 141.1240 - val_loss: 151.1898\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 139.4135 - val_loss: 149.8968\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 137.7574 - val_loss: 147.9979\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.5755 - val_loss: 146.6357\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.8665 - val_loss: 144.8383\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 134.1627 - val_loss: 143.8284\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.0168 - val_loss: 141.7975\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.9494 - val_loss: 141.3341\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.7687 - val_loss: 140.1337\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 7ms/step - loss: 128.5973 - val_loss: 138.5417\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 14ms/step - loss: 127.5538 - val_loss: 136.9287\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 13ms/step - loss: 126.3145 - val_loss: 135.7327\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 13ms/step - loss: 125.1775 - val_loss: 135.1481\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 9ms/step - loss: 124.2709 - val_loss: 133.6577\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 14ms/step - loss: 123.3153 - val_loss: 132.8118\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 9ms/step - loss: 122.0746 - val_loss: 132.0255\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 14ms/step - loss: 121.0826 - val_loss: 130.1189\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.2344 - val_loss: 130.3477\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 119.0270 - val_loss: 127.4505\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 13ms/step - loss: 117.6056 - val_loss: 127.4025\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 13ms/step - loss: 116.7094 - val_loss: 125.3616\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 14ms/step - loss: 115.4034 - val_loss: 125.1056\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 7ms/step - loss: 114.1946 - val_loss: 124.1502\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 7ms/step - loss: 113.1528 - val_loss: 122.5235\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 3s - 145ms/step - loss: 1479.5404 - val_loss: 1734.9785\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1457.7434 - val_loss: 1710.3196\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1431.4930 - val_loss: 1676.5431\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1392.6111 - val_loss: 1623.0953\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 8ms/step - loss: 1328.5959 - val_loss: 1532.1956\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 1219.2844 - val_loss: 1377.2957\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 1043.8293 - val_loss: 1146.2134\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 815.5948 - val_loss: 867.8473\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 577.9450 - val_loss: 609.1409\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 8ms/step - loss: 401.3571 - val_loss: 429.9951\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 305.8863 - val_loss: 337.0905\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 8ms/step - loss: 264.5101 - val_loss: 288.8150\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 243.4237 - val_loss: 263.9838\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 230.5424 - val_loss: 245.1773\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 220.6060 - val_loss: 235.1520\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 212.7800 - val_loss: 228.8820\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 206.4066 - val_loss: 218.3435\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 13ms/step - loss: 200.3169 - val_loss: 212.7149\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 195.2006 - val_loss: 206.1293\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 190.9154 - val_loss: 203.3460\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 186.5100 - val_loss: 193.6761\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 182.2306 - val_loss: 192.4483\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 10ms/step - loss: 177.8601 - val_loss: 186.9767\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 7ms/step - loss: 174.5537 - val_loss: 184.6308\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 171.4161 - val_loss: 179.5003\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 167.6809 - val_loss: 179.1486\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 164.8658 - val_loss: 173.2197\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 162.0654 - val_loss: 170.6364\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 159.1962 - val_loss: 169.4008\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 156.9207 - val_loss: 165.9754\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 7ms/step - loss: 153.9912 - val_loss: 161.3160\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 15ms/step - loss: 151.3846 - val_loss: 156.9528\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 18ms/step - loss: 148.7842 - val_loss: 156.6232\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 14ms/step - loss: 146.6119 - val_loss: 152.5940\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 7ms/step - loss: 145.5005 - val_loss: 153.9501\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 8ms/step - loss: 143.0817 - val_loss: 147.4664\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 9ms/step - loss: 141.2299 - val_loss: 149.7982\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 7ms/step - loss: 139.8539 - val_loss: 144.7531\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 6ms/step - loss: 137.8878 - val_loss: 146.0517\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.5451 - val_loss: 142.9812\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 10ms/step - loss: 135.1734 - val_loss: 140.3123\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.7512 - val_loss: 141.0649\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 8ms/step - loss: 132.8150 - val_loss: 137.0720\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.2568 - val_loss: 138.7923\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 7ms/step - loss: 130.4305 - val_loss: 133.9980\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 13ms/step - loss: 128.6250 - val_loss: 134.2117\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.4602 - val_loss: 132.0487\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 126.2754 - val_loss: 133.1086\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 125.0397 - val_loss: 129.8761\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 124.0594 - val_loss: 129.9508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 7s - 317ms/step - loss: 1521.1066 - val_loss: 1653.3130\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1500.8234 - val_loss: 1629.4312\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1476.5521 - val_loss: 1598.8508\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1445.0244 - val_loss: 1558.4769\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1403.3171 - val_loss: 1504.3453\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1347.7185 - val_loss: 1434.7722\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1276.9963 - val_loss: 1343.5891\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1186.2875 - val_loss: 1228.5315\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1072.9580 - val_loss: 1089.4674\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 938.5026 - val_loss: 928.3047\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 787.5754 - val_loss: 754.7673\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 631.3667 - val_loss: 585.6452\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 485.2987 - val_loss: 441.7374\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 366.5809 - val_loss: 335.7285\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 285.8255 - val_loss: 271.5725\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 240.7196 - val_loss: 243.8246\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 220.8828 - val_loss: 231.7765\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 3ms/step - loss: 210.5379 - val_loss: 224.7721\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 204.1146 - val_loss: 219.6664\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 3ms/step - loss: 198.3232 - val_loss: 215.0736\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 193.8112 - val_loss: 210.8712\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 189.7944 - val_loss: 206.4958\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 11ms/step - loss: 186.3955 - val_loss: 202.9831\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 7ms/step - loss: 181.6119 - val_loss: 198.8917\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 178.1481 - val_loss: 195.2851\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 174.6772 - val_loss: 191.6457\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 171.7877 - val_loss: 188.2599\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 168.0674 - val_loss: 185.0725\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 3ms/step - loss: 164.9205 - val_loss: 181.5399\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 161.5713 - val_loss: 178.2402\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 158.4726 - val_loss: 175.0903\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 155.2761 - val_loss: 171.6522\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 152.3372 - val_loss: 168.5165\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.4440 - val_loss: 165.2453\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 7ms/step - loss: 146.2850 - val_loss: 162.1085\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 143.7540 - val_loss: 159.0735\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.6350 - val_loss: 156.2721\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 9ms/step - loss: 138.1756 - val_loss: 153.5370\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 8ms/step - loss: 135.8705 - val_loss: 150.5272\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 8ms/step - loss: 132.9215 - val_loss: 147.9766\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.3331 - val_loss: 145.3675\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.1658 - val_loss: 142.8906\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.5353 - val_loss: 140.4370\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 8ms/step - loss: 123.3122 - val_loss: 137.9191\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 3ms/step - loss: 121.3235 - val_loss: 135.5952\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 119.1156 - val_loss: 132.8698\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 116.6790 - val_loss: 131.0508\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 3ms/step - loss: 114.7497 - val_loss: 128.5227\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 112.3576 - val_loss: 126.2391\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.5815 - val_loss: 124.2702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 109ms/step - loss: 1490.8577 - val_loss: 1613.1108\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1465.3890 - val_loss: 1580.3911\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1427.8403 - val_loss: 1528.9525\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 3ms/step - loss: 1367.4626 - val_loss: 1444.7670\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1266.2483 - val_loss: 1304.5039\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1105.5562 - val_loss: 1092.8281\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 884.1624 - val_loss: 820.5645\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 624.5737 - val_loss: 544.0144\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 402.4720 - val_loss: 362.8367\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 7ms/step - loss: 288.2440 - val_loss: 287.0039\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 237.1245 - val_loss: 262.7810\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 7ms/step - loss: 215.5157 - val_loss: 248.9854\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 201.5638 - val_loss: 240.5929\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 8ms/step - loss: 192.4734 - val_loss: 234.8077\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 7ms/step - loss: 186.3101 - val_loss: 229.5920\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 8ms/step - loss: 180.5149 - val_loss: 223.7758\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 6ms/step - loss: 175.7483 - val_loss: 219.4807\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 171.9848 - val_loss: 215.7477\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 168.0998 - val_loss: 211.3660\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 7ms/step - loss: 165.2016 - val_loss: 208.1251\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.3809 - val_loss: 203.6767\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.9201 - val_loss: 202.0142\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 6ms/step - loss: 157.4420 - val_loss: 198.4077\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 154.9106 - val_loss: 195.0902\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 153.0997 - val_loss: 192.5628\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.8930 - val_loss: 189.5926\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.1867 - val_loss: 187.1273\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 147.8988 - val_loss: 185.3237\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 146.1597 - val_loss: 182.7741\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.7121 - val_loss: 180.4068\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.7657 - val_loss: 179.3754\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 142.4274 - val_loss: 176.2539\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 141.5695 - val_loss: 175.0641\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.1161 - val_loss: 172.7488\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 138.8596 - val_loss: 171.6613\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.9862 - val_loss: 170.5853\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.9637 - val_loss: 169.0105\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.1487 - val_loss: 167.3739\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 135.2936 - val_loss: 165.5349\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 12ms/step - loss: 134.2626 - val_loss: 164.9315\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 133.8448 - val_loss: 163.1894\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.6651 - val_loss: 162.3683\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.9705 - val_loss: 161.2497\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.1808 - val_loss: 159.9708\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 130.9007 - val_loss: 160.1441\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 7ms/step - loss: 129.7032 - val_loss: 157.9042\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 3ms/step - loss: 129.3465 - val_loss: 157.0775\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.5780 - val_loss: 156.4953\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.8604 - val_loss: 155.2936\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 3ms/step - loss: 127.6679 - val_loss: 154.3712\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 102ms/step - loss: 1520.8767 - val_loss: 1528.2035\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 11ms/step - loss: 1486.6592 - val_loss: 1486.7642\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1437.8943 - val_loss: 1424.5138\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1362.4243 - val_loss: 1329.6594\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1248.8229 - val_loss: 1183.4843\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1081.4240 - val_loss: 985.4042\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 863.4225 - val_loss: 739.7343\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 621.6990 - val_loss: 491.6195\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 412.4182 - val_loss: 319.0790\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 299.6486 - val_loss: 244.1159\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 263.5458 - val_loss: 215.8346\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 243.2133 - val_loss: 200.6515\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 228.8050 - val_loss: 189.7855\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 218.6879 - val_loss: 181.1223\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 8ms/step - loss: 209.9174 - val_loss: 175.0397\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 202.8070 - val_loss: 168.6733\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 9ms/step - loss: 197.0813 - val_loss: 164.0338\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 191.9834 - val_loss: 159.5113\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 187.5406 - val_loss: 156.6955\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 182.8487 - val_loss: 152.1062\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 179.2192 - val_loss: 149.1666\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 175.7935 - val_loss: 146.5849\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 172.3465 - val_loss: 144.0097\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.8692 - val_loss: 141.0907\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 9ms/step - loss: 167.6205 - val_loss: 140.1513\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.8905 - val_loss: 136.3594\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 161.5228 - val_loss: 134.5065\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.1624 - val_loss: 133.3441\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 9ms/step - loss: 158.2713 - val_loss: 131.4582\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 155.3022 - val_loss: 130.6821\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 3ms/step - loss: 153.5852 - val_loss: 128.9101\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.7994 - val_loss: 126.8532\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.8775 - val_loss: 125.9771\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 148.8572 - val_loss: 124.6711\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.8104 - val_loss: 123.7466\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.4685 - val_loss: 122.2227\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.2663 - val_loss: 121.0615\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 8ms/step - loss: 142.4977 - val_loss: 120.2215\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 142.1931 - val_loss: 119.2387\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 140.8470 - val_loss: 118.2703\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.3271 - val_loss: 118.2264\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.7067 - val_loss: 117.0050\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.4871 - val_loss: 115.6808\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 11ms/step - loss: 135.3403 - val_loss: 114.9225\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.5704 - val_loss: 114.4898\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.6452 - val_loss: 113.9847\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 132.5955 - val_loss: 113.1379\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.7780 - val_loss: 112.4093\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 131.4932 - val_loss: 111.8746\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.2987 - val_loss: 111.7870\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 107ms/step - loss: 1509.4930 - val_loss: 1640.9043\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1485.7550 - val_loss: 1613.3749\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1455.2021 - val_loss: 1575.4937\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1411.7063 - val_loss: 1517.8677\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1344.0474 - val_loss: 1428.4030\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1240.7347 - val_loss: 1297.2516\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1097.6648 - val_loss: 1125.2396\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 922.6276 - val_loss: 921.8020\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 735.8003 - val_loss: 727.6439\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 577.3836 - val_loss: 564.4445\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 446.5461 - val_loss: 434.0030\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 345.0794 - val_loss: 327.4088\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 269.4102 - val_loss: 252.4103\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 223.0244 - val_loss: 204.8669\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 195.7064 - val_loss: 182.1236\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 182.8808 - val_loss: 169.7224\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 7ms/step - loss: 175.5038 - val_loss: 163.3437\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 171.0677 - val_loss: 160.4138\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 8ms/step - loss: 167.9337 - val_loss: 158.2127\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 7ms/step - loss: 164.9384 - val_loss: 155.7604\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 162.9063 - val_loss: 154.4233\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 7ms/step - loss: 160.2097 - val_loss: 151.6141\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 158.3724 - val_loss: 150.7163\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 156.4593 - val_loss: 148.1894\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 154.8531 - val_loss: 148.5341\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 152.5778 - val_loss: 146.5615\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.9235 - val_loss: 144.8411\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.5561 - val_loss: 144.0285\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 3ms/step - loss: 147.5087 - val_loss: 142.1010\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.1330 - val_loss: 141.3729\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.6627 - val_loss: 140.4039\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.2461 - val_loss: 138.7708\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 141.9340 - val_loss: 138.1258\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.8745 - val_loss: 136.3524\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 139.6066 - val_loss: 136.1207\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 138.0910 - val_loss: 135.1555\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.7585 - val_loss: 133.7553\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 135.3791 - val_loss: 132.2144\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.1917 - val_loss: 131.3640\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.5697 - val_loss: 130.8091\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.2820 - val_loss: 128.9412\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 129.7076 - val_loss: 128.1360\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.6784 - val_loss: 126.9159\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 11ms/step - loss: 126.0596 - val_loss: 125.3228\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 124.4351 - val_loss: 124.4361\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 122.6726 - val_loss: 123.1048\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.6858 - val_loss: 120.7252\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 119.0500 - val_loss: 119.7769\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 117.0902 - val_loss: 118.1317\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 7ms/step - loss: 115.2489 - val_loss: 116.8890\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 107ms/step - loss: 1494.6078 - val_loss: 1649.0461\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 6ms/step - loss: 1458.1315 - val_loss: 1601.4421\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1405.5408 - val_loss: 1528.5258\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1324.7126 - val_loss: 1418.7568\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1206.3429 - val_loss: 1261.0546\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1042.8458 - val_loss: 1059.3912\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 851.2228 - val_loss: 826.1051\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 651.2040 - val_loss: 618.4713\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 493.4115 - val_loss: 469.0745\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 388.8364 - val_loss: 373.4186\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 322.3713 - val_loss: 317.0109\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 280.0758 - val_loss: 284.7164\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 253.4465 - val_loss: 265.0864\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 235.1987 - val_loss: 252.3474\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 222.0769 - val_loss: 241.5443\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 211.5311 - val_loss: 233.0152\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 203.2662 - val_loss: 225.7776\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 196.5544 - val_loss: 220.4106\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.3365 - val_loss: 214.2489\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 184.9482 - val_loss: 209.4546\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 180.2652 - val_loss: 205.4513\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 176.4216 - val_loss: 200.8761\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 171.9672 - val_loss: 197.0700\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 168.6609 - val_loss: 192.7465\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.1212 - val_loss: 190.1423\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 162.1265 - val_loss: 186.7991\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 158.9090 - val_loss: 182.6160\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.1198 - val_loss: 179.5554\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.2196 - val_loss: 176.9720\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.7674 - val_loss: 173.9020\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 7ms/step - loss: 148.1352 - val_loss: 171.0323\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 145.7088 - val_loss: 168.4565\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.6313 - val_loss: 165.2867\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 10ms/step - loss: 141.0198 - val_loss: 163.4429\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.0115 - val_loss: 160.3072\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.7228 - val_loss: 157.9244\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.9462 - val_loss: 155.4839\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 133.0251 - val_loss: 153.1282\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.4471 - val_loss: 150.9534\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.4516 - val_loss: 148.6808\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.3703 - val_loss: 146.5425\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.2529 - val_loss: 145.2206\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.4187 - val_loss: 143.1991\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 123.3488 - val_loss: 141.7860\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 12ms/step - loss: 121.8171 - val_loss: 139.6433\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.5610 - val_loss: 137.7697\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 3ms/step - loss: 119.2593 - val_loss: 136.2381\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.8908 - val_loss: 134.9245\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.4911 - val_loss: 133.3099\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.9445 - val_loss: 131.8923\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 4s - 162ms/step - loss: 1564.6919 - val_loss: 1559.2793\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1553.1337 - val_loss: 1546.7001\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1537.3115 - val_loss: 1527.2115\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1512.1259 - val_loss: 1494.2501\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1465.8206 - val_loss: 1430.1019\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1377.4753 - val_loss: 1315.6578\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 1229.8138 - val_loss: 1133.9584\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1017.9243 - val_loss: 898.4252\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 768.0461 - val_loss: 646.8708\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 531.1743 - val_loss: 450.1282\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 375.4808 - val_loss: 345.0947\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 305.0095 - val_loss: 297.8852\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 272.2342 - val_loss: 271.0781\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 251.8848 - val_loss: 253.3970\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 238.6102 - val_loss: 239.7594\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 228.1242 - val_loss: 229.6441\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 219.8598 - val_loss: 221.4740\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 212.8376 - val_loss: 213.7927\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 206.1411 - val_loss: 207.7401\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 200.1824 - val_loss: 202.0036\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 195.1705 - val_loss: 196.7688\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 189.8453 - val_loss: 191.5165\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 185.6338 - val_loss: 186.8084\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 6ms/step - loss: 181.5128 - val_loss: 182.1730\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 177.8725 - val_loss: 177.9243\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.8371 - val_loss: 173.6725\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 170.4292 - val_loss: 170.2430\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.5306 - val_loss: 166.7951\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 164.6750 - val_loss: 163.3082\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 162.1039 - val_loss: 160.6209\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 159.2554 - val_loss: 157.9904\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.1172 - val_loss: 155.3863\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.8779 - val_loss: 152.6382\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.1143 - val_loss: 150.8422\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.8907 - val_loss: 148.7549\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 148.9848 - val_loss: 147.0059\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 147.3822 - val_loss: 144.6733\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.7749 - val_loss: 142.9621\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 144.3655 - val_loss: 141.0421\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.0106 - val_loss: 140.1808\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 141.9215 - val_loss: 138.4715\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.2198 - val_loss: 136.8842\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 7ms/step - loss: 139.1316 - val_loss: 135.3228\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 137.8224 - val_loss: 134.2309\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.4442 - val_loss: 132.8436\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 135.0388 - val_loss: 131.7452\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.1078 - val_loss: 130.6996\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.9436 - val_loss: 128.9741\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.8196 - val_loss: 127.8486\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 12ms/step - loss: 130.7790 - val_loss: 126.6753\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 109ms/step - loss: 1481.2559 - val_loss: 1577.1514\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 6ms/step - loss: 1445.1742 - val_loss: 1526.3807\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1387.8905 - val_loss: 1444.6217\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1292.6251 - val_loss: 1315.4896\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1150.6675 - val_loss: 1126.4326\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 12ms/step - loss: 950.8696 - val_loss: 876.8372\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 14ms/step - loss: 707.5411 - val_loss: 602.0400\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 478.9204 - val_loss: 384.8629\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 9ms/step - loss: 332.7297 - val_loss: 279.6118\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 271.7787 - val_loss: 247.8984\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 247.6620 - val_loss: 231.2965\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 6ms/step - loss: 231.2481 - val_loss: 220.2702\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 220.4976 - val_loss: 209.9909\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 210.3373 - val_loss: 202.4403\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 203.3497 - val_loss: 195.8236\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 196.4518 - val_loss: 190.0178\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.8790 - val_loss: 184.5170\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 7ms/step - loss: 186.1527 - val_loss: 179.4280\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 181.9393 - val_loss: 176.0140\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 178.1365 - val_loss: 172.7871\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 174.4484 - val_loss: 168.8647\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 171.5726 - val_loss: 165.6772\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 168.1201 - val_loss: 162.0339\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 165.0721 - val_loss: 160.0558\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 162.1164 - val_loss: 157.1226\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 158.9987 - val_loss: 154.7288\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.2851 - val_loss: 152.5143\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 9ms/step - loss: 153.6613 - val_loss: 150.5932\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.9029 - val_loss: 147.3282\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.2770 - val_loss: 145.8966\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 145.5531 - val_loss: 143.0505\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 142.9373 - val_loss: 141.5752\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.2532 - val_loss: 138.8760\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.6750 - val_loss: 136.8506\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.7723 - val_loss: 134.9708\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 132.1560 - val_loss: 132.6127\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 129.8546 - val_loss: 130.9420\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 126.9984 - val_loss: 128.8414\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 124.2338 - val_loss: 126.5991\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 121.1155 - val_loss: 123.6783\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 118.2721 - val_loss: 121.9510\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 12ms/step - loss: 114.7695 - val_loss: 119.8792\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 111.7571 - val_loss: 116.9769\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 7ms/step - loss: 108.7165 - val_loss: 113.8603\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 106.0391 - val_loss: 111.6446\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 102.7287 - val_loss: 109.4668\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 99.4092 - val_loss: 106.0226\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 96.0883 - val_loss: 103.3267\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 7ms/step - loss: 92.5495 - val_loss: 101.5331\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 89.8082 - val_loss: 97.7565\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 127ms/step - loss: 1602.5676 - val_loss: 1595.5945\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1577.4613 - val_loss: 1571.3674\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1556.3544 - val_loss: 1550.1412\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1536.5402 - val_loss: 1527.3861\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1512.6472 - val_loss: 1496.2957\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 1475.5610 - val_loss: 1445.1180\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1413.3589 - val_loss: 1354.6259\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1305.5142 - val_loss: 1214.4387\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1147.7493 - val_loss: 1015.7478\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 933.9117 - val_loss: 767.9373\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 688.8311 - val_loss: 514.9044\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 461.6120 - val_loss: 337.9385\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 326.7195 - val_loss: 261.7147\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 268.3098 - val_loss: 242.1065\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 245.2753 - val_loss: 230.4247\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 229.8052 - val_loss: 218.2564\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 217.9041 - val_loss: 212.2585\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 209.2717 - val_loss: 206.0872\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 201.8641 - val_loss: 199.2083\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 195.7324 - val_loss: 195.1042\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.6825 - val_loss: 190.5257\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 185.9193 - val_loss: 187.5642\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 181.2755 - val_loss: 183.4509\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 177.4257 - val_loss: 179.1202\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.8485 - val_loss: 175.8168\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 170.7774 - val_loss: 174.6157\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.3462 - val_loss: 170.6265\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 164.6600 - val_loss: 167.2220\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.2148 - val_loss: 165.1011\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 159.4456 - val_loss: 163.4541\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 157.2504 - val_loss: 162.3558\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.9842 - val_loss: 159.1680\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 153.6663 - val_loss: 158.0302\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.6346 - val_loss: 155.3466\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.9820 - val_loss: 154.6053\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 146.8189 - val_loss: 151.9048\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.2242 - val_loss: 151.2599\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.6926 - val_loss: 148.0052\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 6ms/step - loss: 141.9818 - val_loss: 148.4368\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 139.9839 - val_loss: 145.4024\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 3ms/step - loss: 138.4455 - val_loss: 145.0494\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - loss: 137.2172 - val_loss: 141.4629\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 135.2371 - val_loss: 141.6485\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 133.0869 - val_loss: 139.4682\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 131.4763 - val_loss: 137.8727\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.0879 - val_loss: 136.7236\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 10ms/step - loss: 128.5397 - val_loss: 136.2221\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 126.7237 - val_loss: 133.3664\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.2979 - val_loss: 131.3962\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.5932 - val_loss: 130.8505\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 114ms/step - loss: 1551.6042 - val_loss: 1571.6292\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1537.0688 - val_loss: 1554.4221\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1515.4248 - val_loss: 1525.1418\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1477.8634 - val_loss: 1474.3470\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1412.5082 - val_loss: 1384.9983\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1298.2272 - val_loss: 1236.4991\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 1116.2583 - val_loss: 1022.6118\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 877.6987 - val_loss: 770.6069\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 632.6537 - val_loss: 542.8957\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 440.5823 - val_loss: 411.1133\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 341.4519 - val_loss: 345.4937\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 292.7941 - val_loss: 307.2619\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 263.0579 - val_loss: 276.2265\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 239.5629 - val_loss: 250.0320\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 6ms/step - loss: 220.3950 - val_loss: 230.1332\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 205.3486 - val_loss: 213.6654\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 192.8462 - val_loss: 199.4728\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 182.5733 - val_loss: 187.9283\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 173.6145 - val_loss: 179.0130\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 167.0762 - val_loss: 172.3342\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 160.7542 - val_loss: 166.0293\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 8ms/step - loss: 155.4930 - val_loss: 161.1941\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.1439 - val_loss: 156.9250\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 147.3868 - val_loss: 153.1584\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.8215 - val_loss: 150.1379\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.2168 - val_loss: 146.8118\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 137.3432 - val_loss: 143.5874\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.0575 - val_loss: 141.6770\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.4970 - val_loss: 139.3885\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.6672 - val_loss: 137.2162\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.1008 - val_loss: 134.8587\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 123.8319 - val_loss: 132.9690\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.5214 - val_loss: 131.1136\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 119.5870 - val_loss: 130.2093\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.0451 - val_loss: 127.8867\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.3812 - val_loss: 126.6134\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.3120 - val_loss: 125.0584\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 111.3726 - val_loss: 124.0355\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 6ms/step - loss: 109.7133 - val_loss: 122.5853\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 108.1507 - val_loss: 121.5625\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 7ms/step - loss: 106.3825 - val_loss: 120.5647\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 12ms/step - loss: 104.9615 - val_loss: 119.2757\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 103.4148 - val_loss: 118.3777\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 102.0655 - val_loss: 117.6763\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 100.6826 - val_loss: 116.3513\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 99.3382 - val_loss: 115.7183\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 7ms/step - loss: 98.1744 - val_loss: 114.7711\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 96.8036 - val_loss: 114.3017\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 95.7916 - val_loss: 113.0541\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 94.7691 - val_loss: 112.6652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 116ms/step - loss: 1521.8545 - val_loss: 1460.7894\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1482.9448 - val_loss: 1413.8605\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1422.0074 - val_loss: 1338.6702\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 6ms/step - loss: 1326.8118 - val_loss: 1225.6371\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1188.4399 - val_loss: 1066.6104\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1000.0239 - val_loss: 863.4548\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 771.9816 - val_loss: 640.8576\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 545.3210 - val_loss: 449.9612\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 8ms/step - loss: 371.1215 - val_loss: 340.8281\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 280.1443 - val_loss: 298.7265\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 246.5712 - val_loss: 282.1051\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 231.0515 - val_loss: 268.6664\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 219.8469 - val_loss: 256.8677\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 9ms/step - loss: 210.6800 - val_loss: 245.2226\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 202.7755 - val_loss: 237.2431\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 197.0224 - val_loss: 229.0187\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 3ms/step - loss: 190.7451 - val_loss: 220.9021\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 185.4608 - val_loss: 214.7049\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 180.9603 - val_loss: 209.6964\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 176.6223 - val_loss: 203.8627\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 172.5289 - val_loss: 198.6225\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 168.9545 - val_loss: 194.1810\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.6614 - val_loss: 189.8302\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.4627 - val_loss: 186.3562\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 8ms/step - loss: 159.7042 - val_loss: 182.6019\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 157.5261 - val_loss: 180.1766\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 155.1999 - val_loss: 176.2167\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 3ms/step - loss: 152.6438 - val_loss: 173.7568\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 150.4139 - val_loss: 171.0298\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 148.5752 - val_loss: 168.7063\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.6165 - val_loss: 165.4370\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.9536 - val_loss: 163.4718\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.8251 - val_loss: 160.8669\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.2151 - val_loss: 159.1799\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.5363 - val_loss: 156.7056\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 138.2482 - val_loss: 155.2488\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.9191 - val_loss: 153.2018\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 135.4118 - val_loss: 151.5621\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.2284 - val_loss: 149.8098\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 12ms/step - loss: 133.0981 - val_loss: 148.7517\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.9233 - val_loss: 146.3502\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 7ms/step - loss: 130.7211 - val_loss: 145.5632\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 129.8923 - val_loss: 143.8546\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.7111 - val_loss: 142.3034\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.9537 - val_loss: 141.3325\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.8145 - val_loss: 140.7088\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.0714 - val_loss: 138.7717\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.2927 - val_loss: 137.9743\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 124.3500 - val_loss: 136.6150\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 123.5601 - val_loss: 135.7486\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 128ms/step - loss: 1604.5936 - val_loss: 1429.6339\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1564.4927 - val_loss: 1390.6361\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1511.4022 - val_loss: 1332.1857\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1429.4293 - val_loss: 1242.7314\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1307.2247 - val_loss: 1114.9421\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 10ms/step - loss: 1143.7032 - val_loss: 949.7308\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 944.0078 - val_loss: 761.5154\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 7ms/step - loss: 727.4810 - val_loss: 575.6621\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 529.0541 - val_loss: 421.2379\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 385.7706 - val_loss: 316.1937\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 300.1980 - val_loss: 259.6219\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 8ms/step - loss: 255.1649 - val_loss: 227.5928\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 227.9718 - val_loss: 206.7655\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 208.5284 - val_loss: 193.0179\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 196.2057 - val_loss: 183.8591\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 187.1089 - val_loss: 178.4016\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 6ms/step - loss: 179.6456 - val_loss: 174.2088\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 174.6831 - val_loss: 170.9131\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 170.4868 - val_loss: 169.3473\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 166.6503 - val_loss: 166.9192\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.7962 - val_loss: 166.1579\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 160.8257 - val_loss: 164.6282\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 7ms/step - loss: 158.5675 - val_loss: 163.9495\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 156.5491 - val_loss: 162.1385\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.5496 - val_loss: 162.1746\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 152.8077 - val_loss: 160.3674\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 150.9135 - val_loss: 159.3683\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.3974 - val_loss: 158.2040\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 148.0882 - val_loss: 157.8168\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.6328 - val_loss: 156.4116\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.2581 - val_loss: 155.5293\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 7ms/step - loss: 144.6996 - val_loss: 156.5441\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 142.7128 - val_loss: 153.3944\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.9812 - val_loss: 152.6808\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.2651 - val_loss: 153.1125\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 139.9442 - val_loss: 151.3026\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 139.2195 - val_loss: 151.4755\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 7ms/step - loss: 138.7415 - val_loss: 150.1315\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 15ms/step - loss: 138.4665 - val_loss: 150.6831\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 9ms/step - loss: 137.2923 - val_loss: 148.3809\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 7ms/step - loss: 136.0032 - val_loss: 149.0044\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 135.9853 - val_loss: 148.2731\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 21ms/step - loss: 135.1602 - val_loss: 147.0939\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 13ms/step - loss: 134.3669 - val_loss: 146.8559\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 133.9641 - val_loss: 146.8817\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 9ms/step - loss: 133.3157 - val_loss: 145.2803\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 9ms/step - loss: 133.0015 - val_loss: 145.1366\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 14ms/step - loss: 132.3533 - val_loss: 144.6255\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.1962 - val_loss: 143.2838\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.8977 - val_loss: 144.8138\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 3s - 125ms/step - loss: 1574.5779 - val_loss: 1523.8488\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 19ms/step - loss: 1557.4451 - val_loss: 1506.1708\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1533.9539 - val_loss: 1479.0330\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1496.8021 - val_loss: 1433.4625\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1435.7235 - val_loss: 1357.6831\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1336.6482 - val_loss: 1237.8379\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1184.4843 - val_loss: 1056.2827\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 967.5859 - val_loss: 821.0505\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 715.6812 - val_loss: 569.5118\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 478.6595 - val_loss: 388.3717\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 10ms/step - loss: 330.4257 - val_loss: 301.7706\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 266.4569 - val_loss: 264.7555\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 3ms/step - loss: 237.5980 - val_loss: 240.6645\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 220.6650 - val_loss: 226.4871\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 211.1291 - val_loss: 216.7625\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 203.0496 - val_loss: 208.6591\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 8ms/step - loss: 198.2614 - val_loss: 202.9749\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 193.0233 - val_loss: 198.7192\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 189.0396 - val_loss: 194.3215\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 185.4748 - val_loss: 190.2850\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 182.3801 - val_loss: 186.0903\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 178.9462 - val_loss: 182.8543\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 175.7099 - val_loss: 179.6808\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 173.1394 - val_loss: 176.7754\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 170.0634 - val_loss: 174.0790\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.4259 - val_loss: 170.5332\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 164.6300 - val_loss: 168.3094\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 162.2376 - val_loss: 165.6675\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 159.7943 - val_loss: 163.0123\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 7ms/step - loss: 156.9368 - val_loss: 160.2447\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 13ms/step - loss: 154.7124 - val_loss: 157.9372\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 152.1599 - val_loss: 155.1750\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 150.0462 - val_loss: 152.7748\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 148.0937 - val_loss: 150.4518\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 145.9676 - val_loss: 147.8914\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 3ms/step - loss: 143.7967 - val_loss: 145.6294\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.8210 - val_loss: 142.9216\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.8237 - val_loss: 140.7868\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 137.6551 - val_loss: 138.2763\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 135.9271 - val_loss: 136.1780\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 133.8937 - val_loss: 133.9117\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.1718 - val_loss: 131.5718\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.1887 - val_loss: 129.2343\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.2564 - val_loss: 126.9371\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.9407 - val_loss: 124.7385\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.0989 - val_loss: 122.9728\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.7324 - val_loss: 120.3703\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 121.5060 - val_loss: 118.4114\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 119.9838 - val_loss: 116.0705\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 117.5663 - val_loss: 114.1400\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 116ms/step - loss: 1494.6084 - val_loss: 1675.8568\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1472.3945 - val_loss: 1645.5817\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1432.5463 - val_loss: 1591.9125\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1368.3848 - val_loss: 1507.1782\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1271.4694 - val_loss: 1379.6995\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1132.4894 - val_loss: 1202.8864\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 7ms/step - loss: 953.7499 - val_loss: 978.0524\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 745.4791 - val_loss: 734.1999\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 549.5845 - val_loss: 517.6269\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 403.4304 - val_loss: 368.1892\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 315.5720 - val_loss: 284.8363\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 262.8242 - val_loss: 241.3900\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 231.3759 - val_loss: 214.6362\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 3ms/step - loss: 209.4521 - val_loss: 198.5287\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 193.9161 - val_loss: 186.3394\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 182.7684 - val_loss: 177.3046\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 174.2838 - val_loss: 169.9109\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 166.7019 - val_loss: 163.9336\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 160.5212 - val_loss: 158.9653\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 153.8372 - val_loss: 153.4775\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 148.2310 - val_loss: 148.9480\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.4894 - val_loss: 145.1760\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 138.4566 - val_loss: 140.7901\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 133.8078 - val_loss: 137.1704\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.8038 - val_loss: 134.4318\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.9082 - val_loss: 130.9642\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 122.6008 - val_loss: 128.2594\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 119.5646 - val_loss: 126.0922\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.0602 - val_loss: 123.3387\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 7ms/step - loss: 113.4283 - val_loss: 121.0587\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 6ms/step - loss: 110.8676 - val_loss: 118.2986\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 108.2537 - val_loss: 117.1955\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 106.1806 - val_loss: 115.3567\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 14ms/step - loss: 103.9971 - val_loss: 113.1145\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 101.5948 - val_loss: 110.9809\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 99.8841 - val_loss: 109.6487\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 97.8912 - val_loss: 107.7292\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 96.3609 - val_loss: 105.7829\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 8ms/step - loss: 94.7644 - val_loss: 105.2447\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 93.2390 - val_loss: 103.7053\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 12ms/step - loss: 91.7901 - val_loss: 102.2577\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 7ms/step - loss: 90.3881 - val_loss: 101.0266\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 89.0712 - val_loss: 100.2944\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 88.1693 - val_loss: 99.1414\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 87.0621 - val_loss: 98.1223\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 85.6028 - val_loss: 96.7299\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 9ms/step - loss: 84.9184 - val_loss: 95.9927\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 83.6459 - val_loss: 95.0875\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 82.8754 - val_loss: 94.5031\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 82.0059 - val_loss: 93.3779\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 3s - 121ms/step - loss: 1554.9568 - val_loss: 1510.9633\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1531.0632 - val_loss: 1479.3187\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1492.8873 - val_loss: 1429.5404\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1433.0930 - val_loss: 1353.6810\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1341.8309 - val_loss: 1235.6187\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1202.1775 - val_loss: 1059.6029\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1000.5802 - val_loss: 825.9199\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 753.5833 - val_loss: 564.1676\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 508.1100 - val_loss: 361.4102\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 347.5912 - val_loss: 254.4421\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 276.8244 - val_loss: 222.2999\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 249.3977 - val_loss: 209.6906\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 3ms/step - loss: 233.3281 - val_loss: 201.3899\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 222.5748 - val_loss: 195.8747\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 214.2156 - val_loss: 189.8611\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 207.9873 - val_loss: 186.3153\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 6ms/step - loss: 201.8187 - val_loss: 182.1922\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 196.5291 - val_loss: 178.7428\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 191.8697 - val_loss: 175.7389\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 187.7940 - val_loss: 172.9049\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 184.5103 - val_loss: 170.0730\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 180.1559 - val_loss: 167.3181\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 177.0210 - val_loss: 164.9522\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 6ms/step - loss: 173.8307 - val_loss: 162.6355\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 7ms/step - loss: 171.2506 - val_loss: 160.4335\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.8233 - val_loss: 157.4539\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.3275 - val_loss: 155.5204\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.6743 - val_loss: 154.3129\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 160.6350 - val_loss: 152.0997\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 158.2723 - val_loss: 150.1072\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.5282 - val_loss: 148.7374\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 155.2326 - val_loss: 148.5898\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.2556 - val_loss: 146.2546\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 151.5878 - val_loss: 144.7819\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.1710 - val_loss: 143.3793\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.9848 - val_loss: 142.5964\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 147.5797 - val_loss: 141.7126\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.5091 - val_loss: 140.3237\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 145.5912 - val_loss: 139.4373\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 144.2443 - val_loss: 138.5796\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.8189 - val_loss: 138.1074\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.4939 - val_loss: 136.4192\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.9538 - val_loss: 136.4230\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.6779 - val_loss: 134.6341\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 7ms/step - loss: 140.0593 - val_loss: 134.3332\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 139.5343 - val_loss: 134.2619\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 11ms/step - loss: 138.5375 - val_loss: 132.6761\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.6703 - val_loss: 131.8270\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.9620 - val_loss: 131.5975\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.0018 - val_loss: 130.7090\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 4s - 154ms/step - loss: 1562.9108 - val_loss: 1557.5206\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 17ms/step - loss: 1545.9912 - val_loss: 1540.6125\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 7ms/step - loss: 1527.0194 - val_loss: 1515.6873\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1497.1893 - val_loss: 1474.3009\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1446.1431 - val_loss: 1405.2993\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1364.1703 - val_loss: 1293.9515\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1238.1012 - val_loss: 1136.6094\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1064.7520 - val_loss: 927.8300\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 848.8808 - val_loss: 688.9168\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 619.1932 - val_loss: 465.6840\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 427.8817 - val_loss: 312.3915\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 7ms/step - loss: 306.5156 - val_loss: 248.7292\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 252.6922 - val_loss: 230.7460\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 232.4595 - val_loss: 223.0850\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 218.9568 - val_loss: 217.7529\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 210.3549 - val_loss: 210.8209\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 203.5731 - val_loss: 203.2005\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 197.1794 - val_loss: 199.9708\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 9ms/step - loss: 191.8546 - val_loss: 194.7693\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 187.5336 - val_loss: 189.8744\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 183.4577 - val_loss: 186.4764\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 6ms/step - loss: 179.7481 - val_loss: 181.6670\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 7ms/step - loss: 176.1575 - val_loss: 177.5637\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 172.9594 - val_loss: 174.5693\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 170.3305 - val_loss: 171.6747\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 167.7410 - val_loss: 169.4581\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 165.4914 - val_loss: 165.6193\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 7ms/step - loss: 163.2637 - val_loss: 163.7714\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 16ms/step - loss: 161.0288 - val_loss: 162.2637\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 158.8350 - val_loss: 159.5244\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 8ms/step - loss: 156.9522 - val_loss: 156.8848\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 8ms/step - loss: 155.1392 - val_loss: 155.6962\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 13ms/step - loss: 153.3289 - val_loss: 153.7235\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 7ms/step - loss: 151.5150 - val_loss: 151.2631\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.6575 - val_loss: 149.5488\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.2930 - val_loss: 148.1890\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 146.8541 - val_loss: 146.2008\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 8ms/step - loss: 145.5784 - val_loss: 145.6044\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.5138 - val_loss: 143.4353\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 9ms/step - loss: 143.0926 - val_loss: 142.6641\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 141.7488 - val_loss: 140.8801\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.5446 - val_loss: 139.7486\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 7ms/step - loss: 139.8141 - val_loss: 138.3894\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 14ms/step - loss: 138.7339 - val_loss: 137.1880\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 7ms/step - loss: 137.7367 - val_loss: 136.2518\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 136.9047 - val_loss: 135.3615\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 135.8723 - val_loss: 133.9005\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 135.0634 - val_loss: 132.6120\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.2032 - val_loss: 132.3922\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 7ms/step - loss: 133.6509 - val_loss: 130.5006\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 134ms/step - loss: 1482.5273 - val_loss: 1708.6730\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 19ms/step - loss: 1459.0435 - val_loss: 1682.2250\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1431.2401 - val_loss: 1643.7943\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1387.8259 - val_loss: 1582.4525\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1322.8976 - val_loss: 1498.0703\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1233.7631 - val_loss: 1381.7509\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 9ms/step - loss: 1113.2109 - val_loss: 1222.9379\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 952.5867 - val_loss: 1020.3817\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 760.5251 - val_loss: 783.8973\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 7ms/step - loss: 561.6024 - val_loss: 557.2992\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 9ms/step - loss: 396.9864 - val_loss: 397.7463\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 302.0748 - val_loss: 313.2580\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 262.0211 - val_loss: 273.7932\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 242.9949 - val_loss: 255.3442\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 231.2768 - val_loss: 244.0875\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 222.7528 - val_loss: 235.6476\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 8ms/step - loss: 216.6165 - val_loss: 228.3745\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 211.0146 - val_loss: 223.5035\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 206.5211 - val_loss: 217.5957\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 202.3114 - val_loss: 212.4173\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 198.7175 - val_loss: 209.3985\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 195.1811 - val_loss: 205.1400\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 192.0659 - val_loss: 200.8110\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 6ms/step - loss: 189.0456 - val_loss: 198.8543\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 186.1742 - val_loss: 194.1261\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 183.2242 - val_loss: 191.1936\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 180.5223 - val_loss: 189.0850\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 7ms/step - loss: 177.8967 - val_loss: 186.9066\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 175.7377 - val_loss: 184.5560\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.5313 - val_loss: 181.0324\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 171.7984 - val_loss: 178.0406\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.4871 - val_loss: 177.1391\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 167.5866 - val_loss: 175.4468\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 165.9912 - val_loss: 172.2590\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 10ms/step - loss: 163.7159 - val_loss: 170.9541\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 9ms/step - loss: 161.8195 - val_loss: 168.5618\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 8ms/step - loss: 159.9230 - val_loss: 166.6955\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 14ms/step - loss: 157.9610 - val_loss: 164.5314\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 7ms/step - loss: 155.8326 - val_loss: 162.0402\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 153.5286 - val_loss: 159.9760\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.2621 - val_loss: 158.2387\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 16ms/step - loss: 148.9583 - val_loss: 156.0561\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 146.7073 - val_loss: 152.7397\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 8ms/step - loss: 143.9630 - val_loss: 151.6643\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.1340 - val_loss: 149.3250\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 138.6144 - val_loss: 146.0646\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.1524 - val_loss: 144.8731\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.7170 - val_loss: 141.9559\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 130.8663 - val_loss: 140.9235\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 128.5078 - val_loss: 137.0196\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 115ms/step - loss: 1508.0905 - val_loss: 1400.7609\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1461.8961 - val_loss: 1345.0149\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 9ms/step - loss: 1395.2859 - val_loss: 1263.1271\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1293.7365 - val_loss: 1140.2415\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1144.2920 - val_loss: 965.8200\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 937.3224 - val_loss: 738.6558\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 687.2284 - val_loss: 494.8289\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 448.9346 - val_loss: 318.2932\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 9ms/step - loss: 299.6372 - val_loss: 251.1957\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 7ms/step - loss: 244.4922 - val_loss: 228.1602\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 7ms/step - loss: 219.4734 - val_loss: 206.6831\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 8ms/step - loss: 202.7598 - val_loss: 195.3543\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 192.3195 - val_loss: 184.6431\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 7ms/step - loss: 183.1158 - val_loss: 179.5594\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 177.0881 - val_loss: 172.5082\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 171.8315 - val_loss: 169.3689\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 14ms/step - loss: 167.1988 - val_loss: 166.0249\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 7ms/step - loss: 163.9841 - val_loss: 161.5986\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 14ms/step - loss: 160.6637 - val_loss: 158.4579\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 7ms/step - loss: 158.2213 - val_loss: 156.0957\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 156.0075 - val_loss: 154.8181\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 12ms/step - loss: 153.6848 - val_loss: 152.0301\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 7ms/step - loss: 151.3366 - val_loss: 150.8012\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 7ms/step - loss: 149.8333 - val_loss: 149.0452\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 15ms/step - loss: 147.8607 - val_loss: 147.9564\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 15ms/step - loss: 145.9077 - val_loss: 143.3686\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 8ms/step - loss: 144.1406 - val_loss: 143.9394\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 142.2016 - val_loss: 140.7377\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 140.8456 - val_loss: 139.8982\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 9ms/step - loss: 139.6603 - val_loss: 136.8279\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 7ms/step - loss: 137.8127 - val_loss: 136.3187\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 15ms/step - loss: 136.7137 - val_loss: 134.4909\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 134.9142 - val_loss: 131.5110\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 133.7752 - val_loss: 132.0680\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 8ms/step - loss: 132.6958 - val_loss: 130.6213\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 7ms/step - loss: 131.0908 - val_loss: 127.8818\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 129.5747 - val_loss: 127.6646\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 128.7402 - val_loss: 127.5743\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 127.5883 - val_loss: 124.6705\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 126.1308 - val_loss: 124.2390\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 125.1507 - val_loss: 122.2918\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 7ms/step - loss: 124.5437 - val_loss: 120.8300\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 9ms/step - loss: 123.3111 - val_loss: 121.6601\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 7ms/step - loss: 122.0982 - val_loss: 119.1827\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 121.4737 - val_loss: 117.9893\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 7ms/step - loss: 120.8970 - val_loss: 117.5327\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 120.5055 - val_loss: 117.9608\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 119.2276 - val_loss: 115.4446\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 118.0372 - val_loss: 114.4042\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 117.1367 - val_loss: 114.6126\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 6s - 241ms/step - loss: 1525.9143 - val_loss: 1592.0925\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1505.6494 - val_loss: 1570.6343\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 9ms/step - loss: 1482.9031 - val_loss: 1545.0518\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1453.1536 - val_loss: 1509.1727\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 11ms/step - loss: 1408.9032 - val_loss: 1451.8444\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1331.9141 - val_loss: 1341.9719\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1190.0409 - val_loss: 1161.4926\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 983.0303 - val_loss: 930.0198\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 742.1795 - val_loss: 684.0889\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 519.2350 - val_loss: 483.3460\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 365.6466 - val_loss: 368.2268\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 290.5112 - val_loss: 306.6398\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 252.9618 - val_loss: 274.3283\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 7ms/step - loss: 233.2086 - val_loss: 252.3608\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 218.6118 - val_loss: 239.5076\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 8ms/step - loss: 209.0088 - val_loss: 228.5194\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 200.4599 - val_loss: 219.8102\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 194.0967 - val_loss: 213.2923\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 188.3850 - val_loss: 207.6441\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 183.6411 - val_loss: 203.6615\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 8ms/step - loss: 178.7648 - val_loss: 198.6680\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 175.3127 - val_loss: 194.6544\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 171.7299 - val_loss: 191.3266\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 6ms/step - loss: 168.6933 - val_loss: 188.6858\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 165.7917 - val_loss: 185.4471\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 163.1616 - val_loss: 182.8021\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 160.4661 - val_loss: 180.3833\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 158.2410 - val_loss: 177.9698\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 155.6909 - val_loss: 175.4094\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 153.6442 - val_loss: 173.9332\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.2451 - val_loss: 170.7383\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 149.4554 - val_loss: 168.8389\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 147.6066 - val_loss: 167.2484\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 7ms/step - loss: 145.3335 - val_loss: 164.9724\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 9ms/step - loss: 143.7251 - val_loss: 163.4884\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.0005 - val_loss: 161.6304\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 140.5170 - val_loss: 160.0870\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 138.8626 - val_loss: 158.6495\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.4152 - val_loss: 156.8055\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 135.9737 - val_loss: 155.7547\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.8847 - val_loss: 154.5246\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 8ms/step - loss: 133.8584 - val_loss: 153.7274\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 132.7537 - val_loss: 152.3269\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 8ms/step - loss: 132.1709 - val_loss: 151.5639\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.6696 - val_loss: 150.7497\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 14ms/step - loss: 130.7198 - val_loss: 149.6505\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 7ms/step - loss: 130.2086 - val_loss: 149.2068\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.3851 - val_loss: 148.2074\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 128.9202 - val_loss: 147.7839\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.4728 - val_loss: 147.2228\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 115ms/step - loss: 1514.2332 - val_loss: 1657.6339\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 9ms/step - loss: 1490.1901 - val_loss: 1628.9430\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1457.8132 - val_loss: 1585.5945\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1402.5690 - val_loss: 1507.0964\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1308.9308 - val_loss: 1381.4622\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1166.9257 - val_loss: 1197.4546\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 970.5623 - val_loss: 950.4664\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 6ms/step - loss: 731.9105 - val_loss: 671.6181\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 489.2966 - val_loss: 426.9878\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 319.6401 - val_loss: 274.3842\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 7ms/step - loss: 236.5827 - val_loss: 219.5885\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 209.8356 - val_loss: 201.3345\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 198.1852 - val_loss: 190.5845\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 189.3470 - val_loss: 184.6982\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 183.1530 - val_loss: 179.4007\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 177.5224 - val_loss: 176.7590\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 173.1587 - val_loss: 174.1765\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 169.5162 - val_loss: 170.9893\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 7ms/step - loss: 166.2255 - val_loss: 169.4686\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 15ms/step - loss: 163.2504 - val_loss: 167.0120\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 160.6292 - val_loss: 164.5026\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 157.9062 - val_loss: 162.2209\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 6ms/step - loss: 155.7018 - val_loss: 161.6844\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.3925 - val_loss: 159.6802\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 151.6785 - val_loss: 159.1481\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 149.7230 - val_loss: 157.0735\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.2498 - val_loss: 155.0450\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 146.8358 - val_loss: 154.7498\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 7ms/step - loss: 144.8187 - val_loss: 153.0191\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.4821 - val_loss: 152.7103\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.2496 - val_loss: 151.5168\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.3908 - val_loss: 150.5775\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 139.5929 - val_loss: 149.4021\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 139.0461 - val_loss: 148.7237\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 11ms/step - loss: 137.7429 - val_loss: 147.5459\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 136.8117 - val_loss: 147.2794\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 135.8209 - val_loss: 146.5069\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.8812 - val_loss: 146.2337\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.1292 - val_loss: 144.9065\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.9939 - val_loss: 144.0575\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 132.1205 - val_loss: 143.4051\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 131.3986 - val_loss: 143.4254\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.7111 - val_loss: 141.9786\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.0686 - val_loss: 141.1671\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.3536 - val_loss: 140.6389\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.4680 - val_loss: 140.8501\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 127.9616 - val_loss: 140.8250\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 127.3401 - val_loss: 139.7122\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.7011 - val_loss: 138.9733\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.3245 - val_loss: 137.8622\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 117ms/step - loss: 1543.5315 - val_loss: 1554.3834\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 6ms/step - loss: 1512.8977 - val_loss: 1523.8640\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 7ms/step - loss: 1477.0253 - val_loss: 1481.3228\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1423.2450 - val_loss: 1416.9146\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1341.5514 - val_loss: 1319.4961\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1222.3224 - val_loss: 1178.4161\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 8ms/step - loss: 1058.6508 - val_loss: 993.2392\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 856.2407 - val_loss: 772.8305\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 635.5863 - val_loss: 543.2227\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 435.8611 - val_loss: 356.1412\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 293.8821 - val_loss: 248.7392\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 230.1663 - val_loss: 200.5935\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 207.9798 - val_loss: 184.8887\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 197.9521 - val_loss: 176.7901\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 189.5462 - val_loss: 169.4924\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 183.2043 - val_loss: 164.9543\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 176.3538 - val_loss: 159.6608\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 171.4855 - val_loss: 155.3893\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 166.5457 - val_loss: 151.6630\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 162.4746 - val_loss: 148.0550\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 159.0017 - val_loss: 145.3437\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 9ms/step - loss: 155.6518 - val_loss: 142.7099\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 152.6988 - val_loss: 140.2544\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.0160 - val_loss: 138.5685\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 147.4289 - val_loss: 136.0802\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 7ms/step - loss: 144.9210 - val_loss: 133.9086\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.4864 - val_loss: 132.3060\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 7ms/step - loss: 140.1278 - val_loss: 130.6164\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 14ms/step - loss: 137.7543 - val_loss: 128.0353\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 135.3236 - val_loss: 126.5684\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 132.8552 - val_loss: 124.7256\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 130.0715 - val_loss: 122.9837\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.6011 - val_loss: 120.7610\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.6157 - val_loss: 119.6651\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.7490 - val_loss: 117.3415\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 121.1551 - val_loss: 116.2315\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 119.0105 - val_loss: 114.9395\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 116.7557 - val_loss: 112.8643\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 12ms/step - loss: 115.2114 - val_loss: 111.9089\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.9124 - val_loss: 110.6199\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.3219 - val_loss: 109.0674\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.5716 - val_loss: 107.5398\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 107.5917 - val_loss: 106.4395\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 106.3199 - val_loss: 105.1951\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 104.8049 - val_loss: 104.3698\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 102.9128 - val_loss: 102.9938\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 101.4934 - val_loss: 102.0389\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 100.1788 - val_loss: 100.7960\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 99.0621 - val_loss: 100.3183\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 97.3801 - val_loss: 99.1290\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 113ms/step - loss: 1575.4506 - val_loss: 1530.9991\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 6ms/step - loss: 1563.1750 - val_loss: 1514.6396\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1537.3811 - val_loss: 1476.7043\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1489.2839 - val_loss: 1421.3153\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1423.2303 - val_loss: 1345.5057\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1334.6951 - val_loss: 1245.1420\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 1217.4314 - val_loss: 1116.5505\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1070.0620 - val_loss: 956.8293\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 7ms/step - loss: 891.8625 - val_loss: 778.1664\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 700.4063 - val_loss: 593.6612\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 518.3725 - val_loss: 442.9424\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 381.0264 - val_loss: 345.6694\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 298.3313 - val_loss: 293.8170\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 254.5941 - val_loss: 265.9666\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 234.2073 - val_loss: 247.4070\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 220.2587 - val_loss: 233.8067\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 9ms/step - loss: 212.0881 - val_loss: 225.2388\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 7ms/step - loss: 206.4108 - val_loss: 218.1456\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 201.6339 - val_loss: 211.9043\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 197.7815 - val_loss: 206.8600\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 194.0075 - val_loss: 202.7687\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 6ms/step - loss: 190.6501 - val_loss: 198.1545\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 3ms/step - loss: 187.5199 - val_loss: 194.5306\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 184.8433 - val_loss: 191.3144\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 182.2203 - val_loss: 187.6937\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 179.1796 - val_loss: 184.2856\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 8ms/step - loss: 176.8774 - val_loss: 181.7566\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 174.1114 - val_loss: 178.2563\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 171.6136 - val_loss: 175.7133\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.2833 - val_loss: 172.8771\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 166.8368 - val_loss: 170.3728\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 164.9156 - val_loss: 168.1286\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 162.6228 - val_loss: 165.8509\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 160.5795 - val_loss: 163.0941\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 158.5378 - val_loss: 161.7260\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.7579 - val_loss: 159.2581\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 154.5294 - val_loss: 157.5442\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 153.2457 - val_loss: 155.8359\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.9962 - val_loss: 154.0812\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 15ms/step - loss: 149.4472 - val_loss: 152.3329\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 147.8818 - val_loss: 151.0345\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 146.3823 - val_loss: 149.7065\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 9ms/step - loss: 144.9522 - val_loss: 148.2550\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 143.5724 - val_loss: 146.3626\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 9ms/step - loss: 142.1043 - val_loss: 144.8618\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.8105 - val_loss: 143.7005\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.5855 - val_loss: 142.7676\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 138.0065 - val_loss: 141.2630\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.9878 - val_loss: 139.8993\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 135.9025 - val_loss: 138.7993\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 111ms/step - loss: 1568.5037 - val_loss: 1520.0027\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 6ms/step - loss: 1548.8383 - val_loss: 1497.5071\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 7ms/step - loss: 1519.3795 - val_loss: 1461.1149\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1470.6204 - val_loss: 1397.8142\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1386.2051 - val_loss: 1291.8646\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 1251.8617 - val_loss: 1123.7299\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1046.3151 - val_loss: 893.3837\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 9ms/step - loss: 781.6216 - val_loss: 615.0185\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 506.2643 - val_loss: 384.8832\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 9ms/step - loss: 322.4337 - val_loss: 279.6924\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 255.1400 - val_loss: 259.2769\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 7ms/step - loss: 237.7242 - val_loss: 248.0334\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 227.4501 - val_loss: 237.5059\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 217.8937 - val_loss: 228.8039\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 210.7985 - val_loss: 219.6065\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 7ms/step - loss: 202.7596 - val_loss: 212.5932\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 196.3409 - val_loss: 206.0731\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.4144 - val_loss: 198.3113\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 7ms/step - loss: 184.9432 - val_loss: 192.8456\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 179.9510 - val_loss: 187.2262\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 175.2957 - val_loss: 182.1507\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 170.9337 - val_loss: 177.5749\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.1325 - val_loss: 173.3131\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.8618 - val_loss: 168.3571\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.5569 - val_loss: 165.1891\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 156.2553 - val_loss: 161.2614\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 153.2468 - val_loss: 157.7712\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.4883 - val_loss: 155.1494\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.4776 - val_loss: 151.9268\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.6923 - val_loss: 149.9631\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.3065 - val_loss: 147.2747\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.1977 - val_loss: 144.9648\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 7ms/step - loss: 139.1962 - val_loss: 142.8549\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 137.4212 - val_loss: 140.9460\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 135.8779 - val_loss: 138.9945\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.0128 - val_loss: 137.1507\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 132.8019 - val_loss: 135.6373\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.2225 - val_loss: 134.2053\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 129.7845 - val_loss: 132.4521\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.4741 - val_loss: 131.4313\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 12ms/step - loss: 127.1080 - val_loss: 129.8458\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 126.4709 - val_loss: 128.7882\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 9ms/step - loss: 125.3148 - val_loss: 128.1036\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 124.5971 - val_loss: 127.1064\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.7845 - val_loss: 126.4480\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 122.4771 - val_loss: 125.1855\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.6953 - val_loss: 124.7586\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 120.6653 - val_loss: 124.3827\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 120.1086 - val_loss: 123.3700\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 119.1772 - val_loss: 122.5671\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 107ms/step - loss: 1578.1221 - val_loss: 1530.0232\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1560.3629 - val_loss: 1513.3132\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1543.3660 - val_loss: 1492.8472\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1517.5696 - val_loss: 1456.6080\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1471.8474 - val_loss: 1393.9189\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1392.4567 - val_loss: 1288.9708\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1257.8315 - val_loss: 1122.0519\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 9ms/step - loss: 1054.9302 - val_loss: 887.4214\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 800.7059 - val_loss: 621.1730\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 538.3117 - val_loss: 412.4401\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 351.8989 - val_loss: 313.4458\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 6ms/step - loss: 264.2107 - val_loss: 285.8777\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 237.0495 - val_loss: 269.3060\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 223.9287 - val_loss: 256.5010\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 7ms/step - loss: 213.2723 - val_loss: 243.0453\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 205.5002 - val_loss: 232.4882\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 198.2917 - val_loss: 225.6667\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 192.3815 - val_loss: 218.4765\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 186.9858 - val_loss: 210.7444\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 181.1942 - val_loss: 206.8610\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 176.9894 - val_loss: 201.4656\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 171.8687 - val_loss: 195.6015\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.6944 - val_loss: 189.1504\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.5960 - val_loss: 185.9721\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 159.6042 - val_loss: 182.8771\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.6683 - val_loss: 178.6428\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.4989 - val_loss: 174.3118\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.2099 - val_loss: 171.7952\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 147.5106 - val_loss: 168.6893\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 144.3915 - val_loss: 165.1544\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 6ms/step - loss: 141.9040 - val_loss: 162.6044\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.6849 - val_loss: 160.1135\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.4708 - val_loss: 158.1085\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 11ms/step - loss: 135.4501 - val_loss: 155.4990\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 9ms/step - loss: 133.5856 - val_loss: 153.9366\n",
      "Epoch 36/50\n",
      "23/23 - 1s - 25ms/step - loss: 131.8512 - val_loss: 151.3450\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.0847 - val_loss: 149.7180\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.6132 - val_loss: 148.0610\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.9936 - val_loss: 145.5566\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.4335 - val_loss: 144.2219\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 125.1609 - val_loss: 142.3674\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 122.1416 - val_loss: 139.8067\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.7051 - val_loss: 139.2308\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 119.1940 - val_loss: 137.1259\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.7557 - val_loss: 135.9878\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 116.3581 - val_loss: 134.1411\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 114.9964 - val_loss: 131.9319\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 3ms/step - loss: 113.5945 - val_loss: 130.8413\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.3067 - val_loss: 128.9575\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 110.6474 - val_loss: 127.2858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 121ms/step - loss: 1648.0969 - val_loss: 1570.8982\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1576.0787 - val_loss: 1513.0785\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1519.5940 - val_loss: 1458.0785\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1458.6503 - val_loss: 1392.9396\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 6ms/step - loss: 1383.3464 - val_loss: 1311.6321\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1289.7145 - val_loss: 1208.9977\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1169.8066 - val_loss: 1080.3588\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1024.5566 - val_loss: 922.7867\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 848.4243 - val_loss: 747.9547\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 662.3653 - val_loss: 570.1173\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 486.2776 - val_loss: 424.2522\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 357.0506 - val_loss: 327.9274\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 8ms/step - loss: 280.2407 - val_loss: 282.6598\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 247.7207 - val_loss: 262.7697\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 7ms/step - loss: 232.7156 - val_loss: 252.9553\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 224.0681 - val_loss: 246.9521\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 217.2079 - val_loss: 240.8229\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 211.4857 - val_loss: 234.7867\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 205.5037 - val_loss: 230.0484\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 9ms/step - loss: 200.6869 - val_loss: 224.7680\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 14ms/step - loss: 196.4845 - val_loss: 220.2907\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 6ms/step - loss: 191.9825 - val_loss: 215.8361\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 187.6979 - val_loss: 211.4845\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 183.6120 - val_loss: 207.9337\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 180.1883 - val_loss: 202.9213\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 176.4680 - val_loss: 200.0956\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 173.0811 - val_loss: 196.3274\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.8851 - val_loss: 192.5181\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 3ms/step - loss: 167.0201 - val_loss: 189.7266\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 7ms/step - loss: 164.5812 - val_loss: 187.5979\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 7ms/step - loss: 161.8146 - val_loss: 184.6234\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 7ms/step - loss: 159.1463 - val_loss: 181.7673\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 12ms/step - loss: 156.7418 - val_loss: 179.5856\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 154.5710 - val_loss: 176.9668\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 152.3410 - val_loss: 174.9514\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.3960 - val_loss: 173.6266\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.9261 - val_loss: 172.3140\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 147.4120 - val_loss: 169.9475\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 12ms/step - loss: 145.3754 - val_loss: 168.5986\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 144.2854 - val_loss: 167.0587\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.9906 - val_loss: 165.4739\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.4026 - val_loss: 164.3432\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.1899 - val_loss: 162.4124\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 139.1650 - val_loss: 161.5968\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 138.0087 - val_loss: 159.7995\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 8ms/step - loss: 136.6954 - val_loss: 159.1082\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 135.7386 - val_loss: 158.3736\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 134.8396 - val_loss: 157.3332\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 133.7673 - val_loss: 156.0906\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 132.7947 - val_loss: 155.0643\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 126ms/step - loss: 1566.3240 - val_loss: 1429.8665\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 7ms/step - loss: 1523.4005 - val_loss: 1380.8719\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1464.9147 - val_loss: 1313.2979\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1383.5748 - val_loss: 1221.6576\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 10ms/step - loss: 1274.3679 - val_loss: 1099.2960\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 1130.7504 - val_loss: 943.3967\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 8ms/step - loss: 953.2548 - val_loss: 757.0018\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 12ms/step - loss: 752.7314 - val_loss: 571.4778\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 571.2927 - val_loss: 436.7979\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 450.3050 - val_loss: 362.9156\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 8ms/step - loss: 384.3405 - val_loss: 324.3200\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 12ms/step - loss: 341.1042 - val_loss: 293.5886\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 309.2049 - val_loss: 270.5285\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 9ms/step - loss: 284.5945 - val_loss: 251.3674\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 264.0168 - val_loss: 235.3983\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 248.3403 - val_loss: 221.9893\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 8ms/step - loss: 234.7406 - val_loss: 211.9593\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 223.5156 - val_loss: 203.5481\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 17ms/step - loss: 214.7201 - val_loss: 196.0140\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 207.7182 - val_loss: 190.8000\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 201.5753 - val_loss: 185.9956\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 6ms/step - loss: 196.0056 - val_loss: 180.9108\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 191.3731 - val_loss: 177.3040\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 187.4514 - val_loss: 173.5748\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 183.3445 - val_loss: 170.9492\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 179.8586 - val_loss: 168.5067\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 176.6726 - val_loss: 165.2967\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 173.7847 - val_loss: 162.0012\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 170.6485 - val_loss: 160.3078\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.4608 - val_loss: 157.6793\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 164.9734 - val_loss: 155.6316\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.4440 - val_loss: 153.5838\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 9ms/step - loss: 160.2260 - val_loss: 152.1810\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 158.0975 - val_loss: 150.4289\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 155.8532 - val_loss: 148.3286\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 154.5279 - val_loss: 146.9204\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 152.8416 - val_loss: 146.5098\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.7738 - val_loss: 144.5040\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.4303 - val_loss: 143.0973\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 7ms/step - loss: 148.4757 - val_loss: 141.7207\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 146.5605 - val_loss: 140.8296\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.4818 - val_loss: 139.5941\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.2022 - val_loss: 138.4332\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.7818 - val_loss: 137.9299\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.4053 - val_loss: 136.4965\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 141.4017 - val_loss: 136.0183\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 11ms/step - loss: 139.8678 - val_loss: 134.4321\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 138.6426 - val_loss: 134.3813\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 137.7703 - val_loss: 133.5832\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 137.1481 - val_loss: 132.4483\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 107ms/step - loss: 1543.8109 - val_loss: 1611.8416\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1524.1407 - val_loss: 1589.1318\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1500.3062 - val_loss: 1559.8209\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1468.9170 - val_loss: 1520.6901\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1426.4658 - val_loss: 1463.2223\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1360.9349 - val_loss: 1369.7308\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 3ms/step - loss: 1254.0100 - val_loss: 1223.1095\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1095.4825 - val_loss: 1024.0331\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 898.5074 - val_loss: 790.7844\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 684.8696 - val_loss: 571.6415\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 500.3251 - val_loss: 403.9890\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 371.0431 - val_loss: 299.3791\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 294.2037 - val_loss: 243.6365\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 251.8661 - val_loss: 215.0465\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 226.8964 - val_loss: 199.3929\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 209.7963 - val_loss: 189.9411\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 198.9472 - val_loss: 183.6629\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 190.0461 - val_loss: 179.0358\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 183.5111 - val_loss: 175.2660\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 177.9674 - val_loss: 172.0152\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.9493 - val_loss: 169.5231\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 6ms/step - loss: 169.4231 - val_loss: 167.4157\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.6664 - val_loss: 165.4107\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.5517 - val_loss: 163.4024\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.6118 - val_loss: 161.0453\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 156.7156 - val_loss: 158.9576\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 154.7493 - val_loss: 156.7566\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.5098 - val_loss: 154.9332\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.1684 - val_loss: 153.0928\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.9225 - val_loss: 151.1797\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 6ms/step - loss: 144.8305 - val_loss: 149.3268\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 142.9416 - val_loss: 147.0398\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.3103 - val_loss: 145.2233\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.6028 - val_loss: 143.6793\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 3ms/step - loss: 136.9853 - val_loss: 141.8055\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 135.6374 - val_loss: 140.5157\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 133.3309 - val_loss: 138.6224\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.0266 - val_loss: 137.1968\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.7847 - val_loss: 135.9175\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.3156 - val_loss: 134.1355\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.3866 - val_loss: 133.3591\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.6726 - val_loss: 131.7546\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 124.2675 - val_loss: 130.7719\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 123.1133 - val_loss: 129.7708\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 11ms/step - loss: 121.7797 - val_loss: 128.9277\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - loss: 120.6664 - val_loss: 127.6152\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 119.6027 - val_loss: 127.0093\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 118.1726 - val_loss: 125.6280\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 117.1721 - val_loss: 124.9968\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 116.2953 - val_loss: 124.0009\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 148ms/step - loss: 1513.2313 - val_loss: 1588.1158\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1473.6176 - val_loss: 1542.5782\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1417.1638 - val_loss: 1470.6100\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 6ms/step - loss: 1325.0172 - val_loss: 1358.2506\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1189.1909 - val_loss: 1206.4574\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1015.7744 - val_loss: 1013.7139\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 7ms/step - loss: 812.9437 - val_loss: 810.8358\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 620.5604 - val_loss: 635.8358\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 475.9301 - val_loss: 516.7319\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 388.7636 - val_loss: 436.7212\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 329.0815 - val_loss: 377.2352\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 285.4870 - val_loss: 330.9329\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 253.2933 - val_loss: 293.1284\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 7ms/step - loss: 230.0067 - val_loss: 262.4593\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 13ms/step - loss: 210.2081 - val_loss: 241.8267\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 197.2541 - val_loss: 225.9311\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 187.1831 - val_loss: 214.9106\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 179.5826 - val_loss: 206.9464\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.0479 - val_loss: 200.4884\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 168.3118 - val_loss: 196.6054\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.6228 - val_loss: 191.8473\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 6ms/step - loss: 160.1880 - val_loss: 188.4369\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 10ms/step - loss: 156.5169 - val_loss: 185.6710\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 6ms/step - loss: 154.0356 - val_loss: 182.6286\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 150.8279 - val_loss: 179.7200\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 18ms/step - loss: 148.0827 - val_loss: 177.9529\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 10ms/step - loss: 145.7915 - val_loss: 174.2625\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 15ms/step - loss: 143.0304 - val_loss: 172.0647\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 12ms/step - loss: 141.4640 - val_loss: 170.2462\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 7ms/step - loss: 139.2609 - val_loss: 167.3860\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 6ms/step - loss: 135.9714 - val_loss: 166.2016\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 7ms/step - loss: 134.4245 - val_loss: 163.2995\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 10ms/step - loss: 132.5638 - val_loss: 160.0792\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 7ms/step - loss: 130.6679 - val_loss: 158.9161\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 13ms/step - loss: 128.4985 - val_loss: 157.8743\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 3ms/step - loss: 126.4110 - val_loss: 155.5832\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 124.5476 - val_loss: 153.7654\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 122.7282 - val_loss: 152.5903\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 120.8453 - val_loss: 149.5724\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 7ms/step - loss: 118.7635 - val_loss: 147.4723\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 13ms/step - loss: 117.5826 - val_loss: 146.0191\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.4662 - val_loss: 144.6224\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 10ms/step - loss: 113.5100 - val_loss: 142.9730\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.6637 - val_loss: 141.7780\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 109.8816 - val_loss: 139.6040\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 108.0560 - val_loss: 136.7803\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 106.2544 - val_loss: 135.6826\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 104.3292 - val_loss: 134.5610\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 102.5644 - val_loss: 132.4081\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 101.0231 - val_loss: 131.3782\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 131ms/step - loss: 1691.1431 - val_loss: 1513.2137\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 8ms/step - loss: 1651.2876 - val_loss: 1483.1483\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 8ms/step - loss: 1622.8036 - val_loss: 1461.0581\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1600.9641 - val_loss: 1442.9818\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 6ms/step - loss: 1581.5223 - val_loss: 1424.7208\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 1559.5979 - val_loss: 1401.7842\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1528.8778 - val_loss: 1367.6001\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 6ms/step - loss: 1479.6295 - val_loss: 1311.6239\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 1398.5109 - val_loss: 1220.8004\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 1271.1796 - val_loss: 1085.2598\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 9ms/step - loss: 1087.2715 - val_loss: 894.1071\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 848.9992 - val_loss: 663.7062\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 9ms/step - loss: 589.1806 - val_loss: 436.3393\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 14ms/step - loss: 379.8325 - val_loss: 277.6231\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 14ms/step - loss: 268.4099 - val_loss: 207.2255\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 229.6125 - val_loss: 186.3797\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 7ms/step - loss: 215.6974 - val_loss: 176.1168\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 205.2135 - val_loss: 170.1843\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 8ms/step - loss: 196.7482 - val_loss: 164.2838\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 189.4841 - val_loss: 159.3918\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 8ms/step - loss: 183.7770 - val_loss: 156.3020\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 7ms/step - loss: 178.4365 - val_loss: 152.4101\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.6827 - val_loss: 149.8030\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 7ms/step - loss: 169.7303 - val_loss: 147.5696\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 166.2032 - val_loss: 144.8115\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 163.3624 - val_loss: 143.1364\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 160.3301 - val_loss: 140.5172\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 158.0027 - val_loss: 139.2355\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 9ms/step - loss: 155.7604 - val_loss: 138.3359\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 153.9626 - val_loss: 137.1151\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 152.5215 - val_loss: 135.8960\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.9370 - val_loss: 134.9503\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 9ms/step - loss: 149.5839 - val_loss: 134.2472\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 13ms/step - loss: 148.5272 - val_loss: 133.8634\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 12ms/step - loss: 147.0456 - val_loss: 133.0677\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.0911 - val_loss: 132.2882\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.9101 - val_loss: 131.5030\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.8179 - val_loss: 130.9668\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 6ms/step - loss: 143.0008 - val_loss: 130.2885\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 141.6036 - val_loss: 129.8788\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 8ms/step - loss: 140.8406 - val_loss: 129.2139\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.1044 - val_loss: 128.3993\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.2560 - val_loss: 127.5922\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 137.9863 - val_loss: 127.4149\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 137.1156 - val_loss: 126.7891\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.5262 - val_loss: 126.7668\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 135.3666 - val_loss: 126.1068\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 134.5695 - val_loss: 125.2752\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.7355 - val_loss: 124.8142\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.2944 - val_loss: 124.2527\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 116ms/step - loss: 1521.8878 - val_loss: 1643.8451\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 6ms/step - loss: 1506.2487 - val_loss: 1624.1753\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 8ms/step - loss: 1481.9563 - val_loss: 1592.6296\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 6ms/step - loss: 1442.7252 - val_loss: 1538.2423\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1376.1416 - val_loss: 1451.0433\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 7ms/step - loss: 1275.6383 - val_loss: 1319.6371\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1131.5797 - val_loss: 1142.3441\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 946.6836 - val_loss: 915.5157\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 8ms/step - loss: 729.3063 - val_loss: 669.1534\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 517.0844 - val_loss: 466.5042\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 373.4117 - val_loss: 355.5431\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 302.1665 - val_loss: 301.7695\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 9ms/step - loss: 268.9481 - val_loss: 270.0699\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 246.2129 - val_loss: 248.8102\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 230.6565 - val_loss: 233.1665\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 218.0571 - val_loss: 219.5334\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 207.8226 - val_loss: 208.6257\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 198.6057 - val_loss: 199.9800\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 190.5887 - val_loss: 190.2494\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 183.5964 - val_loss: 183.5093\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 8ms/step - loss: 177.9930 - val_loss: 177.2143\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 172.5143 - val_loss: 171.5227\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.7569 - val_loss: 166.7486\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 6ms/step - loss: 163.5507 - val_loss: 162.5546\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 7ms/step - loss: 159.4566 - val_loss: 158.2463\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 154.9192 - val_loss: 153.7754\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 151.5848 - val_loss: 149.0745\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 147.8783 - val_loss: 146.2189\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.3659 - val_loss: 142.2506\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 9ms/step - loss: 141.1628 - val_loss: 138.7617\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.5535 - val_loss: 135.6315\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 10ms/step - loss: 134.6244 - val_loss: 131.6150\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.9380 - val_loss: 128.5843\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.0579 - val_loss: 125.2629\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.1234 - val_loss: 122.3590\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 7ms/step - loss: 122.6172 - val_loss: 119.2721\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 119.9571 - val_loss: 116.0141\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.2974 - val_loss: 113.9230\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.5674 - val_loss: 110.7650\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 12ms/step - loss: 112.2146 - val_loss: 108.2393\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 109.7612 - val_loss: 105.6103\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 106.6847 - val_loss: 102.7598\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 8ms/step - loss: 104.6348 - val_loss: 100.2823\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 101.6934 - val_loss: 97.3935\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 9ms/step - loss: 99.5251 - val_loss: 94.7906\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 97.3335 - val_loss: 92.9428\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 95.7706 - val_loss: 90.3709\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 92.9350 - val_loss: 88.1147\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 90.9708 - val_loss: 86.0871\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 10ms/step - loss: 88.7438 - val_loss: 83.7214\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 116ms/step - loss: 1558.3267 - val_loss: 1485.2543\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 8ms/step - loss: 1534.1614 - val_loss: 1458.4331\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 8ms/step - loss: 1496.4224 - val_loss: 1412.9366\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1430.5516 - val_loss: 1332.0354\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1316.6741 - val_loss: 1198.2650\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1136.2026 - val_loss: 994.0411\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 890.0010 - val_loss: 750.9674\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 6ms/step - loss: 624.8624 - val_loss: 524.3155\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 418.6085 - val_loss: 368.4625\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 311.3503 - val_loss: 295.4653\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 10ms/step - loss: 261.7765 - val_loss: 265.3299\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 239.7128 - val_loss: 248.3501\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 226.5707 - val_loss: 236.4560\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 8ms/step - loss: 215.5076 - val_loss: 226.6294\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 206.6507 - val_loss: 218.2853\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 9ms/step - loss: 199.0400 - val_loss: 211.0463\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 192.0558 - val_loss: 204.6519\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 185.5898 - val_loss: 199.2042\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 180.1528 - val_loss: 193.7800\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 174.7636 - val_loss: 188.7317\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.8730 - val_loss: 184.0440\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 6ms/step - loss: 165.9151 - val_loss: 180.1251\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 161.9903 - val_loss: 176.6595\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 158.4570 - val_loss: 173.0541\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 155.4062 - val_loss: 170.0299\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 152.3844 - val_loss: 167.5873\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.5584 - val_loss: 164.7527\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 7ms/step - loss: 147.3133 - val_loss: 162.6944\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.2564 - val_loss: 160.6188\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 143.2233 - val_loss: 158.5918\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 141.1149 - val_loss: 156.2998\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 8ms/step - loss: 139.2384 - val_loss: 155.0203\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 138.5170 - val_loss: 153.8031\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 136.1565 - val_loss: 151.7630\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 134.6315 - val_loss: 150.6420\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 133.2088 - val_loss: 149.6313\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 132.1107 - val_loss: 148.2160\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 9ms/step - loss: 130.7031 - val_loss: 147.0423\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 129.7451 - val_loss: 146.2383\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 13ms/step - loss: 128.6514 - val_loss: 144.8748\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.9037 - val_loss: 144.7145\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 7ms/step - loss: 126.6469 - val_loss: 143.1563\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.5942 - val_loss: 142.6238\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 7ms/step - loss: 124.7063 - val_loss: 141.2875\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.8829 - val_loss: 140.6234\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 123.3186 - val_loss: 140.1276\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 122.3501 - val_loss: 139.6040\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.5971 - val_loss: 138.8057\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 121.2576 - val_loss: 138.0827\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.4119 - val_loss: 137.2699\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 112ms/step - loss: 1496.5924 - val_loss: 1540.1038\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 7ms/step - loss: 1452.0012 - val_loss: 1485.9722\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1386.1261 - val_loss: 1403.8333\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1285.6963 - val_loss: 1276.2128\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1129.4751 - val_loss: 1085.7231\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 909.5701 - val_loss: 832.6091\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 655.0840 - val_loss: 572.2393\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 6ms/step - loss: 434.3490 - val_loss: 380.6324\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 302.2509 - val_loss: 287.9188\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 253.3605 - val_loss: 251.4076\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 230.4872 - val_loss: 233.4413\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 215.4589 - val_loss: 219.3210\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 203.9999 - val_loss: 209.5062\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 195.3409 - val_loss: 201.4743\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 187.8573 - val_loss: 195.9108\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 181.9685 - val_loss: 189.6311\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 176.3522 - val_loss: 184.8779\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 172.0932 - val_loss: 181.5432\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 167.5106 - val_loss: 176.8005\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 7ms/step - loss: 163.4862 - val_loss: 173.8992\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.8771 - val_loss: 170.0547\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.7813 - val_loss: 166.4906\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 6ms/step - loss: 152.7273 - val_loss: 164.4821\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.6134 - val_loss: 160.7742\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.1081 - val_loss: 158.4882\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 10ms/step - loss: 143.2858 - val_loss: 154.9988\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 7ms/step - loss: 140.5541 - val_loss: 151.8318\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 137.8425 - val_loss: 149.6866\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 15ms/step - loss: 135.1267 - val_loss: 147.0479\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 132.4531 - val_loss: 144.4254\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.1937 - val_loss: 142.8449\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.6762 - val_loss: 139.7474\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 123.7570 - val_loss: 137.1900\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 120.6939 - val_loss: 133.8820\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 117.7360 - val_loss: 131.6066\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.6798 - val_loss: 129.1920\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.3653 - val_loss: 126.7719\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 9ms/step - loss: 109.4996 - val_loss: 124.9377\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 7ms/step - loss: 107.0800 - val_loss: 122.4610\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 105.0274 - val_loss: 120.8931\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 12ms/step - loss: 102.3443 - val_loss: 119.1280\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 100.0107 - val_loss: 116.6805\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 8ms/step - loss: 98.1970 - val_loss: 114.6533\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 13ms/step - loss: 96.4958 - val_loss: 112.6928\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 9ms/step - loss: 94.6963 - val_loss: 111.8652\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 7ms/step - loss: 92.7887 - val_loss: 110.4375\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 91.1699 - val_loss: 108.4976\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 89.7657 - val_loss: 107.2382\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 7ms/step - loss: 88.7357 - val_loss: 105.6203\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 87.0340 - val_loss: 104.4655\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 114ms/step - loss: 1568.2585 - val_loss: 1518.9467\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1545.2538 - val_loss: 1492.8729\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1512.8457 - val_loss: 1451.2650\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 6ms/step - loss: 1457.9469 - val_loss: 1381.0819\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 9ms/step - loss: 1365.9587 - val_loss: 1264.5758\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1215.7878 - val_loss: 1085.6877\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 994.5011 - val_loss: 843.8674\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 725.4728 - val_loss: 569.2975\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 461.2928 - val_loss: 367.0590\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 310.0240 - val_loss: 279.5140\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 264.9567 - val_loss: 253.1489\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 6ms/step - loss: 248.3064 - val_loss: 239.3105\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 235.5891 - val_loss: 227.8903\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 226.0064 - val_loss: 217.8844\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 217.7936 - val_loss: 211.0600\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 210.3932 - val_loss: 202.2537\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 6ms/step - loss: 203.0816 - val_loss: 197.1946\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 197.3998 - val_loss: 191.9391\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 192.3046 - val_loss: 186.6071\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 7ms/step - loss: 187.3443 - val_loss: 182.1804\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 182.6830 - val_loss: 177.5242\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 178.6980 - val_loss: 174.5781\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 9ms/step - loss: 175.3421 - val_loss: 171.7375\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 172.1368 - val_loss: 168.8535\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.3343 - val_loss: 165.6382\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 166.0602 - val_loss: 163.7911\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 9ms/step - loss: 163.4035 - val_loss: 161.3788\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 160.3409 - val_loss: 158.4849\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 7ms/step - loss: 158.4977 - val_loss: 156.2520\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 155.8563 - val_loss: 154.9414\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 8ms/step - loss: 153.2497 - val_loss: 152.8147\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 151.2136 - val_loss: 150.5703\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 148.6328 - val_loss: 148.9258\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 7ms/step - loss: 146.8334 - val_loss: 146.9870\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 144.8239 - val_loss: 145.9122\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 7ms/step - loss: 142.7591 - val_loss: 143.2055\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 8ms/step - loss: 141.2586 - val_loss: 142.0314\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 140.0333 - val_loss: 139.9619\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 14ms/step - loss: 138.3111 - val_loss: 139.2282\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.2544 - val_loss: 138.2987\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 13ms/step - loss: 135.1252 - val_loss: 137.1292\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 133.6523 - val_loss: 135.4270\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 8ms/step - loss: 132.7294 - val_loss: 134.8792\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 7ms/step - loss: 131.0538 - val_loss: 133.1762\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 14ms/step - loss: 130.1162 - val_loss: 132.1605\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 129.0901 - val_loss: 131.0728\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.0957 - val_loss: 130.6342\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 127.1462 - val_loss: 129.7476\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.3425 - val_loss: 128.5714\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 7ms/step - loss: 125.8251 - val_loss: 129.0576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 114ms/step - loss: 1505.2932 - val_loss: 1538.6147\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 1465.1299 - val_loss: 1490.1078\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1405.0725 - val_loss: 1414.8795\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1313.6191 - val_loss: 1299.6826\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1178.7273 - val_loss: 1137.3994\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 996.3038 - val_loss: 926.6507\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 771.6390 - val_loss: 689.7469\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 6ms/step - loss: 544.2664 - val_loss: 471.1732\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 364.4378 - val_loss: 334.9942\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 272.6078 - val_loss: 275.3592\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 237.8034 - val_loss: 255.1358\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 223.1938 - val_loss: 242.2312\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 213.6928 - val_loss: 232.9080\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 207.1937 - val_loss: 225.3984\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 201.2879 - val_loss: 219.9395\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 196.5251 - val_loss: 214.5294\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 6ms/step - loss: 192.3245 - val_loss: 210.8096\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 188.2800 - val_loss: 206.0881\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 185.4237 - val_loss: 202.1991\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 181.8198 - val_loss: 198.7902\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 178.9421 - val_loss: 196.0272\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 9ms/step - loss: 175.6604 - val_loss: 193.5299\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.5239 - val_loss: 189.9222\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 170.6714 - val_loss: 187.6763\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 7ms/step - loss: 168.4881 - val_loss: 184.9341\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 166.3887 - val_loss: 182.9025\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 9ms/step - loss: 164.5090 - val_loss: 180.6017\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 13ms/step - loss: 162.8223 - val_loss: 178.9806\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 7ms/step - loss: 160.3598 - val_loss: 176.4554\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 158.5475 - val_loss: 174.6511\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.2782 - val_loss: 172.5448\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 155.8829 - val_loss: 170.7479\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 153.6903 - val_loss: 168.6956\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 152.1072 - val_loss: 167.3159\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.2386 - val_loss: 165.7897\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.6136 - val_loss: 164.5831\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 148.3284 - val_loss: 162.1170\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 8ms/step - loss: 147.3410 - val_loss: 161.7852\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.5921 - val_loss: 160.4123\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 11ms/step - loss: 144.2019 - val_loss: 158.6723\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 11ms/step - loss: 143.3412 - val_loss: 157.7339\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 142.9597 - val_loss: 156.2453\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 141.0826 - val_loss: 154.7217\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 139.6929 - val_loss: 153.6782\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 138.7442 - val_loss: 152.9984\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 138.0526 - val_loss: 151.6246\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.8346 - val_loss: 151.1715\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 135.8971 - val_loss: 150.3407\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 9ms/step - loss: 134.7619 - val_loss: 148.7867\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 133.9157 - val_loss: 147.1293\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 4s - 192ms/step - loss: 1612.7738 - val_loss: 1514.1799\n",
      "Epoch 2/50\n",
      "23/23 - 3s - 121ms/step - loss: 1581.3082 - val_loss: 1487.7372\n",
      "Epoch 3/50\n",
      "23/23 - 2s - 69ms/step - loss: 1554.5714 - val_loss: 1461.7686\n",
      "Epoch 4/50\n",
      "23/23 - 1s - 22ms/step - loss: 1523.9840 - val_loss: 1427.1976\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 14ms/step - loss: 1479.8118 - val_loss: 1375.1571\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 13ms/step - loss: 1412.2518 - val_loss: 1294.6705\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 7ms/step - loss: 1307.7106 - val_loss: 1171.7190\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 11ms/step - loss: 1152.3375 - val_loss: 999.1207\n",
      "Epoch 9/50\n",
      "23/23 - 1s - 43ms/step - loss: 945.2686 - val_loss: 779.4193\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 16ms/step - loss: 699.2397 - val_loss: 545.6552\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 10ms/step - loss: 467.2240 - val_loss: 356.8692\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 16ms/step - loss: 311.0134 - val_loss: 260.1773\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 16ms/step - loss: 246.6704 - val_loss: 226.5269\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 13ms/step - loss: 225.1540 - val_loss: 215.1733\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 16ms/step - loss: 214.6603 - val_loss: 207.8438\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 18ms/step - loss: 206.4811 - val_loss: 202.2103\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 14ms/step - loss: 200.5553 - val_loss: 197.0336\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 13ms/step - loss: 195.2610 - val_loss: 192.4011\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 19ms/step - loss: 190.7106 - val_loss: 188.3262\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 22ms/step - loss: 187.0352 - val_loss: 185.0706\n",
      "Epoch 21/50\n",
      "23/23 - 1s - 25ms/step - loss: 183.0569 - val_loss: 181.5689\n",
      "Epoch 22/50\n",
      "23/23 - 2s - 91ms/step - loss: 179.7977 - val_loss: 178.5371\n",
      "Epoch 23/50\n",
      "23/23 - 1s - 32ms/step - loss: 176.7704 - val_loss: 176.1514\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 11ms/step - loss: 173.9560 - val_loss: 173.2217\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 16ms/step - loss: 171.2055 - val_loss: 170.6115\n",
      "Epoch 26/50\n",
      "23/23 - 1s - 41ms/step - loss: 168.6141 - val_loss: 168.4872\n",
      "Epoch 27/50\n",
      "23/23 - 1s - 25ms/step - loss: 165.8998 - val_loss: 166.3685\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 9ms/step - loss: 163.4573 - val_loss: 163.8564\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 10ms/step - loss: 161.0842 - val_loss: 161.7762\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 10ms/step - loss: 158.8084 - val_loss: 159.9577\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 13ms/step - loss: 157.1289 - val_loss: 157.9611\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 154.4732 - val_loss: 156.1573\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 8ms/step - loss: 152.8228 - val_loss: 154.1244\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 8ms/step - loss: 150.9192 - val_loss: 152.4101\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 13ms/step - loss: 149.0233 - val_loss: 150.6936\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 7ms/step - loss: 146.9505 - val_loss: 149.0480\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 145.2682 - val_loss: 147.8132\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 7ms/step - loss: 143.7886 - val_loss: 146.0522\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 21ms/step - loss: 142.4232 - val_loss: 145.2931\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 11ms/step - loss: 140.4902 - val_loss: 143.7893\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 10ms/step - loss: 139.6048 - val_loss: 142.6488\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 16ms/step - loss: 138.2749 - val_loss: 141.8423\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 14ms/step - loss: 137.0504 - val_loss: 141.3538\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 12ms/step - loss: 135.7964 - val_loss: 140.1216\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 13ms/step - loss: 134.6925 - val_loss: 139.2104\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 7ms/step - loss: 133.5061 - val_loss: 138.9172\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 18ms/step - loss: 132.6003 - val_loss: 137.9174\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 10ms/step - loss: 132.0152 - val_loss: 136.9470\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 130.8991 - val_loss: 136.8123\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 8ms/step - loss: 129.7605 - val_loss: 136.0975\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 8s - 328ms/step - loss: 1596.0933 - val_loss: 1441.0527\n",
      "Epoch 2/50\n",
      "23/23 - 2s - 68ms/step - loss: 1568.2391 - val_loss: 1410.7804\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1534.9740 - val_loss: 1372.7961\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 6ms/step - loss: 1491.5785 - val_loss: 1321.5687\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1431.6595 - val_loss: 1250.9337\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1350.1410 - val_loss: 1159.6713\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1244.8737 - val_loss: 1047.2405\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 9ms/step - loss: 1115.4602 - val_loss: 911.9341\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 960.3550 - val_loss: 758.5157\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 7ms/step - loss: 785.3912 - val_loss: 600.3566\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 607.6103 - val_loss: 459.1117\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 14ms/step - loss: 453.8736 - val_loss: 352.1473\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 340.7815 - val_loss: 284.7594\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 7ms/step - loss: 272.8766 - val_loss: 245.3839\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 6ms/step - loss: 234.7458 - val_loss: 222.6085\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 214.2528 - val_loss: 206.3279\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 202.9006 - val_loss: 196.5971\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 194.8610 - val_loss: 189.1190\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 189.7713 - val_loss: 181.3981\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 8ms/step - loss: 185.2599 - val_loss: 178.3718\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 8ms/step - loss: 181.1338 - val_loss: 172.9260\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 7ms/step - loss: 177.4286 - val_loss: 169.2195\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 174.1398 - val_loss: 166.7648\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 8ms/step - loss: 171.0061 - val_loss: 163.8958\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 168.1642 - val_loss: 161.0658\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.3910 - val_loss: 158.2981\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 7ms/step - loss: 162.8638 - val_loss: 156.0375\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 160.3929 - val_loss: 153.5982\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 158.3161 - val_loss: 151.7516\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 11ms/step - loss: 156.0645 - val_loss: 148.6021\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 6ms/step - loss: 153.7292 - val_loss: 147.1087\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 8ms/step - loss: 151.5974 - val_loss: 144.9734\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 149.5395 - val_loss: 142.9076\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 8ms/step - loss: 146.9295 - val_loss: 140.7386\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 13ms/step - loss: 144.6173 - val_loss: 138.8645\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 9ms/step - loss: 142.2089 - val_loss: 136.9020\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 139.9202 - val_loss: 134.3732\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 137.4129 - val_loss: 132.0774\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 7ms/step - loss: 135.1664 - val_loss: 129.9878\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 132.5646 - val_loss: 127.8866\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 130.1647 - val_loss: 125.3732\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 16ms/step - loss: 127.7223 - val_loss: 123.6954\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 125.4697 - val_loss: 121.3136\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 123.3324 - val_loss: 119.7239\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 120.9595 - val_loss: 118.1396\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 118.5949 - val_loss: 115.7704\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.1327 - val_loss: 114.4655\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.8692 - val_loss: 112.0604\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 3ms/step - loss: 111.8207 - val_loss: 110.6266\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 7ms/step - loss: 109.6201 - val_loss: 109.5572\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 149ms/step - loss: 1561.3263 - val_loss: 1556.3865\n",
      "Epoch 2/50\n",
      "23/23 - 1s - 36ms/step - loss: 1533.2777 - val_loss: 1528.2584\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1499.9521 - val_loss: 1488.7596\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 7ms/step - loss: 1449.7992 - val_loss: 1422.8948\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 10ms/step - loss: 1367.1942 - val_loss: 1319.0385\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 11ms/step - loss: 1241.8850 - val_loss: 1170.3978\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 1069.4235 - val_loss: 977.2443\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 856.4445 - val_loss: 760.9468\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 10ms/step - loss: 631.3799 - val_loss: 560.2888\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 14ms/step - loss: 443.6556 - val_loss: 422.2043\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 8ms/step - loss: 324.5247 - val_loss: 353.4141\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 13ms/step - loss: 269.1409 - val_loss: 318.9010\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 241.6700 - val_loss: 292.8409\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 11ms/step - loss: 221.5065 - val_loss: 270.7048\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 206.4361 - val_loss: 253.6681\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 10ms/step - loss: 195.3766 - val_loss: 239.7403\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 187.4928 - val_loss: 227.9585\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 181.0705 - val_loss: 218.3080\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 10ms/step - loss: 175.6936 - val_loss: 210.0114\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 171.6981 - val_loss: 203.2704\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 12ms/step - loss: 167.7227 - val_loss: 197.0490\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 164.9902 - val_loss: 190.8943\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 161.5960 - val_loss: 186.6212\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 10ms/step - loss: 159.0888 - val_loss: 182.6810\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 156.4045 - val_loss: 178.9305\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 154.2681 - val_loss: 175.6600\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 151.9626 - val_loss: 172.2873\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 149.8609 - val_loss: 169.2656\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 10ms/step - loss: 148.2264 - val_loss: 166.6540\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 145.9197 - val_loss: 164.1192\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 8ms/step - loss: 144.3539 - val_loss: 160.9229\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 142.6333 - val_loss: 159.2650\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 140.8732 - val_loss: 156.4582\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 139.0499 - val_loss: 154.6878\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 137.3128 - val_loss: 152.3268\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 135.8882 - val_loss: 150.2709\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 134.4749 - val_loss: 149.2346\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 13ms/step - loss: 132.8472 - val_loss: 146.2766\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 131.2585 - val_loss: 145.1180\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 8ms/step - loss: 129.8367 - val_loss: 143.2672\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 7ms/step - loss: 128.1651 - val_loss: 140.7925\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 7ms/step - loss: 126.7840 - val_loss: 139.3722\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 12ms/step - loss: 125.4110 - val_loss: 137.8759\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 124.4389 - val_loss: 136.0320\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 122.8720 - val_loss: 135.1758\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 121.4911 - val_loss: 133.5931\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.4328 - val_loss: 131.7299\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 119.2168 - val_loss: 130.6774\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 118.0481 - val_loss: 129.9702\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 8ms/step - loss: 116.7232 - val_loss: 127.5477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 128ms/step - loss: 1588.4353 - val_loss: 1545.7894\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 15ms/step - loss: 1559.5343 - val_loss: 1516.6259\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1526.7499 - val_loss: 1480.4602\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 8ms/step - loss: 1484.3763 - val_loss: 1431.7715\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 6ms/step - loss: 1425.1975 - val_loss: 1359.4307\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 8ms/step - loss: 1336.3369 - val_loss: 1246.2051\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1196.2964 - val_loss: 1080.1956\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 9ms/step - loss: 1003.3093 - val_loss: 869.4778\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 15ms/step - loss: 777.5397 - val_loss: 649.0145\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 13ms/step - loss: 558.7685 - val_loss: 472.8806\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 11ms/step - loss: 397.5179 - val_loss: 364.2301\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 12ms/step - loss: 305.2736 - val_loss: 308.6892\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 17ms/step - loss: 259.0855 - val_loss: 273.7602\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 10ms/step - loss: 230.2099 - val_loss: 248.7941\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 6ms/step - loss: 209.3668 - val_loss: 230.9781\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 195.5495 - val_loss: 217.2262\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 185.4610 - val_loss: 207.2942\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 178.2375 - val_loss: 200.0510\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 172.7238 - val_loss: 193.4965\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 167.7961 - val_loss: 188.1141\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 164.3688 - val_loss: 184.0821\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 161.1690 - val_loss: 180.5673\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 9ms/step - loss: 158.8251 - val_loss: 177.5573\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.2459 - val_loss: 174.4034\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 154.1256 - val_loss: 171.8536\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 152.2152 - val_loss: 169.6443\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.2858 - val_loss: 167.5008\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 148.4853 - val_loss: 165.5706\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 7ms/step - loss: 147.1662 - val_loss: 163.8498\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 7ms/step - loss: 145.6768 - val_loss: 161.8058\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 9ms/step - loss: 144.5513 - val_loss: 160.0933\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.0654 - val_loss: 158.7001\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 10ms/step - loss: 142.1386 - val_loss: 157.2701\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 10ms/step - loss: 140.8391 - val_loss: 155.7584\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.7746 - val_loss: 154.6729\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 138.7576 - val_loss: 153.2417\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 137.8221 - val_loss: 152.1961\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.9880 - val_loss: 151.0969\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.0538 - val_loss: 149.9795\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 135.2188 - val_loss: 149.0473\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.4757 - val_loss: 148.0494\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 133.6189 - val_loss: 146.9438\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 132.9810 - val_loss: 146.2453\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 132.2631 - val_loss: 145.7073\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.5571 - val_loss: 144.8058\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 130.9831 - val_loss: 144.2269\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 130.4495 - val_loss: 143.5155\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.7022 - val_loss: 142.7036\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 129.0622 - val_loss: 142.1975\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.5175 - val_loss: 141.4479\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 4s - 161ms/step - loss: 1522.8911 - val_loss: 1572.8407\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 7ms/step - loss: 1495.6967 - val_loss: 1538.3859\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 7ms/step - loss: 1455.3062 - val_loss: 1485.9668\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 7ms/step - loss: 1391.2649 - val_loss: 1400.4976\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 10ms/step - loss: 1287.6305 - val_loss: 1261.3373\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 9ms/step - loss: 1122.1830 - val_loss: 1048.6807\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 887.8611 - val_loss: 767.5201\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 7ms/step - loss: 621.5906 - val_loss: 506.9598\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 7ms/step - loss: 402.4740 - val_loss: 344.0885\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 275.7215 - val_loss: 269.1413\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 216.3653 - val_loss: 239.1298\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 7ms/step - loss: 192.4019 - val_loss: 225.5201\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 181.0133 - val_loss: 216.6051\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 7ms/step - loss: 174.3976 - val_loss: 210.0236\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.4860 - val_loss: 204.8362\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 165.8151 - val_loss: 200.1770\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 162.2709 - val_loss: 195.4187\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.2270 - val_loss: 191.6183\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 9ms/step - loss: 156.6684 - val_loss: 187.9341\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 154.0443 - val_loss: 184.8607\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 151.5441 - val_loss: 181.8980\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 7ms/step - loss: 149.5527 - val_loss: 178.6413\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 6ms/step - loss: 147.4045 - val_loss: 176.4096\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 6ms/step - loss: 145.7697 - val_loss: 173.8484\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 144.1691 - val_loss: 171.4979\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 142.4612 - val_loss: 169.5094\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 7ms/step - loss: 141.0951 - val_loss: 167.4540\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 8ms/step - loss: 139.5798 - val_loss: 165.7732\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 138.3226 - val_loss: 164.0682\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 15ms/step - loss: 136.9536 - val_loss: 162.2639\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 8ms/step - loss: 136.1721 - val_loss: 160.7880\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 7ms/step - loss: 134.7325 - val_loss: 159.2836\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 134.0717 - val_loss: 157.7959\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 7ms/step - loss: 133.1309 - val_loss: 156.2036\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 131.7454 - val_loss: 155.3428\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.8053 - val_loss: 154.0868\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 10ms/step - loss: 130.0453 - val_loss: 153.0414\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 129.6301 - val_loss: 152.0559\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 128.7296 - val_loss: 151.3582\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 127.5337 - val_loss: 150.3817\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.2763 - val_loss: 149.6985\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.3432 - val_loss: 148.6124\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 125.8763 - val_loss: 148.0066\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 125.3076 - val_loss: 147.0953\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 124.8453 - val_loss: 146.4360\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 123.9843 - val_loss: 145.5090\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 123.2168 - val_loss: 144.6000\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 122.8016 - val_loss: 144.0868\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 121.9331 - val_loss: 143.3804\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.6104 - val_loss: 142.4608\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 121ms/step - loss: 1575.8610 - val_loss: 1570.9357\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 17ms/step - loss: 1552.5704 - val_loss: 1546.3369\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1524.5577 - val_loss: 1513.4852\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 12ms/step - loss: 1484.9620 - val_loss: 1465.0635\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 8ms/step - loss: 1425.4442 - val_loss: 1391.3010\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 19ms/step - loss: 1337.4706 - val_loss: 1286.0212\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 13ms/step - loss: 1214.6229 - val_loss: 1148.7045\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 12ms/step - loss: 1053.7051 - val_loss: 972.2826\n",
      "Epoch 9/50\n",
      "23/23 - 1s - 28ms/step - loss: 859.7143 - val_loss: 777.1647\n",
      "Epoch 10/50\n",
      "23/23 - 1s - 23ms/step - loss: 663.9195 - val_loss: 599.9098\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 15ms/step - loss: 504.0237 - val_loss: 480.6715\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 14ms/step - loss: 405.8526 - val_loss: 412.0253\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 6ms/step - loss: 348.6761 - val_loss: 366.3965\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 310.1779 - val_loss: 325.9865\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 277.1559 - val_loss: 292.1251\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 250.0275 - val_loss: 264.3430\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 229.0082 - val_loss: 241.0607\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 210.2345 - val_loss: 223.2670\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 196.8106 - val_loss: 208.6913\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 9ms/step - loss: 185.7557 - val_loss: 198.1415\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 177.0032 - val_loss: 188.6904\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 170.0910 - val_loss: 181.8956\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 164.6556 - val_loss: 176.9210\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 160.0251 - val_loss: 172.8387\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.6565 - val_loss: 170.2995\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 153.3359 - val_loss: 166.9350\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.4442 - val_loss: 164.8371\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.1338 - val_loss: 162.7580\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.5841 - val_loss: 161.1081\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.0222 - val_loss: 159.5740\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 11ms/step - loss: 141.6404 - val_loss: 157.8255\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.0218 - val_loss: 156.4522\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 138.1411 - val_loss: 155.3008\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 6ms/step - loss: 136.5021 - val_loss: 153.9925\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 135.1211 - val_loss: 152.7766\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 9ms/step - loss: 134.1015 - val_loss: 151.4769\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 12ms/step - loss: 132.5457 - val_loss: 150.3270\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 131.3020 - val_loss: 149.1983\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.9245 - val_loss: 148.3966\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 8ms/step - loss: 128.5074 - val_loss: 146.8913\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 127.4587 - val_loss: 145.9899\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 126.1309 - val_loss: 145.4126\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 124.8942 - val_loss: 143.9819\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 124.0028 - val_loss: 143.3338\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 122.8671 - val_loss: 142.2614\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 121.6830 - val_loss: 141.1153\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.4131 - val_loss: 140.3603\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 119.8971 - val_loss: 139.4925\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 8ms/step - loss: 118.4888 - val_loss: 138.6643\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 9ms/step - loss: 117.4035 - val_loss: 137.1842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 4s - 183ms/step - loss: 1552.7233 - val_loss: 1542.1667\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 6ms/step - loss: 1531.0791 - val_loss: 1514.5151\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 1496.6775 - val_loss: 1469.6921\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 12ms/step - loss: 1440.2253 - val_loss: 1399.7196\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 13ms/step - loss: 1356.2336 - val_loss: 1300.3152\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 10ms/step - loss: 1239.6385 - val_loss: 1164.9559\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 8ms/step - loss: 1085.7642 - val_loss: 994.1264\n",
      "Epoch 8/50\n",
      "23/23 - 1s - 24ms/step - loss: 902.6124 - val_loss: 796.1169\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 19ms/step - loss: 709.4609 - val_loss: 594.1060\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 13ms/step - loss: 528.9758 - val_loss: 433.2074\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 397.1938 - val_loss: 320.4152\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 8ms/step - loss: 317.7098 - val_loss: 254.8307\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 267.6417 - val_loss: 222.4538\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 11ms/step - loss: 240.8948 - val_loss: 205.4071\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 7ms/step - loss: 224.5263 - val_loss: 195.7498\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 8ms/step - loss: 213.4473 - val_loss: 188.5852\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 7ms/step - loss: 205.4204 - val_loss: 183.1085\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 7ms/step - loss: 198.3541 - val_loss: 176.9390\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 8ms/step - loss: 192.4433 - val_loss: 172.6281\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 9ms/step - loss: 187.3175 - val_loss: 167.8730\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 16ms/step - loss: 183.0666 - val_loss: 163.9910\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 8ms/step - loss: 178.6291 - val_loss: 160.8730\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 14ms/step - loss: 175.0753 - val_loss: 158.4055\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 14ms/step - loss: 172.5111 - val_loss: 156.2820\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 9ms/step - loss: 168.6764 - val_loss: 152.4471\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 17ms/step - loss: 165.8480 - val_loss: 149.9122\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 14ms/step - loss: 162.9046 - val_loss: 148.0863\n",
      "Epoch 28/50\n",
      "23/23 - 1s - 23ms/step - loss: 160.1908 - val_loss: 146.2925\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 11ms/step - loss: 157.9586 - val_loss: 143.6477\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 15ms/step - loss: 155.3550 - val_loss: 142.7873\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 15ms/step - loss: 153.2928 - val_loss: 141.0333\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 7ms/step - loss: 151.5192 - val_loss: 139.1449\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 15ms/step - loss: 149.7836 - val_loss: 138.2886\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 147.8223 - val_loss: 136.8094\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.2833 - val_loss: 135.6838\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 144.7760 - val_loss: 134.6685\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 143.2815 - val_loss: 133.3801\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 141.9607 - val_loss: 132.4779\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.1378 - val_loss: 131.7710\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 8ms/step - loss: 139.4697 - val_loss: 130.4102\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 138.2379 - val_loss: 129.8509\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 9ms/step - loss: 137.3551 - val_loss: 129.4079\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.0710 - val_loss: 128.5292\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 134.9990 - val_loss: 127.9044\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 134.3585 - val_loss: 127.4123\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.0817 - val_loss: 126.3742\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 132.3316 - val_loss: 125.8698\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 7ms/step - loss: 131.4698 - val_loss: 125.3807\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 130.6667 - val_loss: 124.9044\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 130.1623 - val_loss: 124.2489\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina nabil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 - 4s - 178ms/step - loss: 1541.4966 - val_loss: 1580.2056\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 17ms/step - loss: 1511.5334 - val_loss: 1543.1606\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 1465.9835 - val_loss: 1483.8854\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1394.7540 - val_loss: 1393.8824\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 8ms/step - loss: 1288.9331 - val_loss: 1261.3947\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 8ms/step - loss: 1138.9794 - val_loss: 1077.5057\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 937.0050 - val_loss: 837.0983\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 7ms/step - loss: 686.7830 - val_loss: 572.3008\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 445.1595 - val_loss: 354.1436\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 15ms/step - loss: 284.4785 - val_loss: 251.5294\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 9ms/step - loss: 223.7974 - val_loss: 220.5473\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 9ms/step - loss: 206.9160 - val_loss: 209.4170\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 14ms/step - loss: 198.4830 - val_loss: 200.6923\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 11ms/step - loss: 191.6711 - val_loss: 193.7632\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 14ms/step - loss: 186.0637 - val_loss: 188.2534\n",
      "Epoch 16/50\n",
      "23/23 - 1s - 32ms/step - loss: 180.7030 - val_loss: 183.5966\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 12ms/step - loss: 176.5363 - val_loss: 178.9456\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 12ms/step - loss: 172.2403 - val_loss: 174.4781\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 12ms/step - loss: 168.0503 - val_loss: 170.1324\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 9ms/step - loss: 163.6611 - val_loss: 166.0686\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 159.5914 - val_loss: 162.4306\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 6ms/step - loss: 155.8349 - val_loss: 158.9595\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 7ms/step - loss: 152.3925 - val_loss: 155.1549\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 7ms/step - loss: 148.9278 - val_loss: 151.8745\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 145.2237 - val_loss: 148.5770\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 141.9797 - val_loss: 145.3847\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 9ms/step - loss: 138.7892 - val_loss: 142.3485\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 11ms/step - loss: 135.7106 - val_loss: 139.4519\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 132.6975 - val_loss: 136.6120\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 130.4632 - val_loss: 134.1655\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 10ms/step - loss: 127.4441 - val_loss: 131.2084\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 13ms/step - loss: 124.7250 - val_loss: 128.8646\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 8ms/step - loss: 122.1003 - val_loss: 126.7233\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 8ms/step - loss: 119.6300 - val_loss: 124.1932\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 7ms/step - loss: 117.5554 - val_loss: 122.0170\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 8ms/step - loss: 115.5205 - val_loss: 120.1016\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 112.7399 - val_loss: 117.8533\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 110.8762 - val_loss: 115.9008\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 6ms/step - loss: 108.8545 - val_loss: 113.8083\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 106.4535 - val_loss: 111.8824\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 104.4791 - val_loss: 109.8761\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 13ms/step - loss: 102.5058 - val_loss: 107.8095\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 100.5137 - val_loss: 105.8241\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 13ms/step - loss: 98.3107 - val_loss: 103.7086\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 96.5892 - val_loss: 102.0061\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 94.5473 - val_loss: 99.5387\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 92.4491 - val_loss: 97.5659\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 12ms/step - loss: 90.6360 - val_loss: 96.0500\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 12ms/step - loss: 88.6906 - val_loss: 93.6732\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 18ms/step - loss: 87.1115 - val_loss: 91.6436\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Mean MSE with Normalized Data and 3 Hidden Layers: 126.56722836873396\n",
      "Standard Deviation of MSE with Normalized Data and 3 Hidden Layers: 16.64988973108454\n"
     ]
    }
   ],
   "source": [
    "# Define the model with three hidden layers\n",
    "def regression_model_deep(n_cols):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Store mean squared errors for 50 repetitions with deeper model\n",
    "mse_list_deep = []\n",
    "\n",
    "for _ in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized, target, test_size=0.3, random_state=None)\n",
    "\n",
    "    # Build and train the model\n",
    "    model = regression_model_deep(n_cols)\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=2)\n",
    "    \n",
    "    # Predict and calculate mean squared error\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list_deep.append(mse)\n",
    "\n",
    "# Compute mean and standard deviation of the mean squared errors\n",
    "mean_mse_deep = np.mean(mse_list_deep)\n",
    "std_mse_deep = np.std(mse_list_deep)\n",
    "\n",
    "print(f'Mean MSE with Normalized Data and 3 Hidden Layers: {mean_mse_deep}')\n",
    "print(f'Standard Deviation of MSE with Normalized Data and 3 Hidden Layers: {std_mse_deep}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Results\n",
    "\n",
    "- **Baseline Model**:\n",
    "  - Mean MSE: 424.30079044071294\n",
    "  - Standard Deviation of MSE: 652.3590805604039\n",
    "\n",
    "- **Normalized Data**:\n",
    "  - Mean MSE: 364.7412743225821\n",
    "  - Standard Deviation of MSE: 91.92585864320618\n",
    "\n",
    "- **100 Epochs**:\n",
    "  - Mean MSE: 169.02386475491716\n",
    "  - Standard Deviation of MSE: 18.66219906409647\n",
    "\n",
    "- **Three Hidden Layers**:\n",
    "  - Mean MSE: 126.56722836873396\n",
    "  - Standard Deviation of MSE: 16.64988973108454\n",
    "\n",
    "## Discussion\n",
    "\n",
    "1. **Baseline Model**: The initial model had a relatively high mean MSE and standard deviation, indicating a moderate prediction accuracy and high variability.\n",
    "\n",
    "2. **Normalized Data**: Normalizing the data improved the model's performance slightly, as seen in the reduction of both the mean and standard deviation of the MSE.\n",
    "\n",
    "3. **100 Epochs**: Increasing the number of epochs significantly improved the model's performance, reducing the mean MSE and its variability, suggesting better training of the neural network.\n",
    "\n",
    "4. **Three Hidden Layers**: Adding more hidden layers further improved the model's performance, reducing the mean MSE and standard deviation, indicating that a deeper network can capture more complex patterns in the data.\n",
    "\n",
    "Overall, the experiments show that normalization, increasing epochs, and adding hidden layers all contribute to improved model performance. 📈"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
